{
    "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/compare/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4...eb26859dd183748040c139e4c179f86a00bef959",
    "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/compare/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4...eb26859dd183748040c139e4c179f86a00bef959",
    "permalink_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/compare/EcoNet-Rheem:c260256...EcoNet-Rheem:eb26859",
    "diff_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/compare/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4...eb26859dd183748040c139e4c179f86a00bef959.diff",
    "patch_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/compare/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4...eb26859dd183748040c139e4c179f86a00bef959.patch",
    "base_commit": {
      "sha": "c2602560bfa97ddaead4ff3c8538ca9a2530a1a4",
      "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OmMyNjAyNTYwYmZhOTdkZGFlYWQ0ZmYzYzg1MzhjYTlhMjUzMGExYTQ=",
      "commit": {
        "author": {
          "name": "Chandani Patel",
          "email": "chandani.patel@volansystech.com",
          "date": "2020-10-27T09:32:01Z"
        },
        "committer": {
          "name": "Chandani Patel",
          "email": "chandani.patel@volansystech.com",
          "date": "2020-10-27T09:32:01Z"
        },
        "message": "EDE-198: initial import adding git submodule",
        "tree": {
          "sha": "d6eb68b492acce8fbb10eda1e28b6cc4119c7e84",
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/d6eb68b492acce8fbb10eda1e28b6cc4119c7e84"
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4",
        "comment_count": 0,
        "verification": {
          "verified": false,
          "reason": "unsigned",
          "signature": null,
          "payload": null
        }
      },
      "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4",
      "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4",
      "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4/comments",
      "author": {
        "login": "chandani-patel",
        "id": 11056833,
        "node_id": "MDQ6VXNlcjExMDU2ODMz",
        "avatar_url": "https://avatars2.githubusercontent.com/u/11056833?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/chandani-patel",
        "html_url": "https://github.com/chandani-patel",
        "followers_url": "https://api.github.com/users/chandani-patel/followers",
        "following_url": "https://api.github.com/users/chandani-patel/following{/other_user}",
        "gists_url": "https://api.github.com/users/chandani-patel/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/chandani-patel/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/chandani-patel/subscriptions",
        "organizations_url": "https://api.github.com/users/chandani-patel/orgs",
        "repos_url": "https://api.github.com/users/chandani-patel/repos",
        "events_url": "https://api.github.com/users/chandani-patel/events{/privacy}",
        "received_events_url": "https://api.github.com/users/chandani-patel/received_events",
        "type": "User",
        "site_admin": false
      },
      "committer": {
        "login": "chandani-patel",
        "id": 11056833,
        "node_id": "MDQ6VXNlcjExMDU2ODMz",
        "avatar_url": "https://avatars2.githubusercontent.com/u/11056833?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/chandani-patel",
        "html_url": "https://github.com/chandani-patel",
        "followers_url": "https://api.github.com/users/chandani-patel/followers",
        "following_url": "https://api.github.com/users/chandani-patel/following{/other_user}",
        "gists_url": "https://api.github.com/users/chandani-patel/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/chandani-patel/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/chandani-patel/subscriptions",
        "organizations_url": "https://api.github.com/users/chandani-patel/orgs",
        "repos_url": "https://api.github.com/users/chandani-patel/repos",
        "events_url": "https://api.github.com/users/chandani-patel/events{/privacy}",
        "received_events_url": "https://api.github.com/users/chandani-patel/received_events",
        "type": "User",
        "site_admin": false
      },
      "parents": [
        {
          "sha": "6cf0182912949e0d2a043b58df63d1ab252c4e4f",
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/6cf0182912949e0d2a043b58df63d1ab252c4e4f",
          "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/6cf0182912949e0d2a043b58df63d1ab252c4e4f"
        }
      ]
    },
    "merge_base_commit": {
      "sha": "c2602560bfa97ddaead4ff3c8538ca9a2530a1a4",
      "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OmMyNjAyNTYwYmZhOTdkZGFlYWQ0ZmYzYzg1MzhjYTlhMjUzMGExYTQ=",
      "commit": {
        "author": {
          "name": "Chandani Patel",
          "email": "chandani.patel@volansystech.com",
          "date": "2020-10-27T09:32:01Z"
        },
        "committer": {
          "name": "Chandani Patel",
          "email": "chandani.patel@volansystech.com",
          "date": "2020-10-27T09:32:01Z"
        },
        "message": "EDE-198: initial import adding git submodule",
        "tree": {
          "sha": "d6eb68b492acce8fbb10eda1e28b6cc4119c7e84",
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/d6eb68b492acce8fbb10eda1e28b6cc4119c7e84"
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4",
        "comment_count": 0,
        "verification": {
          "verified": false,
          "reason": "unsigned",
          "signature": null,
          "payload": null
        }
      },
      "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4",
      "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4",
      "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4/comments",
      "author": {
        "login": "chandani-patel",
        "id": 11056833,
        "node_id": "MDQ6VXNlcjExMDU2ODMz",
        "avatar_url": "https://avatars2.githubusercontent.com/u/11056833?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/chandani-patel",
        "html_url": "https://github.com/chandani-patel",
        "followers_url": "https://api.github.com/users/chandani-patel/followers",
        "following_url": "https://api.github.com/users/chandani-patel/following{/other_user}",
        "gists_url": "https://api.github.com/users/chandani-patel/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/chandani-patel/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/chandani-patel/subscriptions",
        "organizations_url": "https://api.github.com/users/chandani-patel/orgs",
        "repos_url": "https://api.github.com/users/chandani-patel/repos",
        "events_url": "https://api.github.com/users/chandani-patel/events{/privacy}",
        "received_events_url": "https://api.github.com/users/chandani-patel/received_events",
        "type": "User",
        "site_admin": false
      },
      "committer": {
        "login": "chandani-patel",
        "id": 11056833,
        "node_id": "MDQ6VXNlcjExMDU2ODMz",
        "avatar_url": "https://avatars2.githubusercontent.com/u/11056833?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/chandani-patel",
        "html_url": "https://github.com/chandani-patel",
        "followers_url": "https://api.github.com/users/chandani-patel/followers",
        "following_url": "https://api.github.com/users/chandani-patel/following{/other_user}",
        "gists_url": "https://api.github.com/users/chandani-patel/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/chandani-patel/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/chandani-patel/subscriptions",
        "organizations_url": "https://api.github.com/users/chandani-patel/orgs",
        "repos_url": "https://api.github.com/users/chandani-patel/repos",
        "events_url": "https://api.github.com/users/chandani-patel/events{/privacy}",
        "received_events_url": "https://api.github.com/users/chandani-patel/received_events",
        "type": "User",
        "site_admin": false
      },
      "parents": [
        {
          "sha": "6cf0182912949e0d2a043b58df63d1ab252c4e4f",
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/6cf0182912949e0d2a043b58df63d1ab252c4e4f",
          "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/6cf0182912949e0d2a043b58df63d1ab252c4e4f"
        }
      ]
    },
    "status": "ahead",
    "ahead_by": 14,
    "behind_by": 0,
    "total_commits": 14,
    "commits": [
      {
        "sha": "966d12ab3b2731440410d1a8c6cc126e8a75ddb3",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1Ojk2NmQxMmFiM2IyNzMxNDQwNDEwZDFhOGM2Y2MxMjZlOGE3NWRkYjM=",
        "commit": {
          "author": {
            "name": "Chandani Patel",
            "email": "chandani.patel@volansystech.com",
            "date": "2020-11-18T12:01:20Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T12:01:20Z"
          },
          "message": "EDE-198: Release 0.2.0 (#2)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\nCo-authored-by: vivek.rajyaguru <vivek.rajyaguru@volansys.com>",
          "tree": {
            "sha": "ab5945cbcef136ae94cba2b52e73a9e4a8d70447",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/ab5945cbcef136ae94cba2b52e73a9e4a8d70447"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/966d12ab3b2731440410d1a8c6cc126e8a75ddb3",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftQ0QCRBK7hj4Ov3rIwAAdHIIAJWQ8lrOZIxsSE9wcBxLMS0b\nMA5t4sJNtkfG9uNeAFZuIQWnrOLP+i4Q38vy+bLJHRPNctlTCWmcklH13OVeeUxq\n9faQcILZ3J7KQfNbWOqNHlnfv5k/KvfYnC33zhQDKbTqmJDQT84rMsiwD9cQB5Se\np9MEwRBmPZBweIozA0gN9hj9ig5vZHg6BiMVSwjUvM+6qYzgkILMW0NhfQ7DOptX\nwOQB/TlMnGgwSWKjI0YqQ6UQg4a4zOHgn3H02s+yXW8DKnnjsAqt8DO4q1/LLyb8\nrnv+Z2561UTepZlH7yGncsbN2DHwJKh6gh09ma2hpjMP+YadMiJ4WaALKo/cYu4=\n=aX4v\n-----END PGP SIGNATURE-----\n",
            "payload": "tree ab5945cbcef136ae94cba2b52e73a9e4a8d70447\nparent c2602560bfa97ddaead4ff3c8538ca9a2530a1a4\nauthor Chandani Patel <chandani.patel@volansystech.com> 1605700880 +0530\ncommitter GitHub <noreply@github.com> 1605700880 +0530\n\nEDE-198: Release 0.2.0 (#2)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\nCo-authored-by: vivek.rajyaguru <vivek.rajyaguru@volansys.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/966d12ab3b2731440410d1a8c6cc126e8a75ddb3",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/966d12ab3b2731440410d1a8c6cc126e8a75ddb3",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/966d12ab3b2731440410d1a8c6cc126e8a75ddb3/comments",
        "author": {
          "login": "chandani-patel",
          "id": 11056833,
          "node_id": "MDQ6VXNlcjExMDU2ODMz",
          "avatar_url": "https://avatars2.githubusercontent.com/u/11056833?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/chandani-patel",
          "html_url": "https://github.com/chandani-patel",
          "followers_url": "https://api.github.com/users/chandani-patel/followers",
          "following_url": "https://api.github.com/users/chandani-patel/following{/other_user}",
          "gists_url": "https://api.github.com/users/chandani-patel/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/chandani-patel/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/chandani-patel/subscriptions",
          "organizations_url": "https://api.github.com/users/chandani-patel/orgs",
          "repos_url": "https://api.github.com/users/chandani-patel/repos",
          "events_url": "https://api.github.com/users/chandani-patel/events{/privacy}",
          "received_events_url": "https://api.github.com/users/chandani-patel/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "c2602560bfa97ddaead4ff3c8538ca9a2530a1a4",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/c2602560bfa97ddaead4ff3c8538ca9a2530a1a4"
          }
        ]
      },
      {
        "sha": "62638a7458e917695804b5532b2090552f718e90",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OjYyNjM4YTc0NThlOTE3Njk1ODA0YjU1MzJiMjA5MDU1MmY3MThlOTA=",
        "commit": {
          "author": {
            "name": "Chandani Patel",
            "email": "chandani.patel@volansystech.com",
            "date": "2020-11-18T12:15:29Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T12:15:29Z"
          },
          "message": "EDE-198: Fix Deployment Script (#3)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\nCo-authored-by: vivek.rajyaguru <vivek.rajyaguru@volansys.com>",
          "tree": {
            "sha": "fd315b9dd2aa83bc465ce6fa94b319f9a2b39fca",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/fd315b9dd2aa83bc465ce6fa94b319f9a2b39fca"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/62638a7458e917695804b5532b2090552f718e90",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftRBhCRBK7hj4Ov3rIwAAdHIIAAQWwvc6vzvywOEo7MkMiYsA\nApz+4HC9x2jn6HphtTIuxMLSwexqXNWZN84dKYTZxjrZW+HdjUNlx1f/EhcWd5vZ\nyiAFjPhHcBOgLz7LfjgDizyYL+tPepsO+A9oUTPg+nsEoGraAVfqLMiClVVzC/RY\nhuwe+IzQ0uZuPdkFElwfrrr3xam7ONsZFthZ2X+PYhsf9dL0HnGFzfqutAFhbucq\n6EVfzzhV929O3ocrhkaTWhzvy03EF+rH5uyLYwnDGeDm8vHimC1rKxWoryRpGZSt\nJHElsjA7mDmBa6zYTDZWqNs6SDsKZDJgJat/iGBt1f2WLBnMHt6Ve7lQtw1KjQw=\n=UwAN\n-----END PGP SIGNATURE-----\n",
            "payload": "tree fd315b9dd2aa83bc465ce6fa94b319f9a2b39fca\nparent 966d12ab3b2731440410d1a8c6cc126e8a75ddb3\nauthor Chandani Patel <chandani.patel@volansystech.com> 1605701729 +0530\ncommitter GitHub <noreply@github.com> 1605701729 +0530\n\nEDE-198: Fix Deployment Script (#3)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\nCo-authored-by: vivek.rajyaguru <vivek.rajyaguru@volansys.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/62638a7458e917695804b5532b2090552f718e90",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/62638a7458e917695804b5532b2090552f718e90",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/62638a7458e917695804b5532b2090552f718e90/comments",
        "author": {
          "login": "chandani-patel",
          "id": 11056833,
          "node_id": "MDQ6VXNlcjExMDU2ODMz",
          "avatar_url": "https://avatars2.githubusercontent.com/u/11056833?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/chandani-patel",
          "html_url": "https://github.com/chandani-patel",
          "followers_url": "https://api.github.com/users/chandani-patel/followers",
          "following_url": "https://api.github.com/users/chandani-patel/following{/other_user}",
          "gists_url": "https://api.github.com/users/chandani-patel/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/chandani-patel/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/chandani-patel/subscriptions",
          "organizations_url": "https://api.github.com/users/chandani-patel/orgs",
          "repos_url": "https://api.github.com/users/chandani-patel/repos",
          "events_url": "https://api.github.com/users/chandani-patel/events{/privacy}",
          "received_events_url": "https://api.github.com/users/chandani-patel/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "966d12ab3b2731440410d1a8c6cc126e8a75ddb3",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/966d12ab3b2731440410d1a8c6cc126e8a75ddb3",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/966d12ab3b2731440410d1a8c6cc126e8a75ddb3"
          }
        ]
      },
      {
        "sha": "7810c228645e5fcb2ee55795e0b0aed7774f188b",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1Ojc4MTBjMjI4NjQ1ZTVmY2IyZWU1NTc5NWUwYjBhZWQ3Nzc0ZjE4OGI=",
        "commit": {
          "author": {
            "name": "vivek-volansys",
            "email": "63392527+vivek-volansys@users.noreply.github.com",
            "date": "2020-11-18T14:52:51Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T14:52:51Z"
          },
          "message": "EDE-198: Update Deployment Script (#4)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>",
          "tree": {
            "sha": "74111cea8a3f919b5024beb48d1f760e0e074350",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/74111cea8a3f919b5024beb48d1f760e0e074350"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/7810c228645e5fcb2ee55795e0b0aed7774f188b",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftTVDCRBK7hj4Ov3rIwAAdHIIADScflmtFnu0VMFYjfwiyXxM\ntD3l4M5B+GXU/BWtJN6QJQefsCNuwhdSQeVq127yMXTP1obOD42OHoThgmktJFez\nf3QJYKzju3vpl99sWoJLkHw5OTLOv2nuZfi1aYH3oDwimYmKxgwpjvvoccMkJaY4\ndlWU73QJz+nr0ujVeCXHcutN77gMTR/3NVseCBTts2lRyahvTR1AIYRTOkfBRFZf\nA6VMUJNizr2tfW+yV+f5msWbGS8nJ95F/T4KtZN/fEz4EQnvZTth/inb7r14RW00\n109h+l4Lo9WYEFU7M0OWuqrBeNPZ5YKMmTlzJsOjmyYl7MhGxWpotVx57nulGFY=\n=H20k\n-----END PGP SIGNATURE-----\n",
            "payload": "tree 74111cea8a3f919b5024beb48d1f760e0e074350\nparent 62638a7458e917695804b5532b2090552f718e90\nauthor vivek-volansys <63392527+vivek-volansys@users.noreply.github.com> 1605711171 +0530\ncommitter GitHub <noreply@github.com> 1605711171 +0530\n\nEDE-198: Update Deployment Script (#4)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/7810c228645e5fcb2ee55795e0b0aed7774f188b",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/7810c228645e5fcb2ee55795e0b0aed7774f188b",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/7810c228645e5fcb2ee55795e0b0aed7774f188b/comments",
        "author": {
          "login": "vivek-volansys",
          "id": 63392527,
          "node_id": "MDQ6VXNlcjYzMzkyNTI3",
          "avatar_url": "https://avatars0.githubusercontent.com/u/63392527?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/vivek-volansys",
          "html_url": "https://github.com/vivek-volansys",
          "followers_url": "https://api.github.com/users/vivek-volansys/followers",
          "following_url": "https://api.github.com/users/vivek-volansys/following{/other_user}",
          "gists_url": "https://api.github.com/users/vivek-volansys/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/vivek-volansys/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/vivek-volansys/subscriptions",
          "organizations_url": "https://api.github.com/users/vivek-volansys/orgs",
          "repos_url": "https://api.github.com/users/vivek-volansys/repos",
          "events_url": "https://api.github.com/users/vivek-volansys/events{/privacy}",
          "received_events_url": "https://api.github.com/users/vivek-volansys/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "62638a7458e917695804b5532b2090552f718e90",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/62638a7458e917695804b5532b2090552f718e90",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/62638a7458e917695804b5532b2090552f718e90"
          }
        ]
      },
      {
        "sha": "0934b6b720e8404816b9c3e2db1ec795200cdcc5",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OjA5MzRiNmI3MjBlODQwNDgxNmI5YzNlMmRiMWVjNzk1MjAwY2RjYzU=",
        "commit": {
          "author": {
            "name": "vivek-volansys",
            "email": "63392527+vivek-volansys@users.noreply.github.com",
            "date": "2020-11-18T15:28:49Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T15:28:49Z"
          },
          "message": "Ede 198 (#5)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>",
          "tree": {
            "sha": "86c999eca86a00ef7985d5cb0dc96d6f9d579e74",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/86c999eca86a00ef7985d5cb0dc96d6f9d579e74"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/0934b6b720e8404816b9c3e2db1ec795200cdcc5",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftT2xCRBK7hj4Ov3rIwAAdHIIADaPKgGFITuMDgcmyokcYMQh\nIVtyyiEvBo/sykMnqcgu56LTREz706JK+hfS9Z2Zk92XNOjm2jLOXA5y9OQufkB7\n7e7j+ONo6sUh7NVVVy/QkHH4cOaygfE75cHAoFdH9J51yQdVjLe4C1TIQOVoKi3N\n6KIAQ0eI+FI88CgCKDK15ldSqEQcqjRmYRPPZLSwRR7EUyWh3NEDiv+7k3nmXuXI\n36v/sUG7HPJHEPDtadIl/SEHa8RSEHHufPLw85kLGpwdcfPkmL4Dxy0gB2to1MFg\nlnAkppPiBYJFTGbXX5aMSyF5XvhPjET29Ez20zBWJ1EE0CLvGaQdqik4tLd/qU0=\n=usBJ\n-----END PGP SIGNATURE-----\n",
            "payload": "tree 86c999eca86a00ef7985d5cb0dc96d6f9d579e74\nparent 7810c228645e5fcb2ee55795e0b0aed7774f188b\nauthor vivek-volansys <63392527+vivek-volansys@users.noreply.github.com> 1605713329 +0530\ncommitter GitHub <noreply@github.com> 1605713329 +0530\n\nEde 198 (#5)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/0934b6b720e8404816b9c3e2db1ec795200cdcc5",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/0934b6b720e8404816b9c3e2db1ec795200cdcc5",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/0934b6b720e8404816b9c3e2db1ec795200cdcc5/comments",
        "author": {
          "login": "vivek-volansys",
          "id": 63392527,
          "node_id": "MDQ6VXNlcjYzMzkyNTI3",
          "avatar_url": "https://avatars0.githubusercontent.com/u/63392527?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/vivek-volansys",
          "html_url": "https://github.com/vivek-volansys",
          "followers_url": "https://api.github.com/users/vivek-volansys/followers",
          "following_url": "https://api.github.com/users/vivek-volansys/following{/other_user}",
          "gists_url": "https://api.github.com/users/vivek-volansys/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/vivek-volansys/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/vivek-volansys/subscriptions",
          "organizations_url": "https://api.github.com/users/vivek-volansys/orgs",
          "repos_url": "https://api.github.com/users/vivek-volansys/repos",
          "events_url": "https://api.github.com/users/vivek-volansys/events{/privacy}",
          "received_events_url": "https://api.github.com/users/vivek-volansys/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "7810c228645e5fcb2ee55795e0b0aed7774f188b",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/7810c228645e5fcb2ee55795e0b0aed7774f188b",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/7810c228645e5fcb2ee55795e0b0aed7774f188b"
          }
        ]
      },
      {
        "sha": "96016550e39becf4fe6d218564707481e8b5ef34",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1Ojk2MDE2NTUwZTM5YmVjZjRmZTZkMjE4NTY0NzA3NDgxZThiNWVmMzQ=",
        "commit": {
          "author": {
            "name": "vivek-volansys",
            "email": "63392527+vivek-volansys@users.noreply.github.com",
            "date": "2020-11-18T15:40:19Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T15:40:19Z"
          },
          "message": "Ede 198 (#6)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>",
          "tree": {
            "sha": "abc5443ba5f3d7e2e4dc0cc858a780986ea4791b",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/abc5443ba5f3d7e2e4dc0cc858a780986ea4791b"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/96016550e39becf4fe6d218564707481e8b5ef34",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftUBjCRBK7hj4Ov3rIwAAdHIIAAxpmVJ7wj31fIb3PYsbeMqh\nzh9mlFOiXCMsimdrV9yjbr2ynmgALW2YDpiR3DT75MI8+/QW4FTKgNb4AuzjlLLR\nLgi3zChdI8SvWl8o6hmtfd4vFzdaXslOPFEuMG4MjoWe2ZUjWswbtpT4Oi/WwpcQ\n1B2EvqEvXC5LIHreyX8W9CB7JU1jUdnaO7luIectL5T6OJG9kmLTHMwZwA8G4uyQ\ne5/3e6sKl8pUt5c1ylG1W+iRWt/AiWIwoOhGJuJ2yVw3KtgVGv60+9HJtLtTkwFM\nTDwD8bxQpgrGrg4Vy4ywaILK4Kds5ieboIN80qLYbu4s9TtYd7G8Rf8HTTeJYUw=\n=RceX\n-----END PGP SIGNATURE-----\n",
            "payload": "tree abc5443ba5f3d7e2e4dc0cc858a780986ea4791b\nparent 0934b6b720e8404816b9c3e2db1ec795200cdcc5\nauthor vivek-volansys <63392527+vivek-volansys@users.noreply.github.com> 1605714019 +0530\ncommitter GitHub <noreply@github.com> 1605714019 +0530\n\nEde 198 (#6)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/96016550e39becf4fe6d218564707481e8b5ef34",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/96016550e39becf4fe6d218564707481e8b5ef34",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/96016550e39becf4fe6d218564707481e8b5ef34/comments",
        "author": {
          "login": "vivek-volansys",
          "id": 63392527,
          "node_id": "MDQ6VXNlcjYzMzkyNTI3",
          "avatar_url": "https://avatars0.githubusercontent.com/u/63392527?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/vivek-volansys",
          "html_url": "https://github.com/vivek-volansys",
          "followers_url": "https://api.github.com/users/vivek-volansys/followers",
          "following_url": "https://api.github.com/users/vivek-volansys/following{/other_user}",
          "gists_url": "https://api.github.com/users/vivek-volansys/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/vivek-volansys/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/vivek-volansys/subscriptions",
          "organizations_url": "https://api.github.com/users/vivek-volansys/orgs",
          "repos_url": "https://api.github.com/users/vivek-volansys/repos",
          "events_url": "https://api.github.com/users/vivek-volansys/events{/privacy}",
          "received_events_url": "https://api.github.com/users/vivek-volansys/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "0934b6b720e8404816b9c3e2db1ec795200cdcc5",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/0934b6b720e8404816b9c3e2db1ec795200cdcc5",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/0934b6b720e8404816b9c3e2db1ec795200cdcc5"
          }
        ]
      },
      {
        "sha": "cd870f6ebe88cfc1a05033551429f27fc592138c",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OmNkODcwZjZlYmU4OGNmYzFhMDUwMzM1NTE0MjlmMjdmYzU5MjEzOGM=",
        "commit": {
          "author": {
            "name": "vivek-volansys",
            "email": "63392527+vivek-volansys@users.noreply.github.com",
            "date": "2020-11-18T16:01:32Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T16:01:32Z"
          },
          "message": "Ede 198 (#7)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>",
          "tree": {
            "sha": "666809148034941eda96d5b0d794be8c41a4b00e",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/666809148034941eda96d5b0d794be8c41a4b00e"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/cd870f6ebe88cfc1a05033551429f27fc592138c",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftUVcCRBK7hj4Ov3rIwAAdHIIAFt1xGJjsK9swvQ55gJT+Ih/\ndLi7QIKewK6m1xu9fba9IPtewTDDZIbMeerMygomzA77pef0x2U9sR9aQbmvf5A0\n45GF2HXUgEEPFO8PsS09G1igddlTkx93xnyXPp5v/VeTWEKViADhVG/xokJNALhx\nWXGeLunGmR6BBTGQOKr+ZwPY+zStRJniHlwTRR8Q3u90GIBmn6bVmCtpJ+rwne3o\n2Hxz1ngOu6wzjYyTz0U/9GVxJ0AHtsaS5n+UTrRo2a5Nm3U+zJ/WfINE/DDoqtzR\nTAZnNHt3n0LSnSXQkfN78hzt3r4eqguE0I+71wiPyLPs6U4Kj6H76r/xgO2+PEY=\n=H651\n-----END PGP SIGNATURE-----\n",
            "payload": "tree 666809148034941eda96d5b0d794be8c41a4b00e\nparent 96016550e39becf4fe6d218564707481e8b5ef34\nauthor vivek-volansys <63392527+vivek-volansys@users.noreply.github.com> 1605715292 +0530\ncommitter GitHub <noreply@github.com> 1605715292 +0530\n\nEde 198 (#7)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/cd870f6ebe88cfc1a05033551429f27fc592138c",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/cd870f6ebe88cfc1a05033551429f27fc592138c",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/cd870f6ebe88cfc1a05033551429f27fc592138c/comments",
        "author": {
          "login": "vivek-volansys",
          "id": 63392527,
          "node_id": "MDQ6VXNlcjYzMzkyNTI3",
          "avatar_url": "https://avatars0.githubusercontent.com/u/63392527?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/vivek-volansys",
          "html_url": "https://github.com/vivek-volansys",
          "followers_url": "https://api.github.com/users/vivek-volansys/followers",
          "following_url": "https://api.github.com/users/vivek-volansys/following{/other_user}",
          "gists_url": "https://api.github.com/users/vivek-volansys/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/vivek-volansys/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/vivek-volansys/subscriptions",
          "organizations_url": "https://api.github.com/users/vivek-volansys/orgs",
          "repos_url": "https://api.github.com/users/vivek-volansys/repos",
          "events_url": "https://api.github.com/users/vivek-volansys/events{/privacy}",
          "received_events_url": "https://api.github.com/users/vivek-volansys/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "96016550e39becf4fe6d218564707481e8b5ef34",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/96016550e39becf4fe6d218564707481e8b5ef34",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/96016550e39becf4fe6d218564707481e8b5ef34"
          }
        ]
      },
      {
        "sha": "8be602f5ed3d57929dc01fcf2e405325305e3be8",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OjhiZTYwMmY1ZWQzZDU3OTI5ZGMwMWZjZjJlNDA1MzI1MzA1ZTNiZTg=",
        "commit": {
          "author": {
            "name": "vivek-volansys",
            "email": "63392527+vivek-volansys@users.noreply.github.com",
            "date": "2020-11-18T16:13:21Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T16:13:21Z"
          },
          "message": "Ede 198 (#8)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>",
          "tree": {
            "sha": "8b7f00b9bfc034c8fb303176c1196dff7c8d068b",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/8b7f00b9bfc034c8fb303176c1196dff7c8d068b"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/8be602f5ed3d57929dc01fcf2e405325305e3be8",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftUghCRBK7hj4Ov3rIwAAdHIIABhxXAyySF05Gb78vztXQKFD\n4F1m8oSzI4w8au0Cpt2RH37/dueDPwauI5mCyttGZqMQq6fCQbJgvGtnUOM5FVuY\nCjplL7vE3jZFR5gkDgDaW7OWnbfBOesmDHZVlH0VVEOjAgTuvx+svqT2WgvQ62/P\nXNroGCMKH74Z1per9zyKHNP26e45fN4QirOp6Gq7AX/yTl5lwrfXoyuw7jtEmJTi\nN5AHWP6bZnArOfA3JLLZIMD8slXkdYCs0iYEU01lIGUR9xJxho61qsfaKpF7otIL\nKZo2AXcQXCYgBkQ498vSVDFfIJjcn75WKZCCFn9bI1SaPJltwNF9a+wICasmggI=\n=z3/P\n-----END PGP SIGNATURE-----\n",
            "payload": "tree 8b7f00b9bfc034c8fb303176c1196dff7c8d068b\nparent cd870f6ebe88cfc1a05033551429f27fc592138c\nauthor vivek-volansys <63392527+vivek-volansys@users.noreply.github.com> 1605716001 +0530\ncommitter GitHub <noreply@github.com> 1605716001 +0530\n\nEde 198 (#8)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/8be602f5ed3d57929dc01fcf2e405325305e3be8",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/8be602f5ed3d57929dc01fcf2e405325305e3be8",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/8be602f5ed3d57929dc01fcf2e405325305e3be8/comments",
        "author": {
          "login": "vivek-volansys",
          "id": 63392527,
          "node_id": "MDQ6VXNlcjYzMzkyNTI3",
          "avatar_url": "https://avatars0.githubusercontent.com/u/63392527?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/vivek-volansys",
          "html_url": "https://github.com/vivek-volansys",
          "followers_url": "https://api.github.com/users/vivek-volansys/followers",
          "following_url": "https://api.github.com/users/vivek-volansys/following{/other_user}",
          "gists_url": "https://api.github.com/users/vivek-volansys/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/vivek-volansys/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/vivek-volansys/subscriptions",
          "organizations_url": "https://api.github.com/users/vivek-volansys/orgs",
          "repos_url": "https://api.github.com/users/vivek-volansys/repos",
          "events_url": "https://api.github.com/users/vivek-volansys/events{/privacy}",
          "received_events_url": "https://api.github.com/users/vivek-volansys/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "cd870f6ebe88cfc1a05033551429f27fc592138c",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/cd870f6ebe88cfc1a05033551429f27fc592138c",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/cd870f6ebe88cfc1a05033551429f27fc592138c"
          }
        ]
      },
      {
        "sha": "402c108616ca6a0668ac2d0f76de174c89f166f9",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OjQwMmMxMDg2MTZjYTZhMDY2OGFjMmQwZjc2ZGUxNzRjODlmMTY2Zjk=",
        "commit": {
          "author": {
            "name": "vivek-volansys",
            "email": "63392527+vivek-volansys@users.noreply.github.com",
            "date": "2020-11-18T16:24:35Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T16:24:35Z"
          },
          "message": "Ede 198 (#9)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>",
          "tree": {
            "sha": "9a7e01294535eddc08f13136463f6724656fd61a",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/9a7e01294535eddc08f13136463f6724656fd61a"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/402c108616ca6a0668ac2d0f76de174c89f166f9",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftUrDCRBK7hj4Ov3rIwAAdHIIAI0AJvqtGaaIIRopl4VYQkje\n5BHQqwzw+chOTFRhFYnYypaxwaBXB1hVCyAI1Q7X3/ZS7uhtE+hryYPpcWo1gk5j\nTosKvd/Cc9h79RMb2nL7TM1VNCxe/ikQOX0I2n5gMviSOwZJ+XLqnFVAaKBloapU\n8WLpALhvG0haOQprE3mgr1PY3xt+Fk8t10bLrTta5sF8NvhY/q97Jn692Xubb7Sn\nRkLXryRXOOVMWE+LIMyZGStPxh2ROk2PC9Jvp9LOHNWfMdor/uT85qbWc9EQZ3op\nrgYqSWIhM8nPNzmjbiLmta8LAirgepcg4S4DiMy9Q6RXpg1Sa0nLBMc2EuSTzE0=\n=Iret\n-----END PGP SIGNATURE-----\n",
            "payload": "tree 9a7e01294535eddc08f13136463f6724656fd61a\nparent 8be602f5ed3d57929dc01fcf2e405325305e3be8\nauthor vivek-volansys <63392527+vivek-volansys@users.noreply.github.com> 1605716675 +0530\ncommitter GitHub <noreply@github.com> 1605716675 +0530\n\nEde 198 (#9)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/402c108616ca6a0668ac2d0f76de174c89f166f9",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/402c108616ca6a0668ac2d0f76de174c89f166f9",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/402c108616ca6a0668ac2d0f76de174c89f166f9/comments",
        "author": {
          "login": "vivek-volansys",
          "id": 63392527,
          "node_id": "MDQ6VXNlcjYzMzkyNTI3",
          "avatar_url": "https://avatars0.githubusercontent.com/u/63392527?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/vivek-volansys",
          "html_url": "https://github.com/vivek-volansys",
          "followers_url": "https://api.github.com/users/vivek-volansys/followers",
          "following_url": "https://api.github.com/users/vivek-volansys/following{/other_user}",
          "gists_url": "https://api.github.com/users/vivek-volansys/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/vivek-volansys/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/vivek-volansys/subscriptions",
          "organizations_url": "https://api.github.com/users/vivek-volansys/orgs",
          "repos_url": "https://api.github.com/users/vivek-volansys/repos",
          "events_url": "https://api.github.com/users/vivek-volansys/events{/privacy}",
          "received_events_url": "https://api.github.com/users/vivek-volansys/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "8be602f5ed3d57929dc01fcf2e405325305e3be8",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/8be602f5ed3d57929dc01fcf2e405325305e3be8",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/8be602f5ed3d57929dc01fcf2e405325305e3be8"
          }
        ]
      },
      {
        "sha": "49b7d207c1fd7011f0da88815bd25ebf8c8567ea",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OjQ5YjdkMjA3YzFmZDcwMTFmMGRhODg4MTViZDI1ZWJmOGM4NTY3ZWE=",
        "commit": {
          "author": {
            "name": "vivek-volansys",
            "email": "63392527+vivek-volansys@users.noreply.github.com",
            "date": "2020-11-18T16:43:39Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T16:43:39Z"
          },
          "message": "Ede 198 (#10)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Dockerfile\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>",
          "tree": {
            "sha": "0fbf3123d95be513d273a131d24c11c775aacffc",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/0fbf3123d95be513d273a131d24c11c775aacffc"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/49b7d207c1fd7011f0da88815bd25ebf8c8567ea",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftU87CRBK7hj4Ov3rIwAAdHIIAEhLHRqZo30jnT0nLFEg5G2C\neWj7sW3Ft9gjKymu/butrQov3vi09Y4YLB2kgArNwpo0O80BsOt7DJHv1Ow7dtTs\nBOuQSFf12hID7XNUdTWcbWG8AgHeGxXE3AWX1RZVzPgs+NKbl7MEhb9wWyIYsp0c\nYnVa5xVrHOtu2Za12xLHYeDnzbmbKYbBZ30UTpnMgRk36vyrVmYEFUYrtonQrxFl\nanAEhmXi6oyOboBxq0YJ9m7Dud+Y0K2z74wGmmF1FTItpnQstoAgsGNSJuGRbMNs\nPiBOBKVhrFDWivXrU3abRXcgpXB0sJhYOCzGwMy5yJ8Lao8CINgA2jjSAGEWigs=\n=BRzX\n-----END PGP SIGNATURE-----\n",
            "payload": "tree 0fbf3123d95be513d273a131d24c11c775aacffc\nparent 402c108616ca6a0668ac2d0f76de174c89f166f9\nauthor vivek-volansys <63392527+vivek-volansys@users.noreply.github.com> 1605717819 +0530\ncommitter GitHub <noreply@github.com> 1605717819 +0530\n\nEde 198 (#10)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Dockerfile\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/49b7d207c1fd7011f0da88815bd25ebf8c8567ea",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/49b7d207c1fd7011f0da88815bd25ebf8c8567ea",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/49b7d207c1fd7011f0da88815bd25ebf8c8567ea/comments",
        "author": {
          "login": "vivek-volansys",
          "id": 63392527,
          "node_id": "MDQ6VXNlcjYzMzkyNTI3",
          "avatar_url": "https://avatars0.githubusercontent.com/u/63392527?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/vivek-volansys",
          "html_url": "https://github.com/vivek-volansys",
          "followers_url": "https://api.github.com/users/vivek-volansys/followers",
          "following_url": "https://api.github.com/users/vivek-volansys/following{/other_user}",
          "gists_url": "https://api.github.com/users/vivek-volansys/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/vivek-volansys/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/vivek-volansys/subscriptions",
          "organizations_url": "https://api.github.com/users/vivek-volansys/orgs",
          "repos_url": "https://api.github.com/users/vivek-volansys/repos",
          "events_url": "https://api.github.com/users/vivek-volansys/events{/privacy}",
          "received_events_url": "https://api.github.com/users/vivek-volansys/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "402c108616ca6a0668ac2d0f76de174c89f166f9",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/402c108616ca6a0668ac2d0f76de174c89f166f9",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/402c108616ca6a0668ac2d0f76de174c89f166f9"
          }
        ]
      },
      {
        "sha": "20927a7f7c11330998c85ce85d40a57dfac2f9cc",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OjIwOTI3YTdmN2MxMTMzMDk5OGM4NWNlODVkNDBhNTdkZmFjMmY5Y2M=",
        "commit": {
          "author": {
            "name": "vivek-volansys",
            "email": "63392527+vivek-volansys@users.noreply.github.com",
            "date": "2020-11-18T16:57:15Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T16:57:15Z"
          },
          "message": "Ede 198 (#11)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Dockerfile\r\n\r\n* EDE-198: Update Submodule\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>",
          "tree": {
            "sha": "028482565c16fb6c120d9931379ba38dc85a1e04",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/028482565c16fb6c120d9931379ba38dc85a1e04"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/20927a7f7c11330998c85ce85d40a57dfac2f9cc",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftVJrCRBK7hj4Ov3rIwAAdHIIAFhaBF+Vtx0NA+5cBVSPdXwf\ninqGtnxZaR98IkprMO7l6cjWxAi7bPFvShjfcrQfxBawNccAuoY18oyR/qS0Z4Et\n89pwjluU9yPEr9IBb8xdf7P/u/TFPshs0e9VtHUPp4JyRdJH3Z7pJ5Jfa5R7dgoP\nIHzfhbNV0wKQYBlqVsTrAYjzQHI67MtRQaLQBXIGw5h2QB7ZXSQKvzaq/rIgCztw\nq8G9i7b7rBiAH6UhfeikvTOmlsGFdXE3hY6Rvi1lCkAUk81ugIsL1Nw5wr2GkcoL\nIoDWs7UrM9PIe0t1n4gcDqG20Ir3usgnQFI+JN3e1LoiFZ7M81MJbdjEOUq2kFI=\n=ULmN\n-----END PGP SIGNATURE-----\n",
            "payload": "tree 028482565c16fb6c120d9931379ba38dc85a1e04\nparent 49b7d207c1fd7011f0da88815bd25ebf8c8567ea\nauthor vivek-volansys <63392527+vivek-volansys@users.noreply.github.com> 1605718635 +0530\ncommitter GitHub <noreply@github.com> 1605718635 +0530\n\nEde 198 (#11)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Dockerfile\r\n\r\n* EDE-198: Update Submodule\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/20927a7f7c11330998c85ce85d40a57dfac2f9cc",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/20927a7f7c11330998c85ce85d40a57dfac2f9cc",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/20927a7f7c11330998c85ce85d40a57dfac2f9cc/comments",
        "author": {
          "login": "vivek-volansys",
          "id": 63392527,
          "node_id": "MDQ6VXNlcjYzMzkyNTI3",
          "avatar_url": "https://avatars0.githubusercontent.com/u/63392527?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/vivek-volansys",
          "html_url": "https://github.com/vivek-volansys",
          "followers_url": "https://api.github.com/users/vivek-volansys/followers",
          "following_url": "https://api.github.com/users/vivek-volansys/following{/other_user}",
          "gists_url": "https://api.github.com/users/vivek-volansys/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/vivek-volansys/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/vivek-volansys/subscriptions",
          "organizations_url": "https://api.github.com/users/vivek-volansys/orgs",
          "repos_url": "https://api.github.com/users/vivek-volansys/repos",
          "events_url": "https://api.github.com/users/vivek-volansys/events{/privacy}",
          "received_events_url": "https://api.github.com/users/vivek-volansys/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "49b7d207c1fd7011f0da88815bd25ebf8c8567ea",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/49b7d207c1fd7011f0da88815bd25ebf8c8567ea",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/49b7d207c1fd7011f0da88815bd25ebf8c8567ea"
          }
        ]
      },
      {
        "sha": "928b80a68c0d2c7730df09d62211142625e542a4",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OjkyOGI4MGE2OGMwZDJjNzczMGRmMDlkNjIyMTExNDI2MjVlNTQyYTQ=",
        "commit": {
          "author": {
            "name": "vivek-volansys",
            "email": "63392527+vivek-volansys@users.noreply.github.com",
            "date": "2020-11-18T17:15:22Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T17:15:22Z"
          },
          "message": "Ede 198 (#12)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Dockerfile\r\n\r\n* EDE-198: Update Submodule\r\n\r\n* EDE-196: Update App Version to 0.1.0\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>",
          "tree": {
            "sha": "e35baf4b29060bbf8e32bcb059356a66e10a2d04",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/e35baf4b29060bbf8e32bcb059356a66e10a2d04"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/928b80a68c0d2c7730df09d62211142625e542a4",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftVaqCRBK7hj4Ov3rIwAAdHIIAB6ajIAGinSERSrZUgIFLOVP\np81PDvwXx/sMpRBzsdusTA0dVFUcu0l8DULlopv3i+IPtULORCLsxvlhENAnp84j\n0vu2iBP2JIh21WCsh3IPgkuoATP8wPXatfYKenN86Zg7rLqgDlU2BQyD8JeZjwTk\nmStznEHxZfZsrsi2n+O1vtNngWfLL7T38esWWaZRfSFuybm58oyHPW6zGHwab1Io\nWRFuXMCswoJYSIiNy5Pg7jBLiNIr6LxMnNN7iT0pDtR+uHZQynH1ucfw4C2m9AFn\nfEBjX7Vg2xDLGf5aPgbPtDIMVzxCzxg5fKVZ4+MJ7MvSfdT2X4EnMGw+g/ZGQ9A=\n=Hfim\n-----END PGP SIGNATURE-----\n",
            "payload": "tree e35baf4b29060bbf8e32bcb059356a66e10a2d04\nparent 20927a7f7c11330998c85ce85d40a57dfac2f9cc\nauthor vivek-volansys <63392527+vivek-volansys@users.noreply.github.com> 1605719722 +0530\ncommitter GitHub <noreply@github.com> 1605719722 +0530\n\nEde 198 (#12)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Dockerfile\r\n\r\n* EDE-198: Update Submodule\r\n\r\n* EDE-196: Update App Version to 0.1.0\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/928b80a68c0d2c7730df09d62211142625e542a4",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/928b80a68c0d2c7730df09d62211142625e542a4",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/928b80a68c0d2c7730df09d62211142625e542a4/comments",
        "author": {
          "login": "vivek-volansys",
          "id": 63392527,
          "node_id": "MDQ6VXNlcjYzMzkyNTI3",
          "avatar_url": "https://avatars0.githubusercontent.com/u/63392527?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/vivek-volansys",
          "html_url": "https://github.com/vivek-volansys",
          "followers_url": "https://api.github.com/users/vivek-volansys/followers",
          "following_url": "https://api.github.com/users/vivek-volansys/following{/other_user}",
          "gists_url": "https://api.github.com/users/vivek-volansys/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/vivek-volansys/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/vivek-volansys/subscriptions",
          "organizations_url": "https://api.github.com/users/vivek-volansys/orgs",
          "repos_url": "https://api.github.com/users/vivek-volansys/repos",
          "events_url": "https://api.github.com/users/vivek-volansys/events{/privacy}",
          "received_events_url": "https://api.github.com/users/vivek-volansys/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "20927a7f7c11330998c85ce85d40a57dfac2f9cc",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/20927a7f7c11330998c85ce85d40a57dfac2f9cc",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/20927a7f7c11330998c85ce85d40a57dfac2f9cc"
          }
        ]
      },
      {
        "sha": "2c2aa836da0a678edb3173f50dd8e949554d3bb2",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OjJjMmFhODM2ZGEwYTY3OGVkYjMxNzNmNTBkZDhlOTQ5NTU0ZDNiYjI=",
        "commit": {
          "author": {
            "name": "vivek-volansys",
            "email": "63392527+vivek-volansys@users.noreply.github.com",
            "date": "2020-11-18T17:34:41Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-18T17:34:41Z"
          },
          "message": "Ede 198 (#13)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Dockerfile\r\n\r\n* EDE-198: Update Submodule\r\n\r\n* EDE-196: Update App Version to 0.1.0\r\n\r\n* EDE-198: ChangeLog File Added\r\n\r\n* EDE-198: Update Change Log\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>",
          "tree": {
            "sha": "635fa5a65ef6e299eba8942306d8348d1e87f36a",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/635fa5a65ef6e299eba8942306d8348d1e87f36a"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/2c2aa836da0a678edb3173f50dd8e949554d3bb2",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftVsxCRBK7hj4Ov3rIwAAdHIIAArOgojT8uilZhEdP18hhMhu\nogSJFzABYh/OiBCpzFVRU6sG8VyX7J0h5awVqSkkrAfPqSA+2KnOTBVJuQCE7Cg7\npJBThxufwOLIGE1Q2Rj4Vn3Hr5dZbLeKsGP+MIKZ42Ey+pYt/5yIef14NKu/QfBZ\ncwvBMgQzGbHZcIjjIDBMSIm6WwDiL9rkuI6+79N7R/kqAu1W3QaIDIirDhs+1iJb\nXHr8ByFZaa+sxI+nCQjy0V4yUno1mTO6D8jyb1jwrWvJgO15ccO0WiAMaYM9MXCu\nkk5tioBQUvplD3/S6/xENo7KaTEhU9fSUazNAcvnJyZtDkK0XLj1UlZNiOwMuDI=\n=aGet\n-----END PGP SIGNATURE-----\n",
            "payload": "tree 635fa5a65ef6e299eba8942306d8348d1e87f36a\nparent 928b80a68c0d2c7730df09d62211142625e542a4\nauthor vivek-volansys <63392527+vivek-volansys@users.noreply.github.com> 1605720881 +0530\ncommitter GitHub <noreply@github.com> 1605720881 +0530\n\nEde 198 (#13)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Dockerfile\r\n\r\n* EDE-198: Update Submodule\r\n\r\n* EDE-196: Update App Version to 0.1.0\r\n\r\n* EDE-198: ChangeLog File Added\r\n\r\n* EDE-198: Update Change Log\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/2c2aa836da0a678edb3173f50dd8e949554d3bb2",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/2c2aa836da0a678edb3173f50dd8e949554d3bb2",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/2c2aa836da0a678edb3173f50dd8e949554d3bb2/comments",
        "author": {
          "login": "vivek-volansys",
          "id": 63392527,
          "node_id": "MDQ6VXNlcjYzMzkyNTI3",
          "avatar_url": "https://avatars0.githubusercontent.com/u/63392527?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/vivek-volansys",
          "html_url": "https://github.com/vivek-volansys",
          "followers_url": "https://api.github.com/users/vivek-volansys/followers",
          "following_url": "https://api.github.com/users/vivek-volansys/following{/other_user}",
          "gists_url": "https://api.github.com/users/vivek-volansys/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/vivek-volansys/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/vivek-volansys/subscriptions",
          "organizations_url": "https://api.github.com/users/vivek-volansys/orgs",
          "repos_url": "https://api.github.com/users/vivek-volansys/repos",
          "events_url": "https://api.github.com/users/vivek-volansys/events{/privacy}",
          "received_events_url": "https://api.github.com/users/vivek-volansys/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "928b80a68c0d2c7730df09d62211142625e542a4",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/928b80a68c0d2c7730df09d62211142625e542a4",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/928b80a68c0d2c7730df09d62211142625e542a4"
          }
        ]
      },
      {
        "sha": "a2c05afcdf469ef4bf9605acccbe67731bddcfe9",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OmEyYzA1YWZjZGY0NjllZjRiZjk2MDVhY2NjYmU2NzczMWJkZGNmZTk=",
        "commit": {
          "author": {
            "name": "Chandani Patel",
            "email": "chandani.patel@volansystech.com",
            "date": "2020-11-19T09:17:48Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-19T09:17:48Z"
          },
          "message": "EDE-198: Update Redis Cluster Changes (#14)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Dockerfile\r\n\r\n* EDE-198: Update Submodule\r\n\r\n* version release\r\n\r\n* EDE-196: Update App Version to 0.1.0\r\n\r\n* EDE-198: ChangeLog File Added\r\n\r\n* EDE-198: Update Change Log\r\n\r\n* EDE-198: Update Redis Cluster Details\r\n\r\n* EDE-198: Update Deploymet Script for Redis Cluster Details\r\n\r\n* EDE-198: Fix Redis Cluster Connectivity Issue (#16)\r\n\r\n* EDE-198:Update redis cluster to handle moved exception\r\n\r\n* EDE-198:Update redis cluster to handle moved exception\r\n\r\n* EDE-198: uncomment redis code\r\n\r\n* EDE-198: memory and cpu updated with redis decode issue fix\r\n\r\n* EDE-198: click event of dashboard\r\n\r\nCo-authored-by: vivek.rajyaguru <vivek.rajyaguru@volansys.com>\r\nCo-authored-by: chandanipatel <chandani.patel@volansys.com>",
          "tree": {
            "sha": "dcde5c8411a661357f4b33c9f9f11b45cda91710",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/dcde5c8411a661357f4b33c9f9f11b45cda91710"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/a2c05afcdf469ef4bf9605acccbe67731bddcfe9",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJftjg8CRBK7hj4Ov3rIwAAdHIIAEhTphUI2J0L9NGNZ64lN5vf\nGwI3Qdl7u8Ygetba4Pyjx2wOOjurar9OMUWGsU/bCX/5d1tPPIMkfYJw+09uoGvk\nqotBO8Scgq0m0/kSArMOtBaZbZHNzHsVXLCDxWhVuxboCixoNsBOmeJmxShF6vyJ\n7pgCddKT75eaILvF2DKwzUs/BCdxKvfkpElbVqgPNL939nIaHHdV+EXsJFwzRrWO\nh8NJT3e67F1sqLHSdIBliElpmdOQULlOYPoO+I8BlUofwtIb7a4HUUjyAaeXCSox\nhN5ATV6kUIRj4N1+qZwOZvdZZYp6CpxvzvJPb01LsUhRwJly0GcLSCjmUlGlLHY=\n=OJqG\n-----END PGP SIGNATURE-----\n",
            "payload": "tree dcde5c8411a661357f4b33c9f9f11b45cda91710\nparent 2c2aa836da0a678edb3173f50dd8e949554d3bb2\nauthor Chandani Patel <chandani.patel@volansystech.com> 1605777468 +0530\ncommitter GitHub <noreply@github.com> 1605777468 +0530\n\nEDE-198: Update Redis Cluster Changes (#14)\n\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-198: multi page layour design, single page device connectivity graph\r\n\r\n* EDE-198:\r\n1. fix login\r\n2. multiday dashboard device connectivity\r\n\r\n* EDE-198: multiday dashboard data and redis integration\r\n\r\n* EDE-198: updated query to use day, month year conditions\r\n\r\n* EDE-198: fix for device connectivity dates sort issue\r\n\r\n* EDE-198: added pandas in the requirement.txt\r\n\r\n* EDE-198: update redis details and devops script\r\n\r\n* EDE-198: update github action\r\n\r\n* EDE-198: commented the sub graphs\r\n\r\n* EDE-198: Fix Deployent Scipt\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Deployment Script\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Requirement file\r\n\r\n* EDE-198: Update Dockerfile\r\n\r\n* EDE-198: Update Submodule\r\n\r\n* version release\r\n\r\n* EDE-196: Update App Version to 0.1.0\r\n\r\n* EDE-198: ChangeLog File Added\r\n\r\n* EDE-198: Update Change Log\r\n\r\n* EDE-198: Update Redis Cluster Details\r\n\r\n* EDE-198: Update Deploymet Script for Redis Cluster Details\r\n\r\n* EDE-198: Fix Redis Cluster Connectivity Issue (#16)\r\n\r\n* EDE-198:Update redis cluster to handle moved exception\r\n\r\n* EDE-198:Update redis cluster to handle moved exception\r\n\r\n* EDE-198: uncomment redis code\r\n\r\n* EDE-198: memory and cpu updated with redis decode issue fix\r\n\r\n* EDE-198: click event of dashboard\r\n\r\nCo-authored-by: vivek.rajyaguru <vivek.rajyaguru@volansys.com>\r\nCo-authored-by: chandanipatel <chandani.patel@volansys.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/a2c05afcdf469ef4bf9605acccbe67731bddcfe9",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/a2c05afcdf469ef4bf9605acccbe67731bddcfe9",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/a2c05afcdf469ef4bf9605acccbe67731bddcfe9/comments",
        "author": {
          "login": "chandani-patel",
          "id": 11056833,
          "node_id": "MDQ6VXNlcjExMDU2ODMz",
          "avatar_url": "https://avatars2.githubusercontent.com/u/11056833?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/chandani-patel",
          "html_url": "https://github.com/chandani-patel",
          "followers_url": "https://api.github.com/users/chandani-patel/followers",
          "following_url": "https://api.github.com/users/chandani-patel/following{/other_user}",
          "gists_url": "https://api.github.com/users/chandani-patel/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/chandani-patel/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/chandani-patel/subscriptions",
          "organizations_url": "https://api.github.com/users/chandani-patel/orgs",
          "repos_url": "https://api.github.com/users/chandani-patel/repos",
          "events_url": "https://api.github.com/users/chandani-patel/events{/privacy}",
          "received_events_url": "https://api.github.com/users/chandani-patel/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "2c2aa836da0a678edb3173f50dd8e949554d3bb2",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/2c2aa836da0a678edb3173f50dd8e949554d3bb2",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/2c2aa836da0a678edb3173f50dd8e949554d3bb2"
          }
        ]
      },
      {
        "sha": "eb26859dd183748040c139e4c179f86a00bef959",
        "node_id": "MDY6Q29tbWl0MzA2MzUzMTY1OmViMjY4NTlkZDE4Mzc0ODA0MGMxMzllNGMxNzlmODZhMDBiZWY5NTk=",
        "commit": {
          "author": {
            "name": "vivek-volansys",
            "email": "63392527+vivek-volansys@users.noreply.github.com",
            "date": "2020-11-25T12:54:29Z"
          },
          "committer": {
            "name": "GitHub",
            "email": "noreply@github.com",
            "date": "2020-11-25T12:54:29Z"
          },
          "message": "Release 0.3.0 (#20)\n\n* EDE-225 (#18)\r\n\r\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-233: Add Device List Page\r\n\r\n* EDE-233: Update QuickActions and Device Analysis View\r\n\r\n* EDE-225: device list search\r\n\r\n* EDE-225: device analysis search\r\n\r\n* EDE-225: device analysis page\r\n\r\n* EDE-225: updated admin components\r\n\r\n* EDE-225: change the git modules\r\n\r\nCo-authored-by: vivek.rajyaguru <vivek.rajyaguru@volansys.com>\r\n\r\n* EDE-240: Load Dashboard API added (#17)\r\n\r\n* EDE-240: Load Dashboard API added\r\n\r\n* EDE-240: Update SlackWebhook URL\r\n\r\n* EDE-240: Update API end point and revert the unwanted changes\r\n\r\n* EDE-226: Release 0.3.0 (#19)\r\n\r\n* EDE-240: Load Dashboard API added\r\n\r\n* EDE-240: Update SlackWebhook URL\r\n\r\n* EDE-226: Update Version.sh\r\n\r\n* EDE-226: Update Change Log for release:0.3.0\r\n\r\n* EDE-226: remove unwanted changes\r\n\r\n* EDE-226: Update Deployment Script (#21)\r\n\r\n* EDE-240: Load Dashboard API added\r\n\r\n* EDE-240: Update SlackWebhook URL\r\n\r\n* EDE-226: Update Version.sh\r\n\r\n* EDE-226: Update Change Log for release:0.3.0\r\n\r\n* EDE-226: remove unwanted changes\r\n\r\n* EDE-226: Update Stack Creation File to Add Versioner Installation\r\n\r\n* EDE-226: Update versioneer\r\n\r\n* EDE-226: Update versionner installation\r\n\r\n* EDE-226: Fix Versionner Issue\r\n\r\n* EDE-226: Update versioneer\r\n\r\n* EDE-226: Update versionner package (#22)\r\n\r\n* Ede 226 (#23)\r\n\r\n* EDE-226: Update versionner package\r\n\r\n* EDE-226: Update Version sh file for git branch\r\n\r\n* EDE-226: Update version.sh file\r\n\r\n* EDE-226: Update Version.sh file\r\n\r\n* EDE-226: Remove AWS profile\r\n\r\n* EDE-226: Update to redis cluster\r\n\r\n* EDE-226: Fix Redis Node Issue\r\n\r\n* EDE-225: Device analysis search (#24)\r\n\r\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-233: Add Device List Page\r\n\r\n* EDE-233: Update QuickActions and Device Analysis View\r\n\r\n* EDE-225: device list search\r\n\r\n* EDE-225: device analysis search\r\n\r\n* EDE-225: device analysis page\r\n\r\n* EDE-225: updated admin components\r\n\r\n* EDE-225: change the git modules\r\n\r\n* version release\r\n\r\n* version release\r\n\r\n* EDE-225: device alarm search and multi day dashboard fix\r\n\r\n* EDE-225: fixed devices has alarm search\r\n\r\nCo-authored-by: vivek.rajyaguru <vivek.rajyaguru@volansys.com>\r\n\r\n* EDE-225: comment AWS Profile (#25)\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>",
          "tree": {
            "sha": "e530e5159e892ff302f8ee7a61dd5e7eb1dc4e7e",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/trees/e530e5159e892ff302f8ee7a61dd5e7eb1dc4e7e"
          },
          "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/git/commits/eb26859dd183748040c139e4c179f86a00bef959",
          "comment_count": 0,
          "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJfvlQFCRBK7hj4Ov3rIwAAdHIIAKbiafYws6qnnX37ZnfGqboi\nltwiVq8Xvtp7rVXFGEIdKW0xT8Aze6dF9mcA26278Km+baotdT2OmNZi7ik9g9JJ\nXivS9pXVw2JdiZgBHq4GI7+5bNQXMp2HXkMoGuCuBQBiibF2vjkBfdacoGyH4Gj2\n12N4qOYQAD9/Tw5POHzPQQ5dqBM/DW2cS1BufOJhiOaEKG+UDrHr+3uzs4qqOqZN\nPJZS6rf3JUYNzzH4//42QLskbkFVTrJnmSobYOrhhotXx8fGtjyzzp0cN5wFFnyI\n1wPLRmut0sTHBGXk4eWtiEFX3Migzo+I8famkUyDVwAEMzxB6Zy+WmVULFOSZBA=\n=CtuX\n-----END PGP SIGNATURE-----\n",
            "payload": "tree e530e5159e892ff302f8ee7a61dd5e7eb1dc4e7e\nparent a2c05afcdf469ef4bf9605acccbe67731bddcfe9\nauthor vivek-volansys <63392527+vivek-volansys@users.noreply.github.com> 1606308869 +0530\ncommitter GitHub <noreply@github.com> 1606308869 +0530\n\nRelease 0.3.0 (#20)\n\n* EDE-225 (#18)\r\n\r\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-233: Add Device List Page\r\n\r\n* EDE-233: Update QuickActions and Device Analysis View\r\n\r\n* EDE-225: device list search\r\n\r\n* EDE-225: device analysis search\r\n\r\n* EDE-225: device analysis page\r\n\r\n* EDE-225: updated admin components\r\n\r\n* EDE-225: change the git modules\r\n\r\nCo-authored-by: vivek.rajyaguru <vivek.rajyaguru@volansys.com>\r\n\r\n* EDE-240: Load Dashboard API added (#17)\r\n\r\n* EDE-240: Load Dashboard API added\r\n\r\n* EDE-240: Update SlackWebhook URL\r\n\r\n* EDE-240: Update API end point and revert the unwanted changes\r\n\r\n* EDE-226: Release 0.3.0 (#19)\r\n\r\n* EDE-240: Load Dashboard API added\r\n\r\n* EDE-240: Update SlackWebhook URL\r\n\r\n* EDE-226: Update Version.sh\r\n\r\n* EDE-226: Update Change Log for release:0.3.0\r\n\r\n* EDE-226: remove unwanted changes\r\n\r\n* EDE-226: Update Deployment Script (#21)\r\n\r\n* EDE-240: Load Dashboard API added\r\n\r\n* EDE-240: Update SlackWebhook URL\r\n\r\n* EDE-226: Update Version.sh\r\n\r\n* EDE-226: Update Change Log for release:0.3.0\r\n\r\n* EDE-226: remove unwanted changes\r\n\r\n* EDE-226: Update Stack Creation File to Add Versioner Installation\r\n\r\n* EDE-226: Update versioneer\r\n\r\n* EDE-226: Update versionner installation\r\n\r\n* EDE-226: Fix Versionner Issue\r\n\r\n* EDE-226: Update versioneer\r\n\r\n* EDE-226: Update versionner package (#22)\r\n\r\n* Ede 226 (#23)\r\n\r\n* EDE-226: Update versionner package\r\n\r\n* EDE-226: Update Version sh file for git branch\r\n\r\n* EDE-226: Update version.sh file\r\n\r\n* EDE-226: Update Version.sh file\r\n\r\n* EDE-226: Remove AWS profile\r\n\r\n* EDE-226: Update to redis cluster\r\n\r\n* EDE-226: Fix Redis Node Issue\r\n\r\n* EDE-225: Device analysis search (#24)\r\n\r\n* EDE-198: single day and multi day dashboards\r\n\r\n* EDE-210: Add Github Actions and Add Devops Folder for CICD\r\n\r\n* EDE-210: Workflow Folder Added\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: add condition for Branch and env\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: fix ecr stac name\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update Service yaml and deployment file\r\n\r\n* EDE-210: Update stack creation file\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: add container port\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: update stack creation and ecs yaml file\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update service json and requirement txt to fix dependency issue\r\n\r\n* EDE-210: Update ELB DNS Mappings\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: add jq and j2 installation in elbmapping sh\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix json parsing issue\r\n\r\n* EDE-210: fix elb dns url issue\r\n\r\n* EDE-210: Update Deployment Script to have Temporary Environment\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Github Action\r\n\r\n* EDE-210: Update Event Rule Yaml File for lambda function\r\n\r\n* EDE-198: redis and sql connection\r\n\r\n* EDE-198: single page helper and url change\r\n\r\n* EDE-198:\r\n- added versioning stratagy to semver stratagy\r\n- single day dashboard\r\n\r\n* EDE-235: Implement Login Auth Flow\r\n\r\n* EDE-198:\r\n- fixed map chart reload issue\r\n- integrated map click event\r\n- integrated column pie chart for product type and alarm code\r\n\r\n* EDE-235: Update Login Flow to get user details and show to Dashboard\r\n\r\n* EDE-198: updating admin components\r\n\r\n* EDE-233: Add Device List Page\r\n\r\n* EDE-233: Update QuickActions and Device Analysis View\r\n\r\n* EDE-225: device list search\r\n\r\n* EDE-225: device analysis search\r\n\r\n* EDE-225: device analysis page\r\n\r\n* EDE-225: updated admin components\r\n\r\n* EDE-225: change the git modules\r\n\r\n* version release\r\n\r\n* version release\r\n\r\n* EDE-225: device alarm search and multi day dashboard fix\r\n\r\n* EDE-225: fixed devices has alarm search\r\n\r\nCo-authored-by: vivek.rajyaguru <vivek.rajyaguru@volansys.com>\r\n\r\n* EDE-225: comment AWS Profile (#25)\r\n\r\nCo-authored-by: Chandani Patel <chandani.patel@volansystech.com>"
          }
        },
        "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/eb26859dd183748040c139e4c179f86a00bef959",
        "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/eb26859dd183748040c139e4c179f86a00bef959",
        "comments_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/eb26859dd183748040c139e4c179f86a00bef959/comments",
        "author": {
          "login": "vivek-volansys",
          "id": 63392527,
          "node_id": "MDQ6VXNlcjYzMzkyNTI3",
          "avatar_url": "https://avatars0.githubusercontent.com/u/63392527?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/vivek-volansys",
          "html_url": "https://github.com/vivek-volansys",
          "followers_url": "https://api.github.com/users/vivek-volansys/followers",
          "following_url": "https://api.github.com/users/vivek-volansys/following{/other_user}",
          "gists_url": "https://api.github.com/users/vivek-volansys/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/vivek-volansys/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/vivek-volansys/subscriptions",
          "organizations_url": "https://api.github.com/users/vivek-volansys/orgs",
          "repos_url": "https://api.github.com/users/vivek-volansys/repos",
          "events_url": "https://api.github.com/users/vivek-volansys/events{/privacy}",
          "received_events_url": "https://api.github.com/users/vivek-volansys/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "web-flow",
          "id": 19864447,
          "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
          "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/web-flow",
          "html_url": "https://github.com/web-flow",
          "followers_url": "https://api.github.com/users/web-flow/followers",
          "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
          "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
          "organizations_url": "https://api.github.com/users/web-flow/orgs",
          "repos_url": "https://api.github.com/users/web-flow/repos",
          "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
          "received_events_url": "https://api.github.com/users/web-flow/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "a2c05afcdf469ef4bf9605acccbe67731bddcfe9",
            "url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/commits/a2c05afcdf469ef4bf9605acccbe67731bddcfe9",
            "html_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/commit/a2c05afcdf469ef4bf9605acccbe67731bddcfe9"
          }
        ]
      }
    ],
    "files": [
      {
        "sha": "dc96f17703b47435ac5dceee5e1721ca93faf203",
        "filename": ".github/workflows/rheem-ds-portal-cd.yaml",
        "status": "added",
        "additions": 83,
        "deletions": 0,
        "changes": 83,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/.github/workflows/rheem-ds-portal-cd.yaml",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/.github/workflows/rheem-ds-portal-cd.yaml",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/.github/workflows/rheem-ds-portal-cd.yaml?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,83 @@\n+name: Rheem-Ds-Portal-CD\n+\n+on:\n+  push:\n+    branches:\n+      - master\n+      - main\n+  pull_request:\n+    branches:\n+      - master\n+      - main\n+\n+jobs:\n+  deploy:\n+    runs-on: ubuntu-latest\n+    env:\n+      ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n+    steps:\n+      - name: checking repository\n+        uses: actions/checkout@v2\n+        with:\n+          token: ${{ secrets.SUB_MODULE_SECRET }}\n+          submodules: recursive\n+      - name: Load AWS Credentials\n+        uses: aws-actions/configure-aws-credentials@v1\n+        with:\n+          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n+          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n+          aws-region: us-east-1\n+      - name: Declaring variables\n+        id: vars\n+        shell: bash\n+        run: |\n+          echo \"##[set-output name=branch;]$(echo ${GITHUB_REF#refs/heads/})\"\n+          echo \"##[set-output name=prBranch;]$(echo ${{ github.head_ref }})\"\n+          echo \"##[set-output name=checkReqUrl;]$(echo ${GITHUB_REF:5:4})\"\n+      - name: Notify Deployment started slack\n+        uses: sonots/slack-notice-action@v3\n+        with:\n+          status: custom\n+          payload: |\n+            {\n+              \"attachments\": [\n+              {\n+                \"text\": '${{ steps.vars.outputs.checkReqUrl }}' == 'pull' ? ':large_blue_circle: *Deployment for Rheem-DS-Portal Started*\\n *Branch:* ${{ steps.vars.outputs.prBranch }}' : ':large_blue_circle: *Deployment for Rheem-DS-Portal Started*\\n *Branch:* ${{ steps.vars.outputs.branch }}'\n+              }\n+            ]\n+            }\n+        env:\n+          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL_TEST  }}\n+      - name: Deploy\n+        uses: skx/github-action-tester@master\n+        env:\n+          ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n+          API_TOKEN: ${{ secrets.API_TOKEN }}\n+          WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL_TEST  }}\n+        with:\n+          script: devops/stack-creation.sh\n+      - name: DNS Mapping\n+        uses: skx/github-action-tester@master\n+        with:\n+          script: devops/elb-dns-mapping.sh\n+        env:\n+          ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n+          AWS_ACCESS_KEY_ID: ${{ secrets.RHEEM_CONNECT_AWS_ACCESS_KEY_ID }}\n+          AWS_SECRET_ACCESS_KEY: ${{ secrets.RHEEM_CONNECT_AWS_SECRET_ACCESS_KEY }}\n+          AWS_ZONE_ID: ${{ secrets.AWS_ZONE_ID }}\n+      - name: Notify Deployment failure slack\n+        if: failure()\n+        uses: sonots/slack-notice-action@v3\n+        with:\n+          status: custom\n+          payload: |\n+              {\n+                \"attachments\": [\n+                  {\n+                    \"color\": \"#C9302C\",\n+                    \"text\": '${{ steps.vars.outputs.checkReqUrl }}' == 'pull' ? ':red_circle: *Deployment for Rheem-DS-Portal Failed*\\n *Branch:* ${{ steps.vars.outputs.prBranch }}\\n *Error:* https://github.com/EcoNet-Rheem/rheem-datascience-portal/actions/runs/${{ github.run_id }}' : ':red_circle: *Deployment for Rheem-DS-Portal Failed*\\n *Branch:* ${{ steps.vars.outputs.branch }}\\n *Error:* https://github.com/EcoNet-Rheem/rheem-datascience-portal/actions/runs/${{ github.run_id }}'\n+                  }\n+                ]\n+              }\n+        env:\n+          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL_TEST  }}\n\\ No newline at end of file"
      },
      {
        "sha": "4635a36d9316ce73ec89b04c03c86e66093d188a",
        "filename": ".gitignore",
        "status": "modified",
        "additions": 3,
        "deletions": 0,
        "changes": 3,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/.gitignore",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/.gitignore",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/.gitignore?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -127,3 +127,6 @@ dmypy.json\n \n # Pyre type checker\n .pyre/\n+\n+admin_components.min.js*\n+assets\n\\ No newline at end of file"
      },
      {
        "sha": "1b43f40d6441cb918546bf97d51b202ad68e8434",
        "filename": ".gitmodules",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/.gitmodules",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/.gitmodules",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/.gitmodules?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -1,3 +1,4 @@\n [submodule \"rheem_ds_admin_components\"]\n \tpath = rheem_ds_admin_components\n \turl = git@github.com:EcoNet-Rheem/rheem_ds_admin_components.git\n+\tbranch = \"main\""
      },
      {
        "sha": "7dc0fe70deb72e8570aad4852cc7919e3d83193e",
        "filename": ".versionner.rc",
        "status": "added",
        "additions": 21,
        "deletions": 0,
        "changes": 21,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/.versionner.rc",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/.versionner.rc",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/.versionner.rc?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,21 @@\n+[versionner]\n+file = ./VERSION\n+date_format = %Y-%m-%d\n+up_part = minor\n+;default_init_version = 0.1.0\n+\n+[vcs]\n+engine = git\n+commit_message = '%(version)s'\n+;tag_params =\n+;  -f\n+;  --local-user=chandani-volansys\n+\n+[file:init.py]\n+enabled = true\n+search = ^\\s*__version__\\s*=.*$\n+replace = __version__ = '%(version)s'\n+date_format = %Y-%m-%d\n+match = line\n+search_flags = \n+encoding = utf-8"
      },
      {
        "sha": "a0de6cab714be16c5ead064cd1553b95120835de",
        "filename": "CHANGELOG.md",
        "status": "added",
        "additions": 30,
        "deletions": 0,
        "changes": 30,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/CHANGELOG.md",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/CHANGELOG.md",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/CHANGELOG.md?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,30 @@\n+# Changelog\n+\n+All notable changes to this project will be documented in this file.\n+\n+## Release: 0.1.0\n+\n+### Added\n+- Prepare Dashboard with Static UI and Multipage Routing\n+- Integration of Metronic theme with Dashboard and Enhanced Charts\n+\n+## Release: 0.2.0\n+\n+### Added\n+- EDE-223: Multiple day Dashboard\n+  - Prepare the multiple page dashboard UI\n+  - Integrate Database in Dashboard\n+  - Store data in AWS as async and key in Redis to load data\n+- EDE-222: Single day Dashboard\n+  - Prepare the single dashboard UI\n+  - Integrate Database in Dashboard\n+\n+## Release: 0.3.0\n+\n+### Added\n+- EDE-240: Integrate API to Load Dashboard Into Redis\n+- EDE-225: Device Analysis View\n+  - Prepare Device Analysis page UI\n+  - Integrate Database with View\n+  - Store data in AWS as key and value in Redis to load data\n+- EDE-223: Integrate Detailed Chart View on Click of Single and Multiple Day Dashboard Charts\n\\ No newline at end of file"
      },
      {
        "sha": "213508ac8cd06ba109d3382e6317ba858d5024c6",
        "filename": "Dockerfile",
        "status": "added",
        "additions": 24,
        "deletions": 0,
        "changes": 24,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/Dockerfile",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/Dockerfile",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/Dockerfile?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,24 @@\n+FROM python:3.8.3-buster\r\n+\r\n+LABEL maintainer=\"chandani.patel@volansystech.com\"\r\n+\r\n+RUN apt-get update -y\r\n+\r\n+# We copy just the requirements.txt first to leverage Docker cache\r\n+COPY ./app/requirements.txt /app/requirements.txt\r\n+\r\n+WORKDIR /app\r\n+\r\n+RUN pip3 install -r requirements.txt\r\n+\r\n+COPY . /app\r\n+\r\n+RUN cp -r rheem_ds_admin_components/assets .\r\n+RUN cd rheem_ds_admin_components && sh build-install-python-package.sh\r\n+\r\n+\r\n+EXPOSE 8000\r\n+\r\n+ENTRYPOINT [ \"python\" ]\r\n+\r\n+CMD [ \"wsgi.py\" ]\r"
      },
      {
        "sha": "0ea3a944b399d25f7e1b8fe684d754eb8da9fe7f",
        "filename": "VERSION",
        "status": "added",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/VERSION",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/VERSION",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/VERSION?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1 @@\n+0.2.0"
      },
      {
        "sha": "89d0ffc21da142d37946182a2c3526e177e24eb5",
        "filename": "app/auth/user.py",
        "status": "added",
        "additions": 30,
        "deletions": 0,
        "changes": 30,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/auth/user.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/auth/user.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/auth/user.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,30 @@\n+import os\n+import json\n+import requests\n+from flask_login import UserMixin\n+from flask import request\n+AUTH_URL = os.environ.get('DS_AUTH_URL')\n+\n+\n+class User(UserMixin):\n+    def __init__(self, token, email, firstName, lastName):\n+        self.id = token\n+        self.email = email\n+        self.firstName = firstName\n+        self.lastName = lastName\n+\n+def get_user(token):\n+    url = AUTH_URL + \"users/validateToken\"\n+    auth_header = 'Bearer ' + token\n+    headers = {\n+        'Authorization': auth_header\n+    }\n+    response = requests.request(\"GET\", url, headers=headers, data={}, verify=False)\n+    data = response.text\n+    if 'user' in data:\n+        user = json.loads(data)['user']\n+        email = user['email']\n+        firstName = user['firstName']\n+        lastName = user['lastName']\n+        return User(token=token, email=email, firstName=firstName, lastName=lastName)\n+    return None"
      },
      {
        "sha": "0f4f501fe5a6b84599670a4c8ca2df715abe8b8a",
        "filename": "app/commons/aws_s3.py",
        "status": "added",
        "additions": 212,
        "deletions": 0,
        "changes": 212,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/aws_s3.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/aws_s3.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/aws_s3.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,212 @@\n+import boto3\n+import re\n+import time\n+import sys\n+import pandas\n+\n+from botocore.exceptions import ClientError\n+from app.commons.utill import get_env_variable\n+from datetime import datetime\n+from app.commons.log import logging\n+\n+\n+class S3Connection:\n+  __instance = None\n+  session = None\n+  PROFILE = None\n+  REGION = None\n+\n+  @staticmethod\n+  def getInstance():\n+    \"\"\" Static access method. \"\"\"\n+    if S3Connection.__instance == None:\n+      S3Connection()\n+    return S3Connection.__instance\n+\n+  def __init__(self):\n+    \"\"\" Virtually private constructor. \"\"\"\n+    if S3Connection.__instance != None:\n+      raise Exception(\"This class is a singleton!\")\n+    else:\n+      # Environment\n+      #self.PROFILE = get_env_variable('AWS_PROFILE') # for dev purpose\n+      self.REGION = get_env_variable('AWS_REGION')\n+\n+      if self.PROFILE is not None:\n+        self.session = boto3.Session(profile_name=self.PROFILE)\n+      else:\n+        self.session = boto3.Session()\n+\n+      # Connection\n+      S3Connection.__instance = self\n+\n+  def get_s3_session(self):\n+    return S3Connection.getInstance().session\n+\n+  def create_presigned_url(self, bucket_name, object_name, expiration=3600):\n+    \"\"\"Generate a presigned URL to share an S3 object\n+\n+    :param bucket_name: string\n+    :param object_name: string\n+    :param expiration: Time in seconds for the presigned URL to remain valid\n+    :return: Presigned URL as string. If error, returns None.\n+    \"\"\"\n+\n+    # Generate a presigned URL for the S3 object\n+    s3_client = self.session.client('s3')\n+    try:\n+      logging.info('fetching data from : '+bucket_name + '/' +object_name)\n+      response = s3_client.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': object_name}, ExpiresIn=expiration)\n+    except ClientError as e:\n+      logging.error('Error while creating presigned ', e)\n+      return None\n+\n+    return response\n+\n+  def get_athena_output_file_path(self, type):\n+    today = datetime.now()\n+    timestamp = str(today.year) + '-' + str(today.month) + '-' + str(today.day) + '-'+ \\\n+        str(today.hour) + '-' + str(today.minute) + '-' + str(today.second) + '-' + str(today.microsecond)\n+    if type == 'dashboard':\n+      return 'output/data/dashboard/{}/'.format(timestamp)\n+    elif type == 'histogram' or type == 'timeseries_econet_object':\n+      return 'output/data/econet_object_names/{}/'.format(timestamp)\n+    elif type == 'timeseries':\n+      return 'output/data/timeseries//{}/'.format(timestamp)\n+    elif type == 'download_data':\n+      return 'download_data/data/{}/'.format(timestamp)\n+    elif type == 'download_data_preview':\n+      return 'output/data/{}/'.format(timestamp)\n+    elif type == 'device_list_alarm_codes':\n+      return 'output/data/device_list_alarm_codes/{}/'.format(timestamp)\n+    else:\n+      return ''\n+\n+  def execute_athena_query(self, query, page, database, store_data=False, return_df=False, max_execution = 50):\n+    path = self.get_athena_output_file_path(page)\n+\n+    if database is None:\n+      database = get_env_variable('AWS_ATHENA_DATABASE')\n+\n+    bucket = get_env_variable('TEMP_BUCKET')\n+\n+    if store_data is True:\n+      bucket = get_env_variable('LONG_TERM_BUCKET')\n+    file_name = self.athena_to_s3(query, path, database, bucket, max_execution)\n+\n+    if file_name is None:\n+      return None\n+\n+    if store_data == True:\n+      # Store data in redis\n+      logging.info('Storing data for quick retrival')\n+\n+    data = self.get_s3_bucket_details(bucket, file_name)\n+\n+    if return_df:\n+      dataframe = pandas.read_csv(data)\n+      return dataframe\n+    else:\n+      return data\n+\n+  def athena_query(self, query, client, database, bucket, path):\n+    \"\"\"Execute Athena query\n+\n+    :param query: query to execute\n+    :param database: athena database\n+    :param bucket: bucket name to get object from\n+    :param path: path to get object\n+    :return: Presigned URL as string. If error, returns None.\n+    \"\"\"\n+    response = client.start_query_execution(\n+        QueryString=query,\n+        QueryExecutionContext={\n+            'Database': database\n+        },\n+        ResultConfiguration={\n+            'OutputLocation': 's3://' + bucket + '/' + path\n+        }\n+    )\n+    return response\n+\n+  def get_s3_bucket_details(self, bucket, path):\n+    \"\"\"get s3 object\n+\n+    :param bucket: bucket name to get object from\n+    :param path: path to get object\n+    :return: Presigned URL as string. If error, returns None.\n+    \"\"\"\n+    response = self.session.client('s3').get_object(Bucket=bucket, Key=path)\n+    return response['Body']\n+\n+  def athena_to_s3(self, query, path, database, bucket, max_execution = 10):\n+    \"\"\"Execute Athena query and store result to s3\n+\n+    :param query: query to execute\n+    :param path: path to get object\n+    :param database: athena database\n+    :param bucket: bucket name to get object from\n+    :param max_execution: execution to retry the execution\n+    :return: Presigned URL as string. If error, returns None.\n+    \"\"\"\n+    client = self.session.client('athena', region_name=self.REGION)\n+    execution = self.athena_query(query, client, database, bucket, path)\n+    execution_id = execution['QueryExecutionId']\n+    state = 'RUNNING'\n+    while (max_execution > 0 and state in ['RUNNING', 'QUEUED']):\n+      max_execution = max_execution - 1\n+      response = client.get_query_execution(QueryExecutionId = execution_id)\n+      if 'QueryExecution' in response and \\\n+          'Status' in response['QueryExecution'] and \\\n+          'State' in response['QueryExecution']['Status']:\n+        state = response['QueryExecution']['Status']['State']\n+        if state == 'FAILED':\n+          return False\n+        elif state == 'SUCCEEDED':\n+          s3_path = response['QueryExecution']['ResultConfiguration']['OutputLocation']\n+          filename = re.findall('.*\\/(.*)', s3_path)[0]\n+          return filename\n+      time.sleep(1)\n+\n+    return False\n+\n+\n+  def get_athena_query_result(self, query, path, database, bucket, max_execution = 10, nextToken = None, execution_id = None):\n+    client = self.session.client('athena', region_name=self.REGION)\n+    if nextToken is None and execution_id is None:\n+      execution = self.athena_query(query, client, database, bucket, path)\n+      execution_id = execution['QueryExecutionId']\n+\n+      state = 'RUNNING'\n+      logging.info(query)\n+      while (max_execution > 0 and state in ['RUNNING', 'QUEUED']):\n+          max_execution = max_execution - 1\n+          response = client.get_query_execution(QueryExecutionId = execution_id)\n+          if 'QueryExecution' in response and \\\n+                  'Status' in response['QueryExecution'] and \\\n+                  'State' in response['QueryExecution']['Status']:\n+              state = response['QueryExecution']['Status']['State']\n+              if state == 'FAILED':\n+                  return False\n+              elif state == 'SUCCEEDED':\n+                  resp = client.get_query_results(\n+                    QueryExecutionId=execution_id,\n+                    MaxResults=15\n+                  )\n+                  return {\"response\": resp, \"execution_id\": execution_id}\n+          time.sleep(1)\n+\n+      return False\n+    elif nextToken is None and execution_id is not None:\n+      resp = client.get_query_results(\n+        QueryExecutionId=execution_id,\n+        MaxResults=15\n+      )\n+      return {\"response\": resp, \"execution_id\": execution_id}\n+    else:\n+      resp = client.get_query_results(\n+        QueryExecutionId=execution_id,\n+        NextToken=nextToken,\n+        MaxResults=15\n+      )\n+      return {\"response\": resp, \"execution_id\": execution_id}"
      },
      {
        "sha": "445995407b66cf262047d1895a50fdcd1181d0c5",
        "filename": "app/commons/dao/athena/alarms.py",
        "status": "added",
        "additions": 61,
        "deletions": 0,
        "changes": 61,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/athena/alarms.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/athena/alarms.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/athena/alarms.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,61 @@\n+\n+from app.commons.aws_s3 import S3Connection\n+from app.commons.utill import get_search_rages, get_search_conditions\n+from app.commons.log import logging\n+from datetime import datetime, timedelta\n+\n+NAME = str(__name__)\n+\n+def get_alarm_by_location_day(date, level):\n+  query = \"SELECT * from alarm_by_location WHERE year = {0} AND month = {1} AND day = {2} AND level like '{3}'\".format(date.year, date.month, date.day, level)\n+  logging.debug('%s: query: [%s]', NAME, query)\n+\n+  dataframe = S3Connection.getInstance().execute_athena_query(query, 'single_day_dashboard', None, None, True)\n+  return dataframe\n+\n+def get_alarm_history_distict_mac(start_date, end_date, level):\n+  query = \"\"\n+  if start_date.year == end_date.year and start_date.month == end_date.month:\n+    _, days, _ = get_search_rages(start_date, end_date)\n+    query = \"SELECT count(distinct mac_address) as count, product_type, day, month, year, state, alarm_code FROM alarm_history WHERE year = {0} AND month = {1} AND day in ({2}) AND level like '{3}' GROUP BY product_type, day, month, year, state, alarm_code\".format(start_date.year, start_date.month, ','.join(days), level)\n+  else:\n+    query = \"SELECT count(distinct mac_address) as count, product_type, day, month, year, state, alarm_code FROM alarm_history WHERE level like '{0}'\".format(level)\n+    where_conditions = get_search_conditions(start_date, end_date)\n+    if len(where_conditions) > 0:\n+      query = query + ' AND (' + ' OR '.join(where_conditions) + ')'\n+    query = query + ' GROUP BY product_type, day, month, year, state, alarm_code'\n+  \n+  logging.debug('%s: query: [%s]', NAME, query)\n+\n+  dataframe = S3Connection.getInstance().execute_athena_query(query, 'single_day_dashboard', None, None, True)\n+  return dataframe\n+\n+def get_alarm_history_distict_devices(start_date, end_date, level, alarm_code=None, locations=None, product_type= None):\n+  query = \"SELECT a.product_type, a.mac_address, a.alarm_code, COUNT(a.alarm_code) as count, state FROM (SELECT mac_address, alarm_code, product_type, state FROM alarm_history WHERE level like '{0}'\".format(level)\n+\n+  if alarm_code is not None and len(alarm_code) > 1:\n+    query = query + \" AND alarm_code in '{0}'\".format(','.join(alarm_code))\n+  elif alarm_code is not None and len(alarm_code) == 1:\n+    query = query + \" AND alarm_code = '{0}'\".format(alarm_code[0])\n+\n+  if locations is not None and len(locations) > 1:\n+    query = query + \" AND state in '{0}'\".format(','.join(locations))\n+  elif locations is not None and len(locations) == 1:\n+    query = query + \" AND state = '{0}'\".format(locations[0])\n+  \n+  if product_type is not None:\n+    query = query + \" AND product_type = '{0}'\".format(product_type)\n+\n+  if start_date.year == end_date.year and start_date.month == end_date.month:\n+    _, days, _ = get_search_rages(start_date, end_date)\n+    query = query + \" AND year = {0} AND month = {1} AND day in ({2})) a GROUP BY mac_address, alarm_code, product_type, state\".format(start_date.year, start_date.month, ','.join(days))\n+  else:\n+    where_conditions = get_search_conditions(start_date, end_date)\n+    if len(where_conditions) > 0:\n+      query = query + ' AND (' + ' OR '.join(where_conditions) + ')'\n+    query = query + ') a GROUP BY mac_address, alarm_code, product_type, state'\n+  \n+  logging.debug('%s: query: [%s]', NAME, query)\n+\n+  dataframe = S3Connection.getInstance().execute_athena_query(query, 'device_analysis', None, None, True)\n+  return dataframe\n\\ No newline at end of file"
      },
      {
        "sha": "1f90e722f173ec20cac1f7c7dd0f5a7ce64d5ab4",
        "filename": "app/commons/dao/athena/device_connectivity.py",
        "status": "added",
        "additions": 60,
        "deletions": 0,
        "changes": 60,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/athena/device_connectivity.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/athena/device_connectivity.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/athena/device_connectivity.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,60 @@\n+from datetime import datetime, timedelta\n+from app.commons.aws_s3 import S3Connection\n+from app.commons.utill import get_search_conditions\n+from app.commons.log import logging\n+\n+import pandas\n+\n+NAME = str(__name__)\n+\n+def query_device_connectivity_dashboard(start_date, end_date):\n+  if end_date is None: # single day dashboard\n+    end_date = start_date\n+    start_date = end_date - timedelta(days=7)  \n+\n+  query = \"select mac_address, connected_time, disconnected_time, day, month, year, product_type from device_connectivity \"\n+\n+  where_conditions = get_search_conditions(start_date, end_date)\n+  if len(where_conditions) > 0:\n+    query = query + 'WHERE (' + ' OR '.join(where_conditions) + ')'\n+\n+  logging.debug('%s: query: [%s]', NAME, query)\n+\n+  return query\n+\n+def calculate_range(x):\n+  t = x['connected_percentage'] % 20\n+  start = x['connected_percentage'] - t + 1 if x['connected_percentage'] < 100 else 81\n+  end = 19 + start if x['connected_percentage'] < 100 else 100\n+  return str(start)+'%-'+str(end)+'%'\n+\n+def get_device_connectivity_dashboard(start_date, end_date):\n+  query = query_device_connectivity_dashboard(start_date, end_date)\n+\n+  logging.debug('%s: query: [%s]', NAME, query)\n+  connectivity_details_df = S3Connection.getInstance().execute_athena_query(query, 'device_connectivity_single_day_dashboard', None, None, True)\n+\n+  if not connectivity_details_df.empty:\n+    connectivity_details_df['process_date'] = connectivity_details_df['year'].astype(str)+'-'+connectivity_details_df['month'].astype(str)+'-'+connectivity_details_df['day'].astype(str)\n+    connectivity_details_df = connectivity_details_df.groupby(['process_date', 'mac_address', 'product_type'], as_index=False)\\\n+      .agg({'connected_time': 'sum', 'disconnected_time': 'sum'})\n+    connectivity_details_df['total_time'] = connectivity_details_df['connected_time'] + connectivity_details_df['disconnected_time']\n+    connectivity_details_df['connected_percentage'] = connectivity_details_df['connected_time'] * 100 / connectivity_details_df['total_time']\n+    connectivity_details_df['connected_percentage'] = connectivity_details_df['connected_percentage'].fillna(0).map(int)\n+    connectivity_details_df['connection_range'] = connectivity_details_df.apply(calculate_range, axis=1)\n+        \n+    connectivity_data = connectivity_details_df.groupby(['process_date','connection_range'], as_index=False).agg({'mac_address': 'count'})\n+    connectivity_data['date'] = pandas.to_datetime(connectivity_data['process_date'], format='%Y-%m-%d')\n+    connectivity_data = connectivity_data.sort_values(by=['date'])\n+    dates = connectivity_data['process_date'].unique().tolist()\n+\n+    connectivity_data = connectivity_data.groupby(['connection_range'])\n+\n+    data = []\n+    for name,group in connectivity_data:\n+      obj = {'name': name, 'data': group['mac_address'].tolist()}\n+      data.append(obj)\n+    \n+    return dates, data, connectivity_details_df[['mac_address', 'process_date', 'connection_range', 'product_type']]\n+\n+  return None, None, None"
      },
      {
        "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
        "filename": "app/commons/dao/athena/device_history.py",
        "status": "added",
        "additions": 0,
        "deletions": 0,
        "changes": 0,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/athena/device_history.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/athena/device_history.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/athena/device_history.py?ref=eb26859dd183748040c139e4c179f86a00bef959"
      },
      {
        "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
        "filename": "app/commons/dao/athena/timeseries.py",
        "status": "added",
        "additions": 0,
        "deletions": 0,
        "changes": 0,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/athena/timeseries.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/athena/timeseries.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/athena/timeseries.py?ref=eb26859dd183748040c139e4c179f86a00bef959"
      },
      {
        "sha": "c5d04bd076fec6dce094ffe40d0405d5a9cf10e9",
        "filename": "app/commons/dao/db_connection.py",
        "status": "added",
        "additions": 46,
        "deletions": 0,
        "changes": 46,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/db_connection.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/db_connection.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/db_connection.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,46 @@\n+import redis\n+from rediscluster import RedisCluster\n+import psycopg2\n+import psycopg2.extras\n+import pandas\n+import pandas.io.sql as sqlio\n+\n+from app.commons.log import logging\n+from app.commons.utill import get_env_variable\n+NAME = str(__name__)\n+\n+REDIS_HOST = get_env_variable('REDIS_HOST')\n+REDIS_PORT = get_env_variable('REDIS_PORT')\n+\n+redis_store = None\n+if REDIS_HOST is not None or REDIS_PORT is None:\n+  try:\n+    logging.info('%s: Connecting Redis %s:%d', NAME, REDIS_HOST, int(REDIS_PORT))\n+    nodes=[{\"host\": REDIS_HOST, \"port\": REDIS_PORT}]\n+    redis_store = RedisCluster(startup_nodes=nodes, skip_full_coverage_check=True)\n+    # redis_store = redis.Redis(host=REDIS_HOST, port=REDIS_PORT)\n+    # Redic.Redis doesn't throw error on connection unavailability, So checking by setting temp key\n+    redis_store.set('econet_production_test', 2)\n+    logging.info('%s: Redis connected', NAME)\n+  except Exception as ex:\n+    logging.error('%s: Error while Connecting Redis %s', NAME, ''.join(ex.args) )\n+\n+postgres_url=get_env_variable('postgres_url')\n+postgres_port=get_env_variable('postgres_port')\n+postgres_user=get_env_variable('postgres_user')\n+postgres_schema=get_env_variable('postgres_schema')\n+postgres_password=get_env_variable('postgres_password')\n+postgres_db=get_env_variable('postgres_db')\n+\n+postgres_conn = None\n+postgres_cursor = None\n+try:\n+  logging.info('%s: Connecting PostgreSQL url:%s, port: %s, user: %s, schema: %s', NAME, postgres_url, postgres_port, postgres_user, postgres_schema)\n+  postgres_conn = psycopg2.connect(\"dbname='{0}' user='{1}' host='{2}' password='{3}'\".format(postgres_db, postgres_user, postgres_url, postgres_password))\n+  postgres_cursor = postgres_conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n+  logging.info('%s: updating schema to %s', NAME, postgres_schema)\n+  postgres_cursor.execute('SET search_path TO ' + postgres_schema)\n+  logging.info('%s: PostgreSQL connected', NAME)\n+  \n+except Exception as ex:\n+  logging.error('%s: Error while Connecting PostgreSQL %s', NAME, ''.join(ex.args) )"
      },
      {
        "sha": "95c5f6d17482fd6495790e8ee605a38c29cbe4b6",
        "filename": "app/commons/dao/redis/base_dao.py",
        "status": "added",
        "additions": 26,
        "deletions": 0,
        "changes": 26,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/redis/base_dao.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/redis/base_dao.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/redis/base_dao.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,26 @@\n+from app.commons.dao.db_connection import redis_store\n+from app.commons.log import logging\n+\n+import json\n+\n+def get(key):\n+  if redis_store is None:\n+    logging.error('Redis connection is not established')\n+    return None\n+\n+  obj = redis_store.get(key)  \n+  if obj is not None:\n+    obj = obj.decode('utf8').replace(\"'\", '\"')\n+    return json.loads(obj)\n+  return None\n+\n+def set(key, obj, ex):\n+  if redis_store is None:\n+    logging.error('Redis connection is not established')\n+    return\n+\n+  value = json.dumps(obj)\n+  if ex is None:\n+    redis_store.set(key, value, ex=ex)\n+  else:\n+    redis_store.set(key, value)\n\\ No newline at end of file"
      },
      {
        "sha": "19dd362dce7650fb58a2aa4ac5401aab1dc15d28",
        "filename": "app/commons/dao/redis/dashboad_data.py",
        "status": "added",
        "additions": 58,
        "deletions": 0,
        "changes": 58,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/redis/dashboad_data.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/redis/dashboad_data.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/redis/dashboad_data.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,58 @@\n+import json\n+\n+from app.commons.log import logging\n+from app.commons.dao.redis.base_dao import get, set\n+\n+NAMESPACE = 'dashboard'\n+\n+SINGLE_DAY_EXPIRY_SECONDS = 30 * 24 * 60 * 60 # 1 month\n+\n+MULTI_DAY_EXPIRY_SECONDS = 3 * 60 * 60 # 3 hours\n+\n+def store_single_day_dashboard_data(obj, date, expiry_time):\n+  key = NAMESPACE + '_' + date.strftime('%Y_%m_%d')\n+  set(key, obj, ex=expiry_time)\n+\n+def store_single_day_dashboard_connectivity_data(obj, date, expiry_time):\n+  key = NAMESPACE + '_connectivity_' + date.strftime('%Y_%m_%d')\n+  set(key, obj, ex=expiry_time)\n+\n+def store_single_day_dashboard_alarm_data(obj, date, expiry_time):\n+  key = NAMESPACE + '_alarm_' + date.strftime('%Y_%m_%d')\n+  set(key, obj, ex=expiry_time)\n+\n+def store_multiple_day_dashboard_data(obj, start_date, end_date, expiry_time):\n+  key = NAMESPACE + '_' + start_date.strftime('%Y_%m_%d') + '_' + end_date.strftime('%Y_%m_%d')\n+  set(key, obj, ex=expiry_time)\n+\n+def store_multi_day_dashboard_connectivity_data(obj, start_date, end_date, expiry_time):\n+  key = NAMESPACE + '_connectivity_' + start_date.strftime('%Y_%m_%d') + '_' + end_date.strftime('%Y_%m_%d')\n+  set(key, obj, ex=expiry_time)\n+\n+def store_multi_day_dashboard_alarm_data(obj, start_date, end_date, expiry_time):\n+  key = NAMESPACE + '_alarm_' + start_date.strftime('%Y_%m_%d') + '_' + end_date.strftime('%Y_%m_%d')\n+  set(key, obj, ex=expiry_time)\n+\n+def single_day_dashboard_data(date):\n+  key = NAMESPACE + '_' + date.strftime('%Y_%m_%d')\n+  return get(key)\n+\n+def single_day_dashboard_connectivity_data(date):\n+  key = NAMESPACE + '_connectivity_' + date.strftime('%Y_%m_%d')\n+  return get(key)\n+\n+def single_day_dashboard_alarm_data(date):\n+  key = NAMESPACE + '_alarm_' + date.strftime('%Y_%m_%d')\n+  return get(key)\n+\n+def multi_day_dashboard_data(start_date, end_date):\n+  key = NAMESPACE + '_' + start_date.strftime('%Y_%m_%d') + '_' + end_date.strftime('%Y_%m_%d')\n+  return get(key)\n+\n+def multi_day_dashboard_connectivity_data(start_date, end_date):\n+  key = NAMESPACE + '_connectivity_' + start_date.strftime('%Y_%m_%d') + '_' + end_date.strftime('%Y_%m_%d')\n+  return get(key)\n+\n+def multi_day_dashboard_alarm_data(start_date, end_date):\n+  key = NAMESPACE + '_alarm_' + start_date.strftime('%Y_%m_%d') + '_' + end_date.strftime('%Y_%m_%d')\n+  return get(key)"
      },
      {
        "sha": "fbeb2a5f9d6c26a8bce5bb9627010bef429a2c80",
        "filename": "app/commons/dao/sql/alerts.py",
        "status": "added",
        "additions": 20,
        "deletions": 0,
        "changes": 20,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/sql/alerts.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/sql/alerts.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/sql/alerts.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,20 @@\n+from app.commons.dao.db_connection import postgres_cursor\n+from app.commons.log import logging\n+from app.commons.json_encoder import DecimalEncoder\n+import json\n+import pandas\n+\n+NAME = str(__name__)\n+TABLE_NAME = 'alerts'\n+\n+def get_all_alerts(return_df=False):\n+  query = \"\"\"select * from {table_name}\"\"\".format(table_name=TABLE_NAME)\n+  logging.debug('%s: query: [%s]', NAME, query)\n+  postgres_cursor.execute(query)\n+  rows = postgres_cursor.fetchall()\n+  alerts = json.dumps(rows, cls=DecimalEncoder)\n+  if return_df == False:\n+    return alerts\n+  else:\n+    df = pandas.read_json(alerts)\n+    return df\n\\ No newline at end of file"
      },
      {
        "sha": "17067cbe415919710b168be4541acee253f4e2fc",
        "filename": "app/commons/dao/sql/daily_processed_devices.py",
        "status": "added",
        "additions": 45,
        "deletions": 0,
        "changes": 45,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/sql/daily_processed_devices.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/sql/daily_processed_devices.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/sql/daily_processed_devices.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,45 @@\n+from app.commons.dao.db_connection import postgres_cursor\n+from app.commons.log import logging\n+from app.commons.utill import get_search_dates\n+\n+import json\n+\n+TABLE_NAME = 'daily_processed_devices'\n+NAME = str(__name__)\n+\n+def get_count_single_day(date):\n+  query = \"\"\"select type, count from {table_name} where process_date='{process_date}'\"\"\".format(table_name=TABLE_NAME, process_date=date.strftime('%Y-%m-%d'))\n+  logging.debug('%s: query: [%s]', NAME, query)\n+  postgres_cursor.execute(query)\n+  print(postgres_cursor.statusmessage)\n+  rows = postgres_cursor.fetchall()\n+  total_count = 0\n+  new_count = 0\n+  if rows is not None:\n+    for row in rows:\n+      if row['type'] == 'TOTAL_DEVICES':\n+        total_count = row['count']\n+      elif row['type'] == 'NEW_DEVICES':\n+        new_count = row['count']  \n+  return total_count, new_count\n+\n+def get_count_multi_day(start_date, end_date):\n+  dates = get_search_dates(start_date, end_date)\n+  query = \"\"\"select type, count, process_date from {table_name} where process_date in ({process_dates})\"\"\".format(table_name=TABLE_NAME, process_dates=','.join('\\'{0}\\''.format(dt) for dt in dates))\n+  logging.debug('%s: query: [%s]', NAME, query)\n+  postgres_cursor.execute(query)\n+  rows = postgres_cursor.fetchall()\n+  processed_devices_counts = []\n+  new_devices_counts = []\n+  new_devices_dates = []\n+  processed_devices_dates = []\n+  if rows is not None:\n+    for row in rows:\n+      if row['type'] == 'TOTAL_DEVICES':\n+        processed_devices_dates.append(row['process_date'].strftime('%Y-%m-%d'))\n+        processed_devices_counts.append(row['count'])\n+      elif row['type'] == 'NEW_DEVICES':\n+        new_devices_dates.append(row['process_date'].strftime('%Y-%m-%d'))\n+        new_devices_counts.append(row['count'])\n+  \n+  return processed_devices_counts, processed_devices_dates, new_devices_counts, new_devices_dates"
      },
      {
        "sha": "827ba5764767c0fcf878fdc6ed239bd428404239",
        "filename": "app/commons/dao/sql/device_alarms.py",
        "status": "added",
        "additions": 27,
        "deletions": 0,
        "changes": 27,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/sql/device_alarms.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/sql/device_alarms.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/sql/device_alarms.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,27 @@\n+from app.commons.dao.db_connection import postgres_cursor\n+from app.commons.log import logging\n+from app.commons.json_encoder import DecimalEncoder\n+import json\n+\n+ALARM_LEVELS = {\n+  1: 'Critical',\n+  2: 'Alert',\n+  3: 'Message',\n+  4: 'Warning'\n+}\n+\n+ALARM_DROP_DOWN_VALUES=[\n+  {'label':'Critical', 'value':1},\n+  {'label':'Alert', 'value':2},\n+  {'label':'Message', 'value':3},\n+  {'label':'Warning', 'value':4}\n+]\n+\n+NAME = str(__name__)\n+TABLE_NAME = 'devices_alarms'\n+def get_devices_alarms(date, level):\n+  query = \"\"\"select product_type, level, sum(count) as count from {table_name} where level like '{level}' and year={year} and day={day} and month={month} group by product_type, level\"\"\".format(level = level, year = date.year, month = date.month, day = date.day, table_name=TABLE_NAME)\n+  logging.debug('%s: query: [%s]', NAME, query)\n+  postgres_cursor.execute(query)\n+  rows = postgres_cursor.fetchall()\n+  return json.dumps(rows, cls=DecimalEncoder)\n\\ No newline at end of file"
      },
      {
        "sha": "65b3821c90cec26efb6934384ee12c036e40d055",
        "filename": "app/commons/dao/sql/locations.py",
        "status": "added",
        "additions": 20,
        "deletions": 0,
        "changes": 20,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/sql/locations.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/sql/locations.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/sql/locations.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,20 @@\n+from app.commons.dao.db_connection import postgres_cursor\n+from app.commons.log import logging\n+from app.commons.json_encoder import DecimalEncoder\n+import json\n+import pandas\n+\n+NAME = str(__name__)\n+TABLE_NAME = 'locations_helper'\n+\n+def get_unique_states(return_df=False):\n+  query = \"\"\"select DISTINCT state from {table_name}\"\"\".format(table_name=TABLE_NAME)\n+  logging.debug('%s: query: [%s]', NAME, query)\n+  postgres_cursor.execute(query)\n+  rows = postgres_cursor.fetchall()\n+  locations = json.dumps(rows, cls=DecimalEncoder)\n+  if return_df == False:\n+    return locations\n+  else:\n+    df = pandas.read_json(locations)\n+    return df\n\\ No newline at end of file"
      },
      {
        "sha": "bd66ac2bfeaf28bef4fe4b7b64d03c560664fa6c",
        "filename": "app/commons/dao/sql/product_codes.py",
        "status": "added",
        "additions": 13,
        "deletions": 0,
        "changes": 13,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/sql/product_codes.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dao/sql/product_codes.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dao/sql/product_codes.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,13 @@\n+from app.commons.dao.db_connection import postgres_cursor\n+from app.commons.log import logging\n+from app.commons.json_encoder import DecimalEncoder\n+import json\n+\n+NAME = str(__name__)\n+TABLE_NAME = 'product_codes'\n+def get_product_types():\n+  query = \"\"\"select product_type as value, CONCAT(product_type, ' | ', code) as label  from {table_name} where product_type is not NULL \"\"\".format(table_name=TABLE_NAME)\n+  logging.debug('%s: query: [%s]', NAME, query)\n+  postgres_cursor.execute(query)\n+  rows = postgres_cursor.fetchall()\n+  return json.loads(json.dumps(rows, cls=DecimalEncoder))\n\\ No newline at end of file"
      },
      {
        "sha": "46868e63a58453f39a7277a8e496c60dcdb3f5c5",
        "filename": "app/commons/dashboard_helper.py",
        "status": "added",
        "additions": 209,
        "deletions": 0,
        "changes": 209,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dashboard_helper.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/dashboard_helper.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/dashboard_helper.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,209 @@\n+from app.commons.dao.sql.device_alarms import get_devices_alarms, ALARM_LEVELS\n+from app.commons.dao.sql.daily_processed_devices import get_count_single_day, get_count_multi_day\n+from app.commons.dao.athena import alarms\n+from app.commons.utill import map_df, map_data\n+from app.commons.aws_s3 import S3Connection\n+from app.commons.dao.athena import device_connectivity\n+from datetime import datetime, timedelta\n+from  app.commons.dao.redis import dashboad_data\n+\n+import dash_html_components as html\n+import admin_components\n+import pandas\n+import json\n+\n+NAME = str(__name__)\n+\n+def get_single_day_dashboard_data(date, compare_date, expiry_time=dashboad_data.SINGLE_DAY_EXPIRY_SECONDS):\n+  # Get crtitical alarms\n+  obj = dashboad_data.single_day_dashboard_data(date)\n+  if obj is not None:\n+    return obj\n+\n+  critical_alarm_data_a_day_before = get_devices_alarms(compare_date, ALARM_LEVELS.get(1, '%'))\n+  processed_devices, new_devices = get_count_single_day(date)\n+  processed_devices_day_before, new_devices_day_before =  get_count_single_day(date)\n+\n+  alarm_df = alarms.get_alarm_history_distict_mac(date, date, ALARM_LEVELS.get(1, '%'))\n+  total_alarm_count = alarm_df.agg({'count': 'sum'})\n+  if not total_alarm_count.empty:\n+    total_alarm_count = int(total_alarm_count['count'])\n+  location_alarm_data = pandas.DataFrame.from_dict(map_data)\n+  product_type_alarm_data = alarm_df.groupby(['product_type'], as_index=False).agg({'count': 'sum'})\n+\n+  if not alarm_df.empty:\n+    dashboad_data.store_single_day_dashboard_alarm_data(alarm_df.to_dict(orient='records'), date, expiry_time)\n+    location_alarm_data = alarm_df.groupby(['state'], as_index=False).agg({'count': 'sum'})\n+    location_alarm_data['state'] = 'US-' + location_alarm_data['state'].astype(str)\n+    location_alarm_data = location_alarm_data.rename(columns={\"state\": \"id\", \"count\": \"value\"})\n+    temp_merged = location_alarm_data.merge(map_df, indicator=True, how='outer')\n+    location_alarm_data = temp_merged.groupby(['id'], as_index=False).agg({'value': \"sum\"})\n+\n+  connectivity_dates, connectivity_data, connectivity_df = device_connectivity.get_device_connectivity_dashboard(date, None)\n+\n+  dashboad_data.store_single_day_dashboard_connectivity_data(connectivity_df.to_dict(orient='records'), date, expiry_time)\n+\n+  json_object = {\n+    'alarm_count': total_alarm_count,\n+    'alarm_a_day_before': critical_alarm_data_a_day_before,\n+    'processed_devices_count': processed_devices,\n+    'new_devices_count': new_devices,\n+    'processed_devices_count_day_before': processed_devices_day_before,\n+    'new_devices_count_day_before': new_devices_day_before,\n+    'alarm_by_product_code': product_type_alarm_data.to_json(orient=\"records\"),\n+    'alarm_by_state': location_alarm_data.to_dict(orient='records'),\n+    'connectivity_dates': connectivity_dates,\n+    'connectivity_data': connectivity_data\n+  }\n+\n+  dashboad_data.store_single_day_dashboard_data(json_object, date, expiry_time)\n+  return json_object\n+\n+def get_multi_day_dashboard_data(start_date, end_date, expiry_time=dashboad_data.MULTI_DAY_EXPIRY_SECONDS):\n+\n+  redis_store_obj = dashboad_data.multi_day_dashboard_data(start_date, end_date)\n+\n+  if redis_store_obj is not None:\n+    return redis_store_obj\n+  # Get crtitical alarms\n+  alarm_df = alarms.get_alarm_history_distict_mac(start_date, end_date, ALARM_LEVELS.get(1, '%'))\n+  total_alarm_count = alarm_df.agg({'count': 'sum'})\n+  if not total_alarm_count.empty:\n+    total_alarm_count = int(total_alarm_count['count'])\n+\n+  dashboad_data.store_multi_day_dashboard_alarm_data(alarm_df.to_dict(orient=\"records\"), start_date, end_date, expiry_time)\n+\n+  connectivity_dates, connectivity_data, connectivity_df = device_connectivity.get_device_connectivity_dashboard(start_date, end_date)\n+  dashboad_data.store_multi_day_dashboard_connectivity_data(connectivity_df.to_json(orient=\"records\"), start_date, end_date, expiry_time)\n+  processed_devices_counts, processed_devices_dates, new_devices_counts, new_devices_dates = get_count_multi_day(start_date, end_date)\n+\n+  day_alarm_data = alarm_df.groupby(['year', 'month', 'day'], as_index=False).agg({'count': 'sum'})\n+  day_alarm_data['date'] = day_alarm_data['year'].astype(str)+'-'+day_alarm_data['month'].astype(str)+'-'+day_alarm_data['day'].astype(str)\n+  day_alarm_data = day_alarm_data.drop(columns=['year', 'month', 'day'])\n+\n+  product_type_alarm_data = alarm_df.groupby(['product_type'], as_index=False).agg({'count': 'sum'})\n+\n+  location_alarm_data = pandas.DataFrame.from_dict(map_data)\n+\n+  if not alarm_df.empty:\n+    location_alarm_data = alarm_df.groupby(['state'], as_index=False).agg({'count': 'sum'})\n+    location_alarm_data['state'] = 'US-' + location_alarm_data['state'].astype(str)\n+    location_alarm_data = location_alarm_data.rename(columns={\"state\": \"id\", \"count\": \"value\"})\n+    temp_merged = location_alarm_data.merge(map_df, indicator=True, how='outer')\n+    location_alarm_data = temp_merged.groupby(['id'], as_index=False).agg({'value': \"sum\"})\n+\n+  json_object = {\n+    'processed_devices_counts': processed_devices_counts,\n+    'processed_devices_dates': processed_devices_dates,\n+    'new_devices_counts': new_devices_counts,\n+    'new_devices_dates': new_devices_dates,\n+    'connectivity_dates': connectivity_dates,\n+    'connectivity_data': connectivity_data,\n+    'alarm_by_day_count': total_alarm_count,\n+    'alarm_by_day_data': day_alarm_data.to_dict(orient=\"records\"),\n+    'alarm_by_product_code': product_type_alarm_data.to_dict(orient=\"records\"),\n+    'alarm_by_state': location_alarm_data.to_dict(orient='records')\n+  }\n+\n+  dashboad_data.store_multiple_day_dashboard_data(json_object, start_date, end_date, expiry_time)\n+\n+  return json_object\n+\n+def get_alarm_by_product_type_data(product_type, start_date_str, end_date_str=None):\n+  start_date = None\n+  end_date = None\n+  if start_date_str is None:\n+    start_date = datetime.now() - timedelta(days=1)\n+  else:\n+    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n+\n+  if end_date_str is not None:\n+    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n+\n+  alarm_data = None\n+  if end_date is None:\n+    alarm_data = dashboad_data.single_day_dashboard_alarm_data(start_date)\n+  else:\n+    alarm_data = dashboad_data.multi_day_dashboard_alarm_data(start_date, end_date)\n+  alarm_df = pandas.DataFrame.from_dict(alarm_data)\n+  alarm_df = alarm_df[alarm_df['product_type'] == product_type].groupby(['product_type', 'alarm_code'], as_index=False)\\\n+    .agg({'count': \"sum\"}).sort_values(by=['count'], ascending=False)\n+  return alarm_df\n+\n+def get_connectivity_data_from_redis(start_date_str, end_date_str=None):\n+  start_date = None\n+  end_date = None\n+  diff = 0\n+  if start_date_str is None:\n+    start_date = datetime.now() - timedelta(days=1)\n+  else:\n+    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n+\n+  if end_date_str is not None:\n+    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n+    diff = end_date - start_date\n+    diff = diff.days\n+  connectivity_data = []\n+  if end_date is None or diff == 0:\n+    connectivity_data = dashboad_data.single_day_dashboard_connectivity_data(start_date)\n+  else:\n+    connectivity_data = json.loads(dashboad_data.multi_day_dashboard_connectivity_data(start_date, end_date))\n+  return pandas.DataFrame.from_dict(connectivity_data)\n+\n+def get_connectivity_data(connection_range, process_date, start_date_str, end_date_str=None):\n+  \n+  connectivity_df = get_connectivity_data_from_redis(start_date_str, end_date_str)\n+  if connection_range != '':\n+    print('filtering the connection range')\n+    connectivity_df = connectivity_df[(connectivity_df.process_date == process_date) & (connectivity_df.connection_range == connection_range)]\n+  else:\n+    connectivity_df = connectivity_df[connectivity_df.process_date == process_date]\n+\n+  connectivity_df = connectivity_df.groupby(['product_type'], as_index=False)\\\n+    .agg({'mac_address': \"count\"}).sort_values(by=['mac_address'], ascending=False)\n+  total = connectivity_df['mac_address'].sum()\n+  return str(total), connectivity_df\n+\n+def generate_map_dashboard_chart(state_id, start_date_str, end_date_str=None):\n+  start_date = None\n+  end_date = None\n+  id_prefix = ''\n+  if start_date_str is None:\n+    start_date = datetime.now() - timedelta(days=1)\n+  else:\n+    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n+\n+  if end_date_str is not None:\n+    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n+\n+  _, state = state_id.split('-')\n+\n+  alarm_data = None\n+  if end_date is None:\n+    id_prefix = 'dashboard-single-day-search'\n+    alarm_data = dashboad_data.single_day_dashboard_alarm_data(start_date)\n+  else:\n+    id_prefix = 'dashboard-multi-day-search'\n+    alarm_data = dashboad_data.multi_day_dashboard_alarm_data(start_date, end_date)\n+  alarm_df = pandas.DataFrame.from_dict(alarm_data)\n+\n+  if not alarm_df.empty:\n+    alarm_df = alarm_df[alarm_df['state'] == state]\n+    main_records = alarm_df.groupby(['product_type'], as_index=False).agg({'count': \"sum\"}).sort_values(by=['count'], ascending=False)\n+    total = alarm_df['count'].sum()\n+    data_dict = main_records.to_dict(orient='records')\n+\n+    for row in data_dict:\n+      temp_df = alarm_df[alarm_df['product_type'] == row['product_type']]\n+      temp_df = temp_df.groupby(['alarm_code'], as_index=False).agg({'count': \"sum\"})\n+      temp_df['alarm_code'] = row['product_type']+' | '+temp_df['alarm_code']\n+      row['pie'] = temp_df.to_dict(orient='records')\n+\n+    return str(total), admin_components.ColumnPieChartWidget(\n+      id={'type': id_prefix, 'details': 'dashboard-alert-map-chart'},\n+      chartData=data_dict,\n+      columnChartCategory=\"product_type\", chartValueTitle=\"Alarms\", columnChartValue=\"count\",\n+      pieChartCategory=\"alarm_code\", pieChartValue=\"count\", chartHeight=300, columnChartWidth=700/len(main_records['product_type']))\n+  return '0', html.H1(\"No Data available\")\n+\n+"
      },
      {
        "sha": "3e14bed9b1be30ad152e14ec19e824bf595d821e",
        "filename": "app/commons/device_analysis_helper.py",
        "status": "added",
        "additions": 43,
        "deletions": 0,
        "changes": 43,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/device_analysis_helper.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/device_analysis_helper.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/device_analysis_helper.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,43 @@\n+import pandas\n+\n+from datetime import datetime\n+from app.commons.dao.athena.alarms import get_alarm_history_distict_devices\n+from app.commons.dao.sql.device_alarms import ALARM_LEVELS\n+from app.commons.aws_s3 import S3Connection\n+from app.commons.log import logging\n+from app.commons.utill import DEVICE_CONNECTIVITY_SEARCH, DEVICE_ALARM_SEARCH\n+from app.commons.dashboard_helper import get_connectivity_data_from_redis\n+\n+NAME = str(__name__)\n+\n+def get_device_analysis_data(start_date, end_date, search_type, product_type, search_params = {}):\n+  print(search_params)\n+  if search_type is None:\n+    return None\n+  devices_list_df = pandas.DataFrame()\n+  if search_type == DEVICE_CONNECTIVITY_SEARCH:\n+    start_date_str = start_date.strftime('%Y-%m-%d')\n+    end_date_str = end_date.strftime('%Y-%m-%d')\n+    devices_list_df = get_connectivity_data_from_redis(start_date_str, end_date_str)\n+\n+    connection_range = None\n+\n+    if search_params is not None:\n+      connection_range = None if search_params is None else search_params['connection_range']\n+\n+    if connection_range is not None:\n+      devices_list_df = devices_list_df[(devices_list_df['product_type'] == product_type) & (devices_list_df['connection_range'] == connection_range)]\n+    else:\n+      devices_list_df = devices_list_df[devices_list_df['product_type'] == product_type]\n+\n+  elif search_type == DEVICE_ALARM_SEARCH:\n+    level = search_params['alarm_level'] if 'alarm_level' in search_params else None\n+    alarm_codes  = search_params['alarm_codes'] if 'alarm_codes' in search_params else None\n+    locations = search_params['locations'] if 'locations' in search_params else None\n+    devices_list_df = get_alarm_history_distict_devices(start_date, end_date, ALARM_LEVELS.get(level, '%'), alarm_codes, locations, product_type)\n+  json_object = {}\n+  if not devices_list_df.empty:\n+    json_object = {\n+      'devices_analysis_data': devices_list_df.to_dict(orient='records')\n+    }\n+  return json_object\n\\ No newline at end of file"
      },
      {
        "sha": "54b2f53ba788ef6a6bb5885b477f01c9cab084a1",
        "filename": "app/commons/json_encoder.py",
        "status": "added",
        "additions": 14,
        "deletions": 0,
        "changes": 14,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/json_encoder.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/json_encoder.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/json_encoder.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,14 @@\n+import json\n+from decimal import Decimal\n+import decimal\n+\n+class DecimalEncoder(json.JSONEncoder):\n+  '''\n+  Decimal Encoder\n+  SQL returns decimal values with tupal format like ('sum', Decimal('1'))\n+  This Encoder will help to convert above tuple in {sum: 1}\n+  '''\n+  def default(self, o):\n+    if isinstance(o, Decimal):\n+      return float(o)\n+    return super(DecimalEncoder, self).default(o)\n\\ No newline at end of file"
      },
      {
        "sha": "fed823b77c4357e4a4ae05cae50828cf142c9612",
        "filename": "app/commons/log.py",
        "status": "added",
        "additions": 14,
        "deletions": 0,
        "changes": 14,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/log.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/log.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/log.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,14 @@\n+import logging\n+\n+from .utill import get_env_variable\n+\n+log_switcher={\n+  0:logging.DEBUG,\n+  1:logging.INFO,\n+  2:logging.ERROR,\n+  3:logging.WARNING\n+}\n+\n+log_level = log_switcher.get(int(get_env_variable('LOG_LEVEL')), logging.DEBUG)\n+\n+logging.basicConfig(level=log_level)"
      },
      {
        "sha": "dc7ca5b9b38cfbffb2c496fab29611902fe0f0b0",
        "filename": "app/commons/utill.py",
        "status": "added",
        "additions": 325,
        "deletions": 0,
        "changes": 325,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/commons/utill.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/commons/utill.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/commons/utill.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,325 @@\n+import os\n+import pandas\n+\n+from datetime import datetime, timedelta\n+\n+DEVICE_CONNECTIVITY_SEARCH='device_connectivity'\n+DEVICE_ALARM_SEARCH='device_alarms'\n+\n+map_data = [\n+  {\n+    'id': \"US-AL\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-AK\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-AZ\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-AR\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-CA\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-CO\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-CT\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-DE\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-FL\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-GA\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-HI\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-ID\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-IL\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-IN\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-IA\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-KS\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-KY\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-LA\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-ME\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-MD\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-MA\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-MI\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-MN\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-MS\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-MO\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-MT\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-NE\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-NV\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-NH\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-NJ\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-NM\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-NY\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-NC\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-ND\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-OH\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-OK\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-OR\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-PA\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-RI\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-SC\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-SD\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-TN\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-TX\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-UT\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-VT\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-VA\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-WA\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-WV\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-WI\",\n+    'value': 0\n+  },\n+  {\n+    'id': \"US-WY\",\n+    'value': 0\n+  }\n+]\n+\n+page_links = {\n+  'device-analysis': '#/reports/device-analysis',\n+  'single-device-analysis': '#/dashboard',\n+  'multi-day-dashboard': '#/dashboard'\n+}\n+\n+map_df = pandas.DataFrame.from_records(map_data)\n+\n+def page_link(page_name):\n+  return page_links.get(page_name, 'dashboard')\n+\n+def get_date_rage(start_date_str, end_date_str):\n+  if start_date_str is not None:\n+    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n+  else:\n+    start_date= datetime.now() - timedelta(days=1)\n+  if end_date_str is not None:\n+    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n+  else:\n+    end_date = datetime.now() - timedelta(days=1)\n+  return start_date, end_date\n+\n+def get_env_variable(name):\n+  try:\n+    return os.environ[name]\n+  except KeyError:\n+    message = \"Expected environment variable '{}' not set.\".format(name)\n+    raise Exception(message)\n+\n+def check_context_triggered_for_input(ctx, expected_input_ids):\n+  if not ctx.triggered:\n+    # To load the layout on application load, prop_id = '.' that is default view\n+    if ctx.triggered[0]['prop_id'] == '.':\n+      input_id = None\n+    else:\n+      input_id = None\n+  else:\n+    input_id = ctx.triggered[0]['prop_id'].split('.')[0]\n+\n+  if input_id is None:\n+    return None, False\n+  \n+  for element in expected_input_ids: \n+    if input_id == element:\n+      return input_id, True\n+\n+  return input_id, False\n+\n+def get_search_dates(start_date, end_date):\n+  dates = []\n+  while start_date <= end_date:\n+      dates.append(start_date.strftime('%Y-%m-%d'))\n+      start_date = start_date + timedelta(days=1)\n+  return dates\n+\n+def get_search_rages(start_date, end_date):\n+  years = []\n+  days = []\n+  months = []\n+  diff = end_date - start_date\n+  diff = diff.days\n+  if diff <= 0:\n+    years.append(str(start_date.year))\n+    days.append(str(start_date.day))\n+    months.append(str(start_date.month))\n+  else:\n+    while start_date <= end_date:\n+      if years.count(str(start_date.year)) == 0:\n+          years.append(str(start_date.year))\n+      if days.count(str(start_date.day)) == 0:\n+          days.append(str(start_date.day))\n+      if months.count(str(start_date.month)) == 0:\n+          months.append(str(start_date.month))\n+      start_date = start_date + timedelta(days=1)\n+  return years, days, months\n+\n+def get_search_conditions(start_date, end_date):\n+  if start_date.year != end_date.year:\n+    where_conditions = []\n+    start_year = start_date.year\n+    month = start_date.month\n+    days = []\n+    year = start_year\n+    while start_date <= end_date:\n+      if month != start_date.month:\n+        where_conditions.append(\"(year = {0} AND month = {1} AND day in ({2}))\".format(year, month, ','.join(\"{0}\".format(n) for n in days)))\n+        month = start_date.month\n+        days=[]\n+      \n+      days.append(start_date.day)\n+      start_date = start_date + timedelta(days=1)\n+\n+      if start_date.year != year:\n+        where_conditions.append(\"(year = {0} AND month = {1} AND day in ({2}))\".format(year, month, ','.join(\"{0}\".format(n) for n in days)))\n+        month = start_date.month\n+        year = start_date.year\n+        days=[]\n+    where_conditions.append(\"(year = {0} AND month = {1} AND day in ({2}))\".format(year, month, ','.join(\"{0}\".format(n) for n in days)))\n+  else:\n+    where_conditions = []\n+    start_year = start_date.year\n+    month = start_date.month\n+    days = []\n+    year = start_year\n+    while start_date <= end_date:\n+      if month != start_date.month: \n+        where_conditions.append(\"(month = {0} AND day in ({1}))\".format(str(month), ','.join(\"{0}\".format(n) for n in days)))\n+        month = start_date.month\n+        days=[]\n+      days.append(start_date.day)\n+      start_date = start_date + timedelta(days=1)\n+    where_conditions.append(\"(month = {0} AND day in ({1}))\".format(str(month), ','.join(\"{0}\".format(n) for n in days)))\n+\n+  return where_conditions"
      },
      {
        "sha": "ee815049ba2b91d08f25c0ca9e4ea09650bb37c5",
        "filename": "app/config.json",
        "status": "added",
        "additions": 68,
        "deletions": 0,
        "changes": 68,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/config.json",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/config.json",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/config.json?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,68 @@\n+{\n+  \"headerLogo\": \"assets/media/logos/logo-default.png\",\n+  \"appName\": \"Rheem | DataLake Portal\",\n+  \"companyName\": \"Rheem\",\n+  \"navLinks\": [\n+    {\n+      \"name\": \"Dashboard\",\n+      \"link\": \"#/dashboard\"\n+    },\n+    {\n+      \"name\": \"Analysis Tools\",\n+      \"link\": \"#/analysis-tools\",\n+      \"children\": [\n+        {\n+          \"name\": \"Download Reports\",\n+          \"link\": \"#/analysis-tools/download-reports\",\n+          \"icon\": \"flaticon-download\"\n+        },\n+        {\n+          \"name\": \"Connectivity Analysis\",\n+          \"link\": \"#/analysis-tools/connectivity-analysis\",\n+          \"icon\": \"flaticon2-wifi\"\n+        }\n+      ]\n+    },\n+    {\n+      \"name\": \"Reports\",\n+      \"link\": \"#/reports\",\n+      \"children\": [\n+        {\n+          \"name\": \"Software Versions\",\n+          \"link\": \"#/reports/software-versions\",\n+          \"icon\": \"flaticon2-delivery-package\"\n+        },\n+        {\n+          \"name\": \"Time Series\",\n+          \"link\": \"#/reports/time-series\",\n+          \"icon\": \"flaticon2-graph-2\"\n+        },\n+        {\n+          \"name\": \"Alarm Analysis\",\n+          \"link\": \"#/reports/alarm-analysis\",\n+          \"icon\": \"flaticon2-bell-5\"\n+        },\n+        {\n+          \"name\": \"Histogram\",\n+          \"link\": \"#/reports/histogram\",\n+          \"icon\": \"flaticon-graphic-2\"\n+        },\n+        {\n+          \"name\": \"Device Analysis\",\n+          \"link\": \"#/reports/device-analysis\",\n+          \"icon\": \"flaticon2-setup\"\n+        }\n+      ]\n+    }\n+  ],\n+  \"footer\": [\n+    {\n+      \"name\": \"About Us\",\n+      \"link\": \"https://www.rheem.com/\"\n+    },\n+    {\n+      \"name\": \"My Rheem\",\n+      \"link\": \"https://my.rheem.com/\"\n+    }\n+  ]\n+}\n\\ No newline at end of file"
      },
      {
        "sha": "113d86e30f732d486b356cc48c89f035bf8836bf",
        "filename": "app/device_analysis.py",
        "status": "added",
        "additions": 184,
        "deletions": 0,
        "changes": 184,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/device_analysis.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/device_analysis.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/device_analysis.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,184 @@\n+import admin_components\n+import dash_bootstrap_components as dbc\n+import dash_core_components as dcc\n+import dash_html_components as html\n+import dash\n+import dash_table\n+import json\n+import pandas as pd\n+\n+from app.commons.utill import DEVICE_CONNECTIVITY_SEARCH, DEVICE_ALARM_SEARCH, get_date_rage, page_link\n+from app.commons.device_analysis_helper import get_device_analysis_data\n+from app.commons.dao.sql.alerts import get_all_alerts\n+from app.commons.dao.sql.device_alarms import ALARM_DROP_DOWN_VALUES\n+from app.commons.dao.sql.locations import get_unique_states\n+from app.commons.utill import check_context_triggered_for_input\n+from dash.exceptions import PreventUpdate\n+from dash.dependencies import Input, Output, State\n+\n+NAME = str(__name__)\n+PAGE_NAME = 'device-analysis'\n+\n+alerts_df = get_all_alerts(True)\n+alert_codes_arr = alerts_df['alarm_code'].unique().tolist()\n+all_alarm_codes = pd.DataFrame(data=list(zip(alert_codes_arr, alert_codes_arr)), columns=['label', 'value']).to_dict(orient=\"records\")\n+\n+locations=get_unique_states(True)['state'].unique().tolist()\n+all_locations = pd.DataFrame(data=list(zip(locations, locations)), columns=['label', 'value']).to_dict(orient=\"records\")\n+\n+def get_device_analysis_page():\n+  dashboard = [\n+    dbc.Row(\n+      style={\n+          'width': '100%'\n+      },\n+      children=[\n+        dbc.Col(\n+          lg=3,\n+          xl=3,\n+          children=[\n+            admin_components.CardWidget(\n+              id=\"alarm-search\",\n+              primaryTitle=\"Search by Alarm\",\n+              children=[\n+                html.Div([\n+                  html.Label(\"Show Distinct\", className=\"font-weight-bold mr-8\"),\n+                  admin_components.Switch(\n+                    id=\"devices-analysis-show-distinct\",\n+                    onText=\"Yes\",\n+                    offText=\"No\",\n+                    bsSize=\"mini\",\n+                    defaultValue=True,\n+                    onColor=\"success\",\n+                    offColor=\"warning\"\n+                  )\n+                ], className=\"form-group\"),\n+                html.Div([\n+                  html.Label(\"Alarm Level\", className=\"font-weight-bold\"),\n+                  dcc.Dropdown(\n+                    id='devices-analysis-alarm-level-drop-down',\n+                    options=ALARM_DROP_DOWN_VALUES,\n+                    value=['Critical'],\n+                    placeholder=\"Select Alarm Level\",\n+                    multi=False\n+                  )\n+                ], className=\"form-group\"),\n+                html.Div([\n+                  html.Label(\"Alarm Code\", className=\"font-weight-bold\"),\n+                  dcc.Dropdown(\n+                    id='devices-analysis-alarm-code-drop-down',\n+                    options=all_alarm_codes,\n+                    value=[],\n+                    placeholder=\"Select Alarm Codes\",\n+                    multi=True\n+                  )\n+                ], className=\"form-group\"),\n+                html.Div([\n+                  html.Label(\"Alarm Location\", className=\"font-weight-bold\"),\n+                  dcc.Dropdown(\n+                    id='devices-analysis-alarm-location-drop-down',\n+                    options=all_locations,\n+                    value=[],\n+                    placeholder=\"Select Alarm Location\",\n+                    multi=True\n+                  )\n+                ], className=\"form-group\"),\n+                dbc.Button(\n+                  \"Search\",\n+                  id='devices-analysis-alarm-by-search'\n+                )\n+              ]\n+            )\n+          ]\n+        ),\n+        dbc.Col(\n+          lg=9,\n+          xl=9,\n+          children=[\n+              admin_components.CardWidget(\n+                primaryTitle=\"Device Analysis Search\",\n+                children=[\n+                  dash_table.DataTable(\n+                    id='device-analysis-table',\n+                    sort_action=\"native\",\n+                    sort_mode='multi',\n+                    fixed_rows={'headers': True},\n+                    style_cell={\n+                      'textAlign': 'center',\n+                      'border': '1px solid grey'\n+                    },\n+                    style_header={\n+                      'backgroundColor': 'rgb(230, 230, 230)',\n+                      'fontWeight': 'bold',\n+                      'border': '1px solid black',\n+                    },\n+                    style_data_conditional=[{\n+                        'if': {'row_index': 'odd'},\n+                        'backgroundColor': 'rgb(248, 248, 248)'\n+                      }\n+                    ],\n+                    style_table={\n+                      'overflowX': 'auto',\n+                      'overflowY': 'auto'\n+                  })\n+                ])\n+              ]),\n+        html.Span(id='device-analysis-search-container')\n+    ])\n+  ]\n+  return dashboard\n+\n+\n+def init_devices_analysis_callbacks(app):\n+  @app.callback(\n+  [\n+    Output('device-analysis-table', 'data'),\n+    Output('device-analysis-table', 'columns'),\n+    Output('device-analysis-search-container', 'children')\n+  ],\n+  [\n+    Input('device-analytics-page-session-store', 'data'),\n+    Input('devices-analysis-alarm-by-search', 'n_clicks')\n+  ],\n+  [\n+    State('devices-analysis-alarm-level-drop-down', 'value'),\n+    State('devices-analysis-alarm-code-drop-down', 'value'),\n+    State('devices-analysis-alarm-location-drop-down', 'value'),\n+    State('devices-analysis-show-distinct', 'value')\n+  ]\n+  )\n+  def load_dashboard_data(session_data, alarm_by_search_clicks, alarm_level, alarm_codes, alarm_location, show_distinct):\n+    input_id, triggered = check_context_triggered_for_input(dash.callback_context, ['device-analytics-page-session-store', 'devices-analysis-alarm-by-search'])\n+    data = []\n+    columns = []\n+    if input_id == 'devices-analysis-alarm-by-search':\n+      print('Alarm analysis Search')\n+      search_params = {}\n+\n+      if alarm_level is not None:\n+        search_params['alarm_level'] = alarm_level\n+      if alarm_codes is not None:\n+        search_params['alarm_codes'] = alarm_codes\n+      if alarm_location is not None:\n+        search_params['locations'] = alarm_location\n+      search_params['show_distinct'] = show_distinct\n+      search_params['search_type'] = DEVICE_ALARM_SEARCH\n+\n+      return [None, None,\n+        dcc.Store(id={\n+          'type': 'search',\n+          'details': 'devices-analysis-alarm-by-search',\n+          'link': page_link(PAGE_NAME)\n+        },\n+        storage_type='memory',\n+        data=search_params)\n+      ]\n+\n+    if session_data is not None and \"devices_analysis_data\" in session_data:\n+        data = session_data['devices_analysis_data']\n+    \n+    if len(data) > 0:\n+      columns = [{\"name\": key, \"id\": key} for key in data[0].keys()]\n+      return [data, columns, None]\n+    else:\n+      return [[], [], None]"
      },
      {
        "sha": "2b22572f3fa125e3963161bbf62a66e53a23aab8",
        "filename": "app/multi_day_dashboard.py",
        "status": "added",
        "additions": 287,
        "deletions": 0,
        "changes": 287,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/multi_day_dashboard.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/multi_day_dashboard.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/multi_day_dashboard.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,287 @@\n+import admin_components\n+import dash_bootstrap_components as dbc\n+import dash_html_components as html\n+import pandas\n+import dash\n+import statistics\n+import dash_core_components as dcc\n+import json\n+\n+from app.commons.utill import check_context_triggered_for_input, map_data, DEVICE_CONNECTIVITY_SEARCH, DEVICE_ALARM_SEARCH, page_link\n+from app.device_analysis import PAGE_NAME as device_analysis_page_name\n+from app.commons.dashboard_helper import generate_map_dashboard_chart, get_alarm_by_product_type_data, get_connectivity_data\n+from dash.dependencies import Input, Output, State, ALL\n+\n+NAME = str(__name__)\n+PAGE_NAME = 'multi-day-dashboard'\n+\n+def get_multi_day_page_dashboard():\n+  dashboard = [\n+    dbc.Row(\n+      style={\n+        'width': '100%'\n+      },\n+      children=[\n+        dbc.Col(\n+          lg=6,\n+          xl=4,\n+          children=admin_components.StatsWidget(\n+            title=\"Processed Devices\",\n+            subtitle=\"\",\n+            id=\"multi-day-processed-devices\",\n+            chartData=[],\n+            chartCategory=[],\n+            chartType=\"bar\",\n+            chartTitle='Processed Devices',\n+            chartStrokeColors=['#FFA800'],\n+            chartFillColors=['#FFF4DE'],\n+            tooltip=\"Unique Device Processed on selected date range\",\n+            titleClass=\"text-warning font-weight-bold font-size-h5\"\n+          )\n+        ),\n+        dbc.Col(\n+          lg=6,\n+          xl=4,\n+          children=admin_components.StatsWidget(\n+            title=\"New Devices\",\n+            subtitle=\"\",\n+            id=\"multi-day-new-devices\",\n+            chartData=[],\n+            chartCategory=[],\n+            chartType=\"bar\",\n+            chartStrokeColors=['#8950FC'],\n+            chartFillColors=['#EEE5FF'],\n+            tooltip=\"Unique New Devices on boarded to Datalake on selected date range\",\n+            titleClass=\"text-success font-weight-bold font-size-h5\"\n+          )\n+        ),\n+        dbc.Col(\n+          lg=6,\n+          xl=4,\n+          children=admin_components.StatsWidget(\n+            title=\"Device Connectivity\",\n+            subtitle=\"Device connectivity for selected date range\",\n+            id=\"multi-day-device-connectivity\",\n+            chartCategory=[],\n+            chartData=[],\n+            barStacked=True,\n+            chartType=\"bar\",\n+            chartStrokeColors=['#fff'],\n+            chartFillColors=['#2662058C', '#2662059E', '#266205B3', '#266205CC', '#266205'],\n+            titleClass=\"text-primary font-weight-bold font-size-h5\",\n+            tooltip=\"Device connectivity in range of 1%-20%, 21%-4%, 41%-60%, 61%-80%, 81%-100%\",\n+          )\n+        )\n+    ]),\n+    dbc.Row(\n+      style={\n+          'width': '100%'\n+      },\n+      children=[\n+        dbc.Col(\n+          lg=6,\n+          xl=4,\n+          children=dbc.Row(\n+            children=[\n+              dbc.Col(\n+                lg=6,\n+                xl=12,\n+                children=admin_components.StatsWidget(\n+                  title=\"Devices Has Alarm\",\n+                  subtitle=\"02-Feb (Critical Alarm)\",\n+                  id=\"multi-day-alarm-analysis\",\n+                  chartData=[],\n+                  chartCategory=[],\n+                  chartType=\"bar\",\n+                  chartTitle='Processed Devices',\n+                  chartStrokeColors=['#FFA800'],\n+                  chartFillColors=['#FFF4DE'],\n+                  tooltip=\"Unique Devices which got alarm on selected date range\",\n+                  titleClass=\"text-danger font-weight-bold font-size-h5\"\n+                )\n+              ),\n+              dbc.Col(\n+                lg=6, xl=12,\n+                children=admin_components.StatsWidget(\n+                  title=\"Alarm Analysis\",\n+                  subtitle=\"Alarm Analysis by Product Code\",\n+                  id=\"multi-day-alarm-analysis-product-code\",\n+                  chartCategory=[],\n+                  chartData=[],\n+                  chartType=\"bar\",\n+                  chartStrokeColors=['#1BC5BD'],\n+                  chartFillColors=['#C9F7F5'],\n+                  tooltip=\"Shows unique devices(mac_address) count with critical Alarms for selected date range\",\n+              ))\n+            ])\n+        ),\n+        dbc.Col(\n+          xl=8,\n+          children=[\n+            admin_components.MapChartWidget(\n+              id='multi-day-alarm-map-widget',\n+              title=\"Alarm Distribution\", subtitle=\"by USA Location\",\n+              heatLegendMinValue=0,\n+              heatLegendMaxValue=3000,\n+              heatLegendWidth=20,\n+              heatLegendMarginRight=4,\n+              chartData=map_data)\n+          ]\n+        )\n+      ]\n+    ),\n+    html.Span(id='multi-day-device-clicks-container'),\n+  ]\n+  return dashboard\n+\n+\n+def init_multi_day_dashboard_callbacks(app):\n+  @app.callback(\n+  [\n+    Output('multi-day-device-connectivity', 'chartCategory'),\n+    Output('multi-day-device-connectivity', 'chartData'),\n+    Output('multi-day-new-devices', 'totalValue'),\n+    Output('multi-day-new-devices', 'chartCategory'),\n+    Output('multi-day-new-devices', 'chartData'),\n+    Output('multi-day-processed-devices', 'totalValue'),\n+    Output('multi-day-processed-devices', 'chartCategory'),\n+    Output('multi-day-processed-devices', 'chartData'),\n+    Output('multi-day-alarm-analysis', 'totalValue'),\n+    Output('multi-day-alarm-analysis', 'chartCategory'),\n+    Output('multi-day-alarm-analysis', 'chartData'),\n+    Output('multi-day-alarm-map-widget', 'chartData'),\n+    Output('multi-day-alarm-analysis-product-code', 'chartCategory'),\n+    Output('multi-day-alarm-analysis-product-code', 'chartData'),\n+  ],\n+  [\n+    Input('multi-day-session-store', 'data')\n+  ])\n+  def load_dashboard_data(data):\n+    if data is not None:\n+      connectivity_chart_category = data['connectivity_dates']\n+      connectivity_data = data['connectivity_data']\n+      processed_devices_counts = [{ 'name': 'Count', 'data':data['processed_devices_counts']}]\n+      processed_devices_dates = data['processed_devices_dates']\n+      new_devices_dates = data['new_devices_dates']\n+      new_devices_counts = [{ 'name': 'Count', 'data': data['new_devices_counts'] }]\n+      \n+      alarm_count = data['alarm_by_day_count']\n+      alarms_day_df = pandas.DataFrame.from_dict(data['alarm_by_day_data'])\n+      alarm_by_product_code_df = pandas.DataFrame.from_dict(data['alarm_by_product_code'])\n+\n+      if not alarm_by_product_code_df.empty:\n+        alarm_by_product_code_df = alarm_by_product_code_df.sort_values(by=['count'], ascending=False)\n+      \n+      alarms_day_data = [{ 'name': 'Count', 'data': alarms_day_df['count'].tolist() }]\n+      alarm_by_product_code_data = [{ 'name': 'Count', 'data': alarm_by_product_code_df['count'].tolist() }]\n+      \n+      return [\n+        connectivity_chart_category,\n+        connectivity_data,\n+        int(statistics.mean(data['new_devices_counts'])),\n+        new_devices_dates,\n+        new_devices_counts,\n+        int(statistics.mean(data['processed_devices_counts'])),\n+        processed_devices_dates,\n+        processed_devices_counts,\n+        alarm_count,\n+        alarms_day_df['date'].tolist(),\n+        alarms_day_data,\n+        data['alarm_by_state'],\n+        alarm_by_product_code_df['product_type'].tolist(),\n+        alarm_by_product_code_data\n+      ]\n+    return [[], [], 0, [], [], 0, [], []]\n+  @app.callback(\n+  [Output('multi-day-device-clicks-container', 'children')],\n+  [\n+    Input('multi-day-device-connectivity', 'n_clicks'),\n+    Input('multi-day-alarm-map-widget', 'n_clicks'),\n+    Input('multi-day-alarm-analysis-product-code', 'n_clicks'),\n+    Input('multi-day-alarm-analysis', 'header_clicks'),\n+    Input({'type': 'dashboard-multi-day-search', 'details': ALL}, 'selectedData')\n+  ],\n+  [\n+    State('multi-day-device-connectivity', 'selectedData'),\n+    State('multi-day-alarm-map-widget', 'selectedData'),\n+    State('multi-day-alarm-analysis-product-code', 'selectedData'),\n+    State('main-layout', 'start'),\n+    State('main-layout', 'end')\n+  ])\n+  def day_states_graphs_click(day_device_connectivity_n_clicks, day_alarm_map_widget_n_clicks, day_alarm_analysis_n_clicks, device_has_alarms_header_clicks,\n+    subchart_search, device_connectivity_selected_data, alarm_map_selected_data, day_alarm_selected_data, start_date_str, end_date_str):\n+    input_id, triggered = check_context_triggered_for_input(dash.callback_context, ['multi-day-device-connectivity', 'multi-day-alarm-map-widget', 'multi-day-alarm-analysis-product-code', 'multi-day-alarm-analysis'])\n+    print(input_id, subchart_search)\n+    if triggered:\n+      if input_id == 'multi-day-alarm-analysis-product-code':\n+        category = day_alarm_selected_data['category']\n+        alarm_data_df = get_alarm_by_product_type_data(category, start_date_str, end_date_str)\n+        chart = admin_components.ChartWidget(\n+          id={'type': 'dashboard-multi-day-search', 'details': 'alarm-analysis-by-product-code-chart'},\n+          chartData=[{'name': 'Count', 'data': alarm_data_df['count']}], chartCategory=alarm_data_df['alarm_code'])\n+        return [admin_components.AdminModal(children=chart, headingTitle='Alarm distribution: '+category, show=True)]\n+      elif input_id == 'multi-day-alarm-analysis':\n+        data = {\n+          'search_type': DEVICE_ALARM_SEARCH,\n+          'alarm_level': 1\n+        }\n+        return [\n+          dcc.Store(id={\n+            'type': 'search',\n+            'details': 'devices_has_alarms',\n+            'link': page_link(device_analysis_page_name)\n+          }, storage_type='memory', data=data)]\n+      elif input_id == 'multi-day-alarm-map-widget':\n+        state = alarm_map_selected_data['id']\n+        total, chart = generate_map_dashboard_chart(state, start_date_str, end_date_str)\n+        return [admin_components.AdminModal(children=chart, headingTitle='Alarm distribution: '+state+', Total: '+total, show=True)]\n+      elif input_id == 'multi-day-device-connectivity':\n+        print(device_connectivity_selected_data)\n+        process_date = device_connectivity_selected_data['category']\n+        data = device_connectivity_selected_data['data']\n+        connectivity_range = data['name']\n+        total, connectivity_df = get_connectivity_data(connectivity_range, process_date, start_date_str, end_date_str)\n+        chart = admin_components.ChartWidget(\n+          id={'type': 'dashboard-multi-day-search', 'details': 'multi-day-device-connectivity-chart'},\n+          chartData=[{'name': 'Count', 'data': connectivity_df['mac_address']}],\n+          chartCategory=connectivity_df['product_type'])\n+        return [admin_components.AdminModal(children=chart, headingTitle='Connectivity distribution: '+connectivity_range+', Total: '+total, show=True)]\n+    elif input_id is not None:\n+      search_details = json.loads(input_id)\n+      chart_source = search_details['details']\n+      data = {}\n+      if chart_source == 'multi-day-device-connectivity-chart':\n+        data = device_connectivity_selected_data['data'] if 'data' in device_connectivity_selected_data else None\n+        connectivity_range = None if data is None else data['name']\n+        [ obj ] = subchart_search\n+        category = obj['category']\n+        data['product_type'] = category\n+        data['connection_range'] = connectivity_range\n+        data['search_type'] = DEVICE_CONNECTIVITY_SEARCH\n+\n+      elif chart_source == 'dashboard-alert-map-chart':\n+        _, state = alarm_map_selected_data['id'].split('-')\n+        [ obj ] = subchart_search\n+        category = obj['alarm_code']\n+        [product_type, alarm_code] = category.split(' | ')\n+        data['alarm_codes'] = [alarm_code]\n+        data['product_type'] = product_type\n+        data['search_type'] = DEVICE_ALARM_SEARCH\n+        data['locations'] = [state]\n+      elif chart_source == 'alarm-analysis-by-product-code-chart':\n+        product_type = day_alarm_selected_data['category']\n+        [ obj ] = subchart_search\n+        category = obj['category']\n+        data['alarm_codes'] = [category]\n+        data['product_type'] = product_type\n+        data['search_type'] = DEVICE_ALARM_SEARCH\n+      return [\n+          dcc.Store(id={\n+              'type': 'search',\n+              'details': chart_source,\n+              'link': page_link(device_analysis_page_name)\n+            },\n+            storage_type='memory',\n+            data=data)\n+        ]\n+    return [None]"
      },
      {
        "sha": "091f851ba0f3225ea8aafb44ad06121cd0716eb4",
        "filename": "app/requirements.txt",
        "status": "added",
        "additions": 22,
        "deletions": 0,
        "changes": 22,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/requirements.txt",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/requirements.txt",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/requirements.txt?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,22 @@\n+dash==1.12.0\n+dash-auth==1.3.2\n+dash-html-components==1.0.3\n+dash-renderer==1.4.1\n+dash-table==4.10.0\n+Flask==1.1.2\n+Flask-Assets==2.0\n+Flask-Compress==1.5.0\n+Flask-Caching==1.8.0\n+gunicorn==20.0.4\n+python-dotenv==0.13.0\n+tornado==6.0.4\n+psycopg2==2.8.6\n+redis==3.5.3\n+dash-bootstrap-components==0.10.3\n+flask-login==0.5.0\n+pandas==1.1.4\n+boto3==1.14.9\n+requests==2.23.0\n+plotly==4.7.1\n+urllib3==1.25.8\n+redis-py-cluster==2.1.0"
      },
      {
        "sha": "219e51713239699d2ab5ace122946ae8b9c07a7c",
        "filename": "app/single_day_dashboard.py",
        "status": "added",
        "additions": 282,
        "deletions": 0,
        "changes": 282,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/app/single_day_dashboard.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/app/single_day_dashboard.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/app/single_day_dashboard.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,282 @@\n+import admin_components\n+import dash_bootstrap_components as dbc\n+import dash_html_components as html\n+import dash\n+import json\n+import pandas\n+import dash_core_components as dcc\n+\n+from app.commons.utill import map_data, check_context_triggered_for_input, DEVICE_CONNECTIVITY_SEARCH, DEVICE_ALARM_SEARCH, page_link\n+from app.device_analysis import PAGE_NAME as device_analysis_page_name\n+from app.commons.dashboard_helper import generate_map_dashboard_chart, get_alarm_by_product_type_data, get_connectivity_data\n+from dash.exceptions import PreventUpdate\n+from dash.dependencies import Input, Output, State, ALL\n+from datetime import datetime\n+\n+NAME = str(__name__)\n+PAGE_NAME = 'single-dashboard'\n+\n+def get_single_day_page_dashboard():\n+  dashboard = [\n+    dbc.Row(\n+      style={\n+          'width': '100%'\n+      },\n+      children=[\n+        dbc.Col(\n+          lg=6,\n+          xl=4,\n+          children=admin_components.StatsWidget(\n+            title=\"Devices Has Alarm\",\n+            subtitle=\"(Critical Alarm)\",\n+            id=\"day-devices-alarm\",\n+            statastic=0,\n+            totalValue=0,\n+            tooltip=\"Unique Devices which got alarm on selected date\",\n+            titleClass=\"text-danger font-weight-bold font-size-h5\"\n+          )\n+        ),\n+        dbc.Col(\n+          lg=6,\n+          xl=4,\n+          children=admin_components.StatsWidget(\n+            title=\"Processed Devices\",\n+            subtitle=\"    \",\n+            id=\"day-processed-devices\",\n+            statastic=0,\n+            totalValue=0,\n+            tooltip=\"Unique Device Processed on selected date\",\n+            titleClass=\"text-warning font-weight-bold font-size-h5\"\n+          )\n+        ),\n+        dbc.Col(\n+          lg=6,\n+          xl=4,\n+          children=admin_components.StatsWidget(\n+            title=\"New Devices\",\n+            subtitle=\"    \",\n+            id=\"day-new-devices\",\n+            statastic=-0,\n+            totalValue=0,\n+            tooltip=\"Unique New Devices on boarded to Datalake on selected date\",\n+            titleClass=\"text-success font-weight-bold font-size-h5\"\n+          )\n+        )\n+    ]),\n+    dbc.Row(\n+      style={\n+          'width': '100%'\n+      },\n+      children=[\n+        dbc.Col(\n+          lg=6,\n+          xl=4,\n+          children=dbc.Row(\n+            children=[\n+              dbc.Col(\n+                lg=6, xl=12,\n+                children=admin_components.StatsWidget(\n+                  title=\"Alarm Distribution\",\n+                  subtitle=\"by Product Code\",\n+                  id=\"day-alarm-analysis\",\n+                  chartType=\"bar\",\n+                  chartCategory=[],\n+                  chartData=[{'name': 'Alarms','data': []}],\n+                  showChartLabel=True,\n+                  chartStrokeColors=['#F64E60'],\n+                  chartFillColors=['#F64E6080'],\n+                  titleClass=\"text-danger font-weight-bold font-size-h5\",\n+                  tooltip=\"Shows unique devices(mac_address) count with critical Alarms\",\n+              )),\n+              dbc.Col(\n+                lg=6,\n+                xl=12,\n+                children=admin_components.StatsWidget(\n+                  title=\"Device Connectivity\",\n+                  subtitle=\"Device connectivity for past 7 days from selected date\",\n+                  id=\"day-device-connectivity\",\n+                  chartCategory=[],\n+                  chartData=[],\n+                  chartStrokeColors=['#fff'],\n+                  chartFillColors=['#2662058C', '#2662059E', '#266205B3', '#266205CC', '#266205'],\n+                  barStacked=True,\n+                  chartType=\"bar\",\n+                  titleClass=\"text-primary font-weight-bold font-size-h5\",\n+                  tooltip=\"Device connectivity in range of 1%-20%, 21%-4%, 41%-60%, 61%-80%, 81%-100%\",\n+                )\n+              )\n+            ])\n+        ),\n+        dbc.Col(\n+          xl=8,\n+          children=[\n+            admin_components.MapChartWidget(\n+              id='day-alarm-map-widget',\n+              title=\"Alarm Distribution\", subtitle=\"by USA Location\",\n+              heatLegendMinValue=0,\n+              heatLegendMaxValue=3000,\n+              heatLegendWidth=20,\n+              heatLegendMarginRight=4,\n+              chartData=map_data)\n+          ]\n+        )\n+      ]\n+    ),\n+    html.Span(id='day-device-clicks-container')\n+    \n+  ]\n+  return dashboard\n+\n+def init_single_day_dashboard_callbacks(app):\n+  @app.callback(\n+  [\n+    Output('day-processed-devices', 'totalValue'),\n+    Output('day-processed-devices', 'statastic'),\n+    Output('day-new-devices', 'totalValue'),\n+    Output('day-new-devices', 'statastic'),\n+    Output('day-devices-alarm', 'totalValue'),\n+    Output('day-devices-alarm', 'statastic'),\n+    Output('day-alarm-analysis', 'chartCategory'),\n+    Output('day-alarm-analysis', 'chartData'),\n+    Output('day-alarm-map-widget', 'chartData'),\n+    Output('day-device-connectivity', 'chartCategory'),\n+    Output('day-device-connectivity', 'chartData')\n+  ],\n+  [\n+    Input('single-day-session-store', 'data')\n+  ])\n+  def load_dashboard_data(data):\n+    if data is not None:\n+      processed_devices_count = data['processed_devices_count']\n+      new_devices_count = data['new_devices_count']\n+      processed_devices_count_day_before = data['processed_devices_count_day_before']\n+      new_devices_count_day_before = data['new_devices_count_day_before']\n+      alarm_json_data_day_before = data['alarm_a_day_before']\n+\n+      connectivity_chart_category = data['connectivity_dates']\n+      connectivity_data = data['connectivity_data']\n+      \n+      \n+      alarm_chart_category=[]\n+      alarm_chart_data = []\n+      total_devices_has_alarms = data['alarm_count']\n+      total_devices_has_alarms_day_before = 0\n+\n+      alarm_by_product_code = data['alarm_by_product_code']\n+      alarm_by_product_code_df = pandas.read_json(alarm_by_product_code, orient='records')\n+\n+      if not alarm_by_product_code_df.empty:\n+        alarm_by_product_code_df = alarm_by_product_code_df.sort_values(by=['count'], ascending=False)\n+        alarm_chart_category = alarm_by_product_code_df['product_type'].tolist()\n+        alarm_chart_data = [{ 'name': 'Alarms', 'data': alarm_by_product_code_df['count'].tolist() }]\n+\n+      alarms_day_before_df = pandas.read_json(alarm_json_data_day_before, orient='records')\n+      if not alarms_day_before_df.empty:\n+        alarms_day_before_df = alarms_day_before_df.sort_values(by=['count'], ascending=False)\n+        total_devices_has_alarms_day_before = alarms_day_before_df.agg({'count': 'sum'})\n+\n+      return [ processed_devices_count,\n+        (processed_devices_count_day_before - processed_devices_count),\n+        new_devices_count, (new_devices_count_day_before - new_devices_count),\n+        total_devices_has_alarms,\n+        (total_devices_has_alarms_day_before - total_devices_has_alarms),\n+        alarm_chart_category,\n+        alarm_chart_data,\n+        data['alarm_by_state'],\n+        connectivity_chart_category,\n+        connectivity_data\n+      ]\n+    return [None, None, None, None, None, None, [], [{'name': 'Alarms','data': []}], map_data, [], []]\n+  @app.callback(\n+  [\n+    Output('day-device-clicks-container', 'children')\n+  ],\n+  [\n+    Input('day-device-connectivity', 'n_clicks'),\n+    Input('day-alarm-map-widget', 'n_clicks'),\n+    Input('day-alarm-analysis', 'n_clicks'),\n+    Input('day-devices-alarm', 'header_clicks'),\n+    Input({'type': 'dashboard-single-day-search', 'details': ALL}, 'selectedData')\n+  ],\n+  [\n+    State('day-device-connectivity', 'selectedData'),\n+    State('day-alarm-map-widget', 'selectedData'),\n+    State('day-alarm-analysis', 'selectedData'),\n+    State('main-layout', 'start')\n+  ], prevent_initial_call=True)\n+  def day_states_graphs_click(day_device_connectivity_n_clicks, day_alarm_map_widget_n_clicks, day_alarm_analysis_n_clicks, device_has_alarms_header_clicks,\n+      subchart_search, device_connectivity_selected_data, alarm_map_selected_data, day_alarm_selected_data, start_date_str):\n+    input_id, triggered = check_context_triggered_for_input(dash.callback_context, ['day-device-connectivity', 'day-alarm-map-widget', 'day-alarm-analysis', 'day-devices-alarm'])\n+    \n+    if triggered:      \n+      if input_id == 'day-alarm-analysis':\n+        category = day_alarm_selected_data['category']\n+        alarm_data_df = get_alarm_by_product_type_data(category, start_date_str)\n+        chart = admin_components.ChartWidget(\n+            id={'type': 'dashboard-single-day-search', 'details': 'alarm-analysis-by-product-code-chart'},\n+            chartData=[{'name': 'Count', 'data': alarm_data_df['count']}],\n+            chartCategory=alarm_data_df['alarm_code'])\n+        return [admin_components.AdminModal(children=chart, headingTitle='Alarm distribution: '+category, show=True)]\n+      elif input_id == 'day-devices-alarm':\n+        data = {\n+          'search_type': DEVICE_ALARM_SEARCH,\n+          'alarm_level': 1\n+        }\n+        return [\n+          dcc.Store(id={\n+            'type': 'search',\n+            'details': 'devices_has_alarms',\n+            'link': page_link(device_analysis_page_name)\n+          }, storage_type='memory', data=data)]\n+      elif input_id == 'day-alarm-map-widget':\n+        state = alarm_map_selected_data['id']\n+        total, chart = generate_map_dashboard_chart(state, start_date_str)\n+        return [admin_components.AdminModal(children=chart, headingTitle='Alarm distribution: '+state+', Total: '+total, show=True)]\n+      elif input_id == 'day-device-connectivity':\n+        process_date = device_connectivity_selected_data['category']\n+        data = device_connectivity_selected_data['data'] if 'data' in device_connectivity_selected_data else None\n+        connectivity_range = '' if data is None else data['name']\n+        total, connectivity_df = get_connectivity_data(connectivity_range, process_date, start_date_str)\n+        chart = admin_components.ChartWidget(\n+            id={'type': 'dashboard-single-day-search', 'details': 'single-day-device-connectivity-chart'},\n+            chartData=[{'name': 'Count-'+connectivity_range, 'data': connectivity_df['mac_address']}],\n+            chartCategory=connectivity_df['product_type'])\n+        return [admin_components.AdminModal(children=chart, headingTitle='Connectivity distribution: '+connectivity_range+', Total: '+total, show=True)]\n+    elif input_id is not None:\n+      search_details = json.loads(input_id)\n+      chart_source = search_details['details']\n+      data = {}\n+      if chart_source == 'single-day-device-connectivity-chart':\n+        data = device_connectivity_selected_data['data'] if 'data' in device_connectivity_selected_data else None\n+        connectivity_range = None if data is None else data['name']\n+        [ obj ] = subchart_search\n+        category = obj['category']\n+        data['product_type'] = category\n+        data['connection_range'] = connectivity_range\n+        data['search_type'] = DEVICE_CONNECTIVITY_SEARCH\n+      elif chart_source == 'dashboard-alert-map-chart':\n+        _, state = alarm_map_selected_data['id'].split('-')\n+        [ obj ] = subchart_search\n+        category = obj['alarm_code']\n+        [product_type, alarm_code] = category.split(' | ')\n+        data['alarm_codes'] = [alarm_code]\n+        data['product_type'] = product_type\n+        data['locations'] = [state]\n+        data['search_type'] = DEVICE_ALARM_SEARCH\n+      elif chart_source == 'alarm-analysis-by-product-code-chart':\n+        product_type = day_alarm_selected_data['category']\n+        [ obj ] = subchart_search\n+        category = obj['category']\n+        data['alarm_codes'] = [category]\n+        data['product_type'] = product_type\n+        data['search_type'] = DEVICE_ALARM_SEARCH\n+      return [\n+          dcc.Store(id={\n+              'type': 'search',\n+              'details': chart_source,\n+              'link': page_link(device_analysis_page_name)\n+            },\n+            storage_type='memory',\n+            data=data)\n+        ]\n+    return [None]"
      },
      {
        "sha": "55038f03655abdd47c92d21bf4a2b0790ff2cb91",
        "filename": "config.py",
        "status": "added",
        "additions": 29,
        "deletions": 0,
        "changes": 29,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/config.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/config.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/config.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,29 @@\n+\"\"\"App config.\"\"\"\n+from os import environ, path\n+from dotenv import load_dotenv\n+\n+\n+BASEDIR = path.abspath(path.dirname(__file__))\n+load_dotenv(path.join(BASEDIR, '.env'))\n+\n+# pylint: disable=too-few-public-methods\n+class Config:\n+    \"\"\"Flask configuration variables.\"\"\"\n+\n+    # General Config\n+    SECRET_KEY = environ.get('SECRET_KEY')\n+    FLASK_APP = environ.get('FLASK_APP')\n+    FLASK_ENV = environ.get('FLASK_ENV')\n+    FLASK_PROD = environ.get('FLASK_PROD')\n+\n+    # Assets\n+    LESS_BIN = environ.get('LESS_BIN')\n+    ASSETS_DEBUG = environ.get('ASSETS_DEBUG')\n+    LESS_RUN_IN_DEBUG = environ.get('LESS_RUN_IN_DEBUG')\n+\n+    # Static Assets\n+    STATIC_FOLDER = environ.get('STATIC_FOLDER')\n+    TEMPLATES_FOLDER = environ.get('TEMPLATES_FOLDER')\n+    COMPRESSOR_DEBUG = environ.get('COMPRESSOR_DEBUG')\n+\n+    LOG_LEVEL = environ.get('LOG_LEVEL')"
      },
      {
        "sha": "2823197539ed0804d304659fd41d8a31a4e2f6e0",
        "filename": "devops/ecr-creation.yaml",
        "status": "added",
        "additions": 27,
        "deletions": 0,
        "changes": 27,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/ecr-creation.yaml",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/ecr-creation.yaml",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/ecr-creation.yaml?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,27 @@\n+AWSTemplateFormatVersion: 2010-09-09\r\n+Parameters:\r\n+  ECRName:\r\n+    Default: rheem-curve-fitting\r\n+    Type: String\r\n+Resources:\r\n+  ECRRepository: \r\n+    Type: AWS::ECR::Repository\r\n+    Properties: \r\n+      RepositoryName: !Ref ECRName\r\n+      RepositoryPolicyText: \r\n+        Version: \"2012-10-17\"\r\n+        Statement: \r\n+          - \r\n+            Sid: AllowPushPull\r\n+            Effect: Allow\r\n+            Principal: \r\n+              AWS: \r\n+                - \"arn:aws:iam::355521354617:user/vivek.rajyaguru\"\r\n+            Action: \r\n+              - \"ecr:GetDownloadUrlForLayer\"\r\n+              - \"ecr:BatchGetImage\"\r\n+              - \"ecr:BatchCheckLayerAvailability\"\r\n+              - \"ecr:PutImage\"\r\n+              - \"ecr:InitiateLayerUpload\"\r\n+              - \"ecr:UploadLayerPart\"\r\n+              - \"ecr:CompleteLayerUpload\"\n\\ No newline at end of file"
      },
      {
        "sha": "803022547b4fe172e8296594f00b32af570edf09",
        "filename": "devops/ecs-setup.sh",
        "status": "added",
        "additions": 102,
        "deletions": 0,
        "changes": 102,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/ecs-setup.sh",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/ecs-setup.sh",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/ecs-setup.sh?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,102 @@\n+#!/bin/bash\n+GIT_BRANCH=`git branch 2> /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/\\1/'`\n+GIT_SHORT_COMMIT=`git rev-parse --short HEAD`\n+echo \"ECS-Setup.sh Called\"\n+echo $GIT_BRANCH\n+echo $GIT_SHORT_COMMIT\n+VPC_ID=``\n+SUBNET_1_ID=``\n+SUBNET_2_ID=``\n+BUCKET_NAME='rheem-datascience-infa'\n+ENV=\"production\"\n+RDS_HOST=''\n+RDS_USER=''\n+RDS_PASSWORD=''\n+RDS_SCHEMA=''\n+RDS_PORT=5432\n+RDS_DB=''\n+TEMP_BUCKET='rheem-athena-query-output'\n+LONG_TERM_BUCKET='rheem-download-data-output'\n+REGION='us-east-1'\n+DS_AUTH_URL='https://ds-auth.rheemconnect.com/'\n+DS_APP_URL='https://ds.rheemconnect.com'\n+SECRET_KEY='fL3dCuXw47oOojJSVH46aSA2b+5kZ+/QbuCakkqR'\n+FLASK_PROD='1'\n+ATHENA_DATABASE=''\n+\n+if [ \"$GIT_BRANCH\" == \"main\" ];then\n+        declare -a lastChangeArray\n+        apt-get update\n+        curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n+        apt -y install unzip\n+        unzip awscliv2.zip\n+        ./aws/install\n+        aws --version\n+        apt -y install jq\n+        apt -y install docker.io\n+        apt-get update\n+        aws cloudformation describe-stacks --stack-name ECS-curve-fitting\n+        stackCheck=$?\n+        aws ecs list-tasks --cluster rheem-datascience-applications --service-name \"rheem-curvefitting-service\"\n+        serviceCheck=$?\n+        echo $GIT_BRANCH\n+        echo $GIT_SHORT_COMMIT\n+        cd Devops\n+        if [ \"$stackCheck\" -eq 0 -a  \"$serviceCheck\" -eq 0 ];then\n+                echo \"The ECS is already Created\"\n+\n+                export imageID=\"355521354617.dkr.ecr.us-east-1.amazonaws.com/rheem-curve-fitting:$GIT_BRANCH-$GIT_SHORT_COMMIT\"\n+                jq '.containerDefinitions[0].image = env.imageID' rheem-curve-fit-service.json > tmp.$$.json && mv tmp.$$.json rheem-curve-fit-service.json\n+                echo \"registering task definitions\"\n+                aws ecs register-task-definition --cli-input-json file://rheem-curve-fit-service.json\n+                TASK_ID=$(aws ecs list-tasks --cluster rheem-datascience-applications --desired-status RUNNING --family rheem-curvefitting-service | egrep \"task\" | tr \"/\" \" \" | tr \"[\" \" \" |  awk '{print $2}' | sed 's/\"$//')\n+                TASK_REVISION=$(aws ecs describe-task-definition --task-definition rheem-curvefitting-service | egrep \"revision\" | tr \"/\" \" \" | awk '{print $2}' | sed 's/\"$//' | sed 's/,//g')\n+                aws ecs stop-task --cluster rheem-datascience-applications --task ${TASK_ID}\n+                aws ecs update-service --cluster rheem-datascience-applications --service rheem-curvefitting-service --task-definition rheem-curvefitting-service:${TASK_REVISION} --desired-count 1\n+                sleep 1m\n+\n+\n+        else\n+                echo \"Creating ECS\"\n+                aws s3 cp \"s3://$BUCKET_NAME/$ENV\" ./json/ --recursive\n+\n+                RDS_HOST=$(jq '.database_host' ./json/config/database_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+                RDS_DB=$(jq '.database_schema' ./json/config/database_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+                RDS_USER=$(jq '.database_user' ./json/config/database_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+                RDS_SCHEMA=$(jq '.database_user' ./json/config/database_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+                RDS_PASSWORD=$(jq '.database_password' ./json/config/database_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+                ATHENA_DATABASE=$(jq '.database_name' ./json/config/athena_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+\n+                VPC_ID=$(jq '.vpcId' ./json/rheem-datascience-stack.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+                SUBNET_1_ID=$(jq '.subnetIdOne' ./json/rheem-datascience-stack.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+                SUBNET_2_ID=$(jq '.subnetIdTwo' ./json/rheem-datascience-stack.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+\n+                aws cloudformation create-stack --stack-name ECS-curve-fitting --template-body file://rheem-curve-fitting-ecs.yaml --parameters ParameterKey=EnvironmentName,ParameterValue=rheem-curve-fitting ParameterKey=KeyPair,ParameterValue=rheem-emr-key ParameterKey=DockerImage,ParameterValue=\"355521354617.dkr.ecr.us-east-1.amazonaws.com/rheem-curve-fitting:$GIT_BRANCH-$GIT_SHORT_COMMIT\" ParameterKey=ServiceName,ParameterValue=rheem-curvefitting-service ParameterKey=VpcId,ParameterValue=\"${VPC_ID}\" ParameterKey=SubnetOne,ParameterValue=\"${SUBNET_1_ID}\" ParameterKey=SubnetTwo,ParameterValue=\"${SUBNET_2_ID}\" ParameterKey=RdsHost,ParameterValue=\"${RDS_HOST}\" ParameterKey=RdsDb,ParameterValue=\"${RDS_DB}\" ParameterKey=RdsUser,ParameterValue=\"${RDS_USER}\" ParameterKey=RdsSchema,ParameterValue=\"${RDS_SCHEMA}\" ParameterKey=RdsPassword,ParameterValue=\"${RDS_PASSWORD}\" ParameterKey=RdsPort,ParameterValue=\"${RDS_PORT}\" ParameterKey=AthenaDatabase,ParameterValue=\"${ATHENA_DATABASE}\" ParameterKey=TempBucket,ParameterValue=\"${TEMP_BUCKET}\" ParameterKey=LongTermBucket,ParameterValue=\"${LONG_TERM_BUCKET}\" ParameterKey=Region,ParameterValue=\"${REGION}\" ParameterKey=FlaskProd,ParameterValue=\"${FLASK_PROD}\" ParameterKey=DsAuthUrl,ParameterValue=\"${DS_AUTH_URL}\" ParameterKey=DsAppUrl,ParameterValue=\"${DS_APP_URL}\" ParameterKey=SecretKey,ParameterValue=\"${SECRET_KEY}\" --capabilities CAPABILITY_NAMED_IAM\n+\n+                i=0\n+                while [ \"$i\" -lt 40 ]\n+                do\n+                        stackStatus=$(aws cloudformation describe-stacks --stack-name ECS-curve-fitting | grep \"StackStatus\" |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+                        if [ \"${stackStatus}\" == 'CREATE_COMPLETE' ];then\n+                                echo \"Stack is Ready\"\n+                                break\n+                else\n+                                echo \"Waiting for Stack creation\"\n+                                sleep 1m\n+                                i=$((i+1))\n+                        fi\n+                done\n+\n+                if [ \"${stackStatus}\" != 'CREATE_COMPLETE' ];then\n+                        exit 1\n+                fi\n+        fi\n+        ELB_DNS_URL=$(aws cloudformation describe-stacks --stack-name ECS-curve-fitting | grep LoadBalancerDNS -A 1 | grep OutputValue | cut -d \":\" -f2 | tr -d ',' | tr -d '\"' | sed 's/^ *//')\n+        color=\"#548B54\"\n+        IST_TIME=$(date -d \"+1 hours\")\n+        EDT_TIME=$(TZ=\"EDT\" date -d \"+1 hours\")\n+        GMT_TIME=$(TZ=\"GMT\" date -d \"+1 hours\")\n+        text=\":heavy_check_mark: *Deployment for Curvefitting-App completed successfully*\\n *Branch:* ${GIT_BRANCH}\\n *URL:* ${ELB_DNS_URL} \\n Environment will expire at,\\n 1. IST TIME: ${IST_TIME} \\n2. EDT TIME: ${EDT_TIME} \\n3. GMT TIME: ${GMT_TIME}\"\n+        json=\"{\\\"attachments\\\":[{ \\\"color\\\":\\\"${color}\\\", \\\"text\\\": \\\"${text}\\\" }]}\"\n+        curl -d \"payload=$json\" ${WEBHOOK_URL}\n+fi"
      },
      {
        "sha": "c54fad78c7eb5e3bafda69b71c6aff31e9ad4883",
        "filename": "devops/elb-dns-mapping.sh",
        "status": "added",
        "additions": 26,
        "deletions": 0,
        "changes": 26,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/elb-dns-mapping.sh",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/elb-dns-mapping.sh",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/elb-dns-mapping.sh?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,26 @@\n+#!/bin/bash\n+set -e\n+GIT_BRANCH=`git branch 2> /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/\\1/'`\n+\n+if [ \"$GIT_BRANCH\" == \"main\" ];then\n+  apt-get update\n+  apt-get -y install curl\n+  curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n+  apt -y install unzip zip\n+  unzip -o awscliv2.zip\n+  ./aws/install\n+  aws --version\n+  apt -y install jq\n+  apt-get update\n+  apt -y install python3-pip\n+  pip3 install j2cli\n+  apt-get update\n+\n+  cd devops\n+  # Mapping ELB with Route53\n+  export ELB_DNS_URL=${ELB_DNS_URL}\n+  jq '.Changes[0].ResourceRecordSet.ResourceRecords[0].Value=env.ELB_DNS_URL' rheem-connect-elb.json > tmp.$$.json && mv tmp.$$.json rheem-connect-elb.json\n+\n+  aws route53 change-resource-record-sets --hosted-zone-id ${AWS_ZONE_ID} --change-batch file://rheem-connect-elb.json\n+\n+fi"
      },
      {
        "sha": "4e6312e2eb2f596389f0773e75cce1035441dfbb",
        "filename": "devops/event_rule.yaml",
        "status": "added",
        "additions": 27,
        "deletions": 0,
        "changes": 27,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/event_rule.yaml",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/event_rule.yaml",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/event_rule.yaml?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,27 @@\n+AWSTemplateFormatVersion: 2010-09-09\n+Description: Create Event Rule\n+Parameters:\n+  Duration:\n+    Type: String\n+    Description: Duration\n+    Default: 60\n+  EventRuleName:\n+    Type: String\n+\n+Resources:\n+  ScheduledRule:\n+    Type: AWS::Events::Rule\n+    Properties:\n+      Description: \"ScheduledRule\"\n+      Name: !Ref EventRuleName\n+      ScheduleExpression: !Join\n+                            - ''\n+                            - - 'rate('\n+                              - !Ref Duration\n+                              - ' minutes)'\n+      State: \"ENABLED\"\n+      Targets:\n+        -\n+          Arn: \"arn:aws:lambda:us-east-1:355521354617:function:rheem-ds-portal-delete-stack\"\n+          Id: \"TargetFunctionV1\"\n+          Input: \"{\\\"stack_name\\\":\\\"stack_value\\\",\\\"ecs_file_name\\\":\\\"ecs_file_value\\\", \\\"elb_dns_url\\\": \\\"elb_dns_value\\\", \\\"pull_request\\\": \\\"pull_request_id\\\", \\\"git_branch\\\": \\\"git_brach_value\\\", \\\"event_rule\\\": \\\"rule_name\\\", \\\"event_rule_stack\\\": \\\"event_rule_stack_name\\\"}\"\n\\ No newline at end of file"
      },
      {
        "sha": "3aab8240585044b5b2aa5b5b6befa64884590c7d",
        "filename": "devops/json/ecr.json",
        "status": "added",
        "additions": 3,
        "deletions": 0,
        "changes": 3,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/json/ecr.json",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/json/ecr.json",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/json/ecr.json?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,3 @@\n+{\n+  \"ecr_repo_name\": \"\"\n+}"
      },
      {
        "sha": "45fee4e9f36336044d95c310fb3de12e6bd3debf",
        "filename": "devops/json/ecs-cluster.json",
        "status": "added",
        "additions": 3,
        "deletions": 0,
        "changes": 3,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/json/ecs-cluster.json",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/json/ecs-cluster.json",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/json/ecs-cluster.json?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,3 @@\n+{\n+  \"ecs_cluster_name\": \"\"\n+}"
      },
      {
        "sha": "6a414d0618cb9f5bd87dd66eea8d20a848bffd16",
        "filename": "devops/json/ecs-service.json",
        "status": "added",
        "additions": 4,
        "deletions": 0,
        "changes": 4,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/json/ecs-service.json",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/json/ecs-service.json",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/json/ecs-service.json?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,4 @@\n+{\n+  \"ecs_service_name\": \"\",\n+  \"elb_dns_url\": \"\"\n+}"
      },
      {
        "sha": "0d0912b343e771396b30071bc68a3dca0968feb2",
        "filename": "devops/json/vpc.json",
        "status": "added",
        "additions": 5,
        "deletions": 0,
        "changes": 5,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/json/vpc.json",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/json/vpc.json",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/json/vpc.json?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,5 @@\n+{\n+  \"vpcId\": \"\",\n+  \"subnetIdOne\": \"\",\n+  \"subnetIdTwo\": \"\"\n+}"
      },
      {
        "sha": "decd732d94d879a87fcf0ec51a3b479a41f130b9",
        "filename": "devops/rheem-connect-elb.json",
        "status": "added",
        "additions": 11,
        "deletions": 0,
        "changes": 11,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/rheem-connect-elb.json",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/rheem-connect-elb.json",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/rheem-connect-elb.json?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,11 @@\n+{\n+    \"Comment\": \"UPDET a record \",\n+    \"Changes\": [{\n+    \"Action\": \"UPSERT\",\n+                \"ResourceRecordSet\": {\n+                            \"Name\": \"ds.rheemconnect.com\",\n+                            \"Type\": \"CNAME\",\n+                            \"TTL\": 60,\n+                         \"ResourceRecords\": [{ \"Value\": \"{{elbName}}\"}]\n+                }}]\n+}"
      },
      {
        "sha": "b98cc443f9f13344b4dffcbad8f936874aee5077",
        "filename": "devops/rheem-ds-portal-ecs.yaml",
        "status": "added",
        "additions": 373,
        "deletions": 0,
        "changes": 373,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/rheem-ds-portal-ecs.yaml",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/rheem-ds-portal-ecs.yaml",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/rheem-ds-portal-ecs.yaml?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,373 @@\n+AWSTemplateFormatVersion: 2010-09-09\r\n+Description: >\r\n+    This template deploys an ECS cluster to the provided VPC and subnets\r\n+    using an Auto Scaling Group\r\n+Parameters:\r\n+  EnvironmentName:\r\n+      Description: An environment name that will be prefixed to resource names\r\n+      Type: String\r\n+  DockerImage:\r\n+      Description: The Docker image to pull from your container registry\r\n+      Type: String\r\n+  ServiceName:\r\n+    Type: String\r\n+    Default: rheem-ds-portal-service\r\n+    Description: A name for the service\r\n+  ContainerPort:\r\n+    Type: Number\r\n+  ClusterName:\r\n+    Type: String\r\n+    Default: rheem-datascience-applications\r\n+  VpcId:\r\n+    Type: String\r\n+    Default: \"\"\r\n+  SubnetOne:\r\n+    Type: String\r\n+    Default: \"\"\r\n+  SubnetTwo:\r\n+    Type: String\r\n+    Default: \"\"\r\n+  ContainerCpu:\r\n+    Type: Number\r\n+    Default: 2048\r\n+    Description: How much CPU to give the container. 1024 is 1 CPU\r\n+  ContainerMemory:\r\n+    Type: Number\r\n+    Default: 4096\r\n+    Description: How much memory in megabytes to give the container\r\n+  Path:\r\n+    Type: String\r\n+    Default: \"*\"\r\n+    Description: A path on the public load balancer that this service\r\n+                 should be connected to. Use * to send all load balancer\r\n+                 traffic to this service.\r\n+  DesiredCount:\r\n+    Type: Number\r\n+    Default: 1\r\n+    Description: How many copies of the service task to run\r\n+  Role:\r\n+    Type: String\r\n+    Default: \"\"\r\n+    Description: (Optional) An IAM role to give the service's containers if the code within needs to\r\n+                 access other AWS resources like S3 buckets, DynamoDB tables, etc\r\n+  RdsHost:\r\n+    Type: String\r\n+  RdsPort:\r\n+    Type: String\r\n+  RdsUser:\r\n+    Type: String\r\n+  RdsPassword:\r\n+    Type: String\r\n+  RdsSchema:\r\n+    Type: String\r\n+  RdsDb:\r\n+    Type: String\r\n+  AthenaDatabase:\r\n+    Type: String\r\n+  Region:\r\n+    Type: String\r\n+  LongTermBucket:\r\n+    Type: String\r\n+  SecretKey:\r\n+    Type: String\r\n+  DsAppUrl:\r\n+    Type: String\r\n+  DsAuthUrl:\r\n+    Type: String\r\n+  FlaskProd:\r\n+    Type: String\r\n+  TempBucket:\r\n+    Type: String\r\n+  CloudWatchGroup:\r\n+    Type: String\r\n+    Default: RheemDsPortal-staging\r\n+  TargetGroupName:\r\n+    Type: String\r\n+    Default: rheem-ds-portal-tg-staging\r\n+  RedisCluster:\r\n+    Type: String\r\n+\r\n+Resources:\r\n+  ECSTaskExecutionRole:\r\n+    Type: AWS::IAM::Role\r\n+    Properties:\r\n+      AssumeRolePolicyDocument:\r\n+        Statement:\r\n+        - Effect: Allow\r\n+          Principal:\r\n+            Service: [ecs-tasks.amazonaws.com]\r\n+          Action: ['sts:AssumeRole']\r\n+      Path: /\r\n+      Policies:\r\n+        - PolicyName: AmazonECSTaskExecutionRolePolicy\r\n+          PolicyDocument:\r\n+            Statement:\r\n+            - Effect: Allow\r\n+              Action:\r\n+                - 'ecr:GetAuthorizationToken'\r\n+                - 'ecr:BatchCheckLayerAvailability'\r\n+                - 'ecr:GetDownloadUrlForLayer'\r\n+                - 'ecr:BatchGetImage'\r\n+                - 'logs:CreateLogStream'\r\n+                - 'logs:PutLogEvents'\r\n+              Resource: '*'\r\n+        - PolicyName: CurveFittingAthenaReadAccess\r\n+          PolicyDocument:\r\n+            Statement:\r\n+            - Effect: Allow\r\n+              Action:\r\n+                - 'athena:*'\r\n+              Resource: '*'\r\n+            - Effect: Allow\r\n+              Action:\r\n+                - 'glue:GetDatabase'\r\n+                - 'glue:GetDatabases'\r\n+                - 'glue:GetTable'\r\n+                - 'glue:GetTables'\r\n+                - 'glue:GetPartition'\r\n+                - 'glue:GetPartitions'\r\n+                - 'glue:BatchGetPartition'\r\n+              Resource: '*'\r\n+            - Effect: Allow\r\n+              Action:\r\n+                - 's3:GetBucketLocation'\r\n+                - 's3:GetObject'\r\n+                - 's3:ListBucket'\r\n+                - 's3:ListBucketMultipartUploads'\r\n+                - 's3:ListMultipartUploadParts'\r\n+              Resource: '*'\r\n+            - Effect: Allow\r\n+              Action:\r\n+                - 'lakeformation:GetDataAccess'\r\n+              Resource: '*'\r\n+            - Effect: Allow\r\n+              Action:\r\n+                - 's3:*'\r\n+              Resource: '*'\r\n+\r\n+  TaskDefinition:\r\n+    Type: AWS::ECS::TaskDefinition\r\n+    Properties:\r\n+      Family: !Ref 'ServiceName'\r\n+      Cpu: !Ref 'ContainerCpu'\r\n+      Memory: !Ref 'ContainerMemory'\r\n+      NetworkMode: awsvpc\r\n+      RequiresCompatibilities:\r\n+        - FARGATE\r\n+      ExecutionRoleArn: !Ref ECSTaskExecutionRole\r\n+      TaskRoleArn: !Ref TaskRole\r\n+      ContainerDefinitions:\r\n+        - Name: !Ref 'ServiceName'\r\n+          Cpu: !Ref 'ContainerCpu'\r\n+          Memory: !Ref 'ContainerMemory'\r\n+          Image: !Ref 'DockerImage'\r\n+          Environment:\r\n+            - Name: \"DS_AUTH_URL\"\r\n+              Value: !Ref DsAuthUrl\r\n+            - Name: \"DS_APP_URL\"\r\n+              Value: !Ref DsAppUrl\r\n+            - Name: \"SECRET_KEY\"\r\n+              Value: !Ref SecretKey\r\n+            - Name: \"FLASK_PROD\"\r\n+              Value: !Ref FlaskProd\r\n+            - Name: \"postgres_url\"\r\n+              Value: \"production-rheem-datascience-rds-database.cxi7zfcpgbcr.us-east-1.rds.amazonaws.com\"\r\n+            - Name: \"postgres_port\"\r\n+              Value: !Ref RdsPort\r\n+            - Name: \"postgres_user\"\r\n+              Value: \"econet_production\"\r\n+            - Name: \"postgres_password\"\r\n+              Value: \"MjEyOTQ0YjkxOGMzOTJlZTFlMGY4MWQ0\"\r\n+            - Name: \"postgres_db\"\r\n+              Value: !Ref RdsDb\r\n+            - Name: \"postgres_schema\"\r\n+              Value: !Ref RdsSchema\r\n+            - Name: \"AWS_REGION\"\r\n+              Value: !Ref Region\r\n+            - Name: \"AWS_ATHENA_DATABASE\"\r\n+              Value: \"production-rheem-datascience-econet-database\"\r\n+            - Name: \"TEMP_BUCKET\"\r\n+              Value: !Ref TempBucket\r\n+            - Name: \"LONG_TERM_BUCKET\"\r\n+              Value: !Ref LongTermBucket\r\n+            - Name: \"LOG_LEVEL\"\r\n+              Value: \"0\"\r\n+            - Name: \"REDIS_HOST\"\r\n+              Value: !Ref RedisCluster\r\n+            - Name: \"REDIS_PORT\"\r\n+              Value: \"6379\"\r\n+            - Name: \"API_SECRET_KEY\"\r\n+              Value: \"Y2UwMDhiNzJiOTQ3NzlhZTAyMjZlMDg1Y2NiNWM3ZTM=\"\r\n+          PortMappings:\r\n+            - ContainerPort: !Ref 'ContainerPort'\r\n+              Protocol: tcp\r\n+          LogConfiguration:\r\n+            LogDriver: awslogs\r\n+            Options:\r\n+              awslogs-group: !Ref CloudWatchGroup\r\n+              awslogs-region: us-east-1\r\n+              awslogs-stream-prefix: ecs\r\n+  TaskRole:\r\n+    Type: AWS::IAM::Role\r\n+    Properties:\r\n+      RoleName: !Join ['', [!Ref ServiceName, TaskRole]]\r\n+      Policies:\r\n+        - PolicyName: CurveFittingAthenaReadAccess\r\n+          PolicyDocument:\r\n+            Statement:\r\n+            - Effect: Allow\r\n+              Action:\r\n+                - 'athena:*'\r\n+              Resource: '*'\r\n+            - Effect: Allow\r\n+              Action:\r\n+                - 'glue:GetDatabase'\r\n+                - 'glue:GetDatabases'\r\n+                - 'glue:GetTable'\r\n+                - 'glue:GetTables'\r\n+                - 'glue:GetPartition'\r\n+                - 'glue:GetPartitions'\r\n+                - 'glue:BatchGetPartition'\r\n+              Resource: '*'\r\n+            - Effect: Allow\r\n+              Action:\r\n+                - 's3:GetBucketLocation'\r\n+                - 's3:GetObject'\r\n+                - 's3:ListBucket'\r\n+                - 's3:ListBucketMultipartUploads'\r\n+                - 's3:ListMultipartUploadParts'\r\n+                - 'logs:CreateLogStream'\r\n+                - 'logs:PutLogEvents'\r\n+              Resource: '*'\r\n+            - Effect: Allow\r\n+              Action:\r\n+                - 'lakeformation:GetDataAccess'\r\n+              Resource: '*'\r\n+            - Effect: Allow\r\n+              Action:\r\n+                - 's3:*'\r\n+              Resource: '*'\r\n+      AssumeRolePolicyDocument:\r\n+        Statement:\r\n+          - Effect: Allow\r\n+            Principal:\r\n+              Service: ecs-tasks.amazonaws.com\r\n+            Action: 'sts:AssumeRole'\r\n+\r\n+  Service:\r\n+    Type: AWS::ECS::Service\r\n+    DependsOn: LoadBalancerRule\r\n+    Properties:\r\n+      ServiceName: !Ref 'ServiceName'\r\n+      Cluster: !Ref ClusterName\r\n+      LaunchType: FARGATE\r\n+      DeploymentConfiguration:\r\n+        MaximumPercent: 200\r\n+        MinimumHealthyPercent: 75\r\n+      DesiredCount: !Ref 'DesiredCount'\r\n+      NetworkConfiguration:\r\n+        AwsvpcConfiguration:\r\n+          AssignPublicIp: ENABLED\r\n+          Subnets:\r\n+            - !Ref SubnetOne\r\n+            - !Ref SubnetTwo\r\n+          SecurityGroups:\r\n+            - !Ref LoadBalancerSecurityGroup\r\n+      TaskDefinition: !Ref 'TaskDefinition'\r\n+      LoadBalancers:\r\n+        - ContainerName: !Ref 'ServiceName'\r\n+          ContainerPort: !Ref 'ContainerPort'\r\n+          TargetGroupArn: !Ref 'TargetGroup'\r\n+\r\n+  TargetGroup:\r\n+    Type: AWS::ElasticLoadBalancingV2::TargetGroup\r\n+    Properties:\r\n+      Name: !Ref TargetGroupName\r\n+      VpcId: !Ref VpcId\r\n+      HealthCheckIntervalSeconds: 80\r\n+      HealthCheckPath: /healthcheck\r\n+      HealthCheckPort: 8000\r\n+      HealthCheckProtocol: HTTP\r\n+      HealthCheckTimeoutSeconds: 60\r\n+      HealthyThresholdCount: 5\r\n+      Protocol: HTTP\r\n+      Port: 8000\r\n+      Protocol: HTTP\r\n+      TargetType: ip\r\n+\r\n+  # Create a rule on the load balancer for routing traffic to the target group\r\n+  LoadBalancerRule:\r\n+    Type: AWS::ElasticLoadBalancingV2::ListenerRule\r\n+    Properties:\r\n+      Actions:\r\n+        - TargetGroupArn: !Ref 'TargetGroup'\r\n+          Type: 'forward'\r\n+      Conditions:\r\n+        - Field: path-pattern\r\n+          Values: [!Ref 'Path']\r\n+      ListenerArn: !Ref Listener\r\n+      Priority: 2\r\n+  LoadBalancer:\r\n+      Type: AWS::ElasticLoadBalancingV2::LoadBalancer\r\n+      Properties:\r\n+          Name: !Ref EnvironmentName\r\n+          Subnets:\r\n+            - !Ref SubnetOne\r\n+            - !Ref SubnetTwo\r\n+          Tags:\r\n+              - Key: Name\r\n+                Value: !Ref EnvironmentName\r\n+          SecurityGroups:\r\n+            - !Ref LoadBalancerSecurityGroup\r\n+  LoadBalancerSecurityGroup:\r\n+    Type: AWS::EC2::SecurityGroup\r\n+    Properties:\r\n+      GroupDescription: Security group for loadbalancer to services on ECS\r\n+      VpcId: !Ref VpcId\r\n+      SecurityGroupIngress:\r\n+        - CidrIp: 0.0.0.0/0\r\n+          IpProtocol: 'tcp'\r\n+          FromPort: 80\r\n+          ToPort: 8000\r\n+  ContainerSecurityGroup:\r\n+    Type: AWS::EC2::SecurityGroup\r\n+    Properties:\r\n+     VpcId: !Ref VpcId\r\n+     GroupDescription: for ecs containers\r\n+     SecurityGroupIngress:\r\n+       - SourceSecurityGroupId: !Ref 'LoadBalancerSecurityGroup'\r\n+         IpProtocol: 'tcp'\r\n+         FromPort: 80\r\n+         ToPort: 8000\r\n+  Listener:\r\n+    Type: 'AWS::ElasticLoadBalancingV2::Listener'\r\n+    Properties:\r\n+      DefaultActions:\r\n+        - Type: forward\r\n+          TargetGroupArn: !Ref TargetGroup\r\n+      LoadBalancerArn: !Ref LoadBalancer\r\n+      Port: 443\r\n+      Protocol: HTTPS\r\n+      Certificates:\r\n+        - CertificateArn: \"arn:aws:acm:us-east-1:355521354617:certificate/c39a1992-7361-472f-8625-335bf3fe47f7\"\r\n+      SslPolicy: ELBSecurityPolicy-2016-08\r\n+\r\n+  CloudWatchLogsGroup:\r\n+    Type: AWS::Logs::LogGroup\r\n+    Properties:\r\n+      LogGroupName: !Ref CloudWatchGroup\r\n+      RetentionInDays: 1\r\n+\r\n+Outputs:\r\n+    RheemDSPortalLoadBalancer:\r\n+        Description: A reference to the ECS cluster\r\n+        Value: !Ref LoadBalancer\r\n+    RheemDSPortalLoadBalancerDNS:\r\n+      Description: Domain name for the loadbalancer\r\n+      Value: !GetAtt LoadBalancer.DNSName\r\n+    RheemDSPortalECSTaskExecutionRole:\r\n+      Description: ECS Task Execution Role\r\n+      Value: !GetAtt 'ECSTaskExecutionRole.Arn'\r\n+    RheemDSPortalECSService:\r\n+      Description: ECS Service Name\r\n+      Value: !Ref ServiceName\n\\ No newline at end of file"
      },
      {
        "sha": "ae3d49da52deaac13b2a3134b5cc1a9939c2e982",
        "filename": "devops/rheem-ds-portal-service.json",
        "status": "added",
        "additions": 89,
        "deletions": 0,
        "changes": 89,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/rheem-ds-portal-service.json",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/rheem-ds-portal-service.json",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/rheem-ds-portal-service.json?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,89 @@\n+{\n+    \"containerDefinitions\": [\n+        {\n+            \"dnsSearchDomains\": [],\n+            \"entryPoint\": [],\n+            \"portMappings\": [\n+                {\n+                    \"hostPort\": 8000,\n+                    \"protocol\": \"tcp\",\n+                    \"containerPort\": 8000\n+                }\n+            ],\n+            \"command\": [],\n+            \"cpu\": 2048,\n+            \"environment\": [\n+            {\n+                \"name\": \"DS_AUTH_URL\", \"value\": \"https://ds-auth.rheemconnect.com/\"\n+            }, {\n+               \"name\": \"DS_APP_URL\", \"value\": \"https://ds.rheemconnect.com\"\n+            }, {\n+               \"name\": \"SECRET_KEY\", \"value\": \"fL3dCuXw47oOojJSVH46aSA2b+5kZ+/QbuCakkqR\"\n+            }, {\n+                \"name\": \"FLASK_PROD\", \"value\": \"1\"\n+            }, {\n+                \"name\": \"postgres_url\", \"value\": \"production-rheem-datascience-rds-database.cxi7zfcpgbcr.us-east-1.rds.amazonaws.com\"\n+            }, {\n+                \"name\": \"postgres_port\", \"value\": \"5432\"\n+            }, {\n+                \"name\": \"postgres_user\", \"value\": \"econet_production\"\n+            }, {\n+                \"name\": \"postgres_password\", \"value\": \"MjEyOTQ0YjkxOGMzOTJlZTFlMGY4MWQ0\"\n+            }, {\n+                \"name\": \"postgres_schema\", \"value\": \"econet_production\"\n+            }, {\n+                \"name\": \"postgres_db\", \"value\": \"postgres\"\n+            }, {\n+                \"name\": \"AWS_REGION\", \"value\": \"us-east-1\"\n+            }, {\n+                \"name\": \"AWS_ATHENA_DATABASE\", \"value\": \"production-rheem-datascience-econet-database\"\n+            }, {\n+                \"name\": \"TEMP_BUCKET\", \"value\": \"rheem-athena-query-output\"\n+            }, {\n+                \"name\": \"LONG_TERM_BUCKET\", \"value\": \"rheem-download-data-output\"\n+            }, {\n+                \"name\": \"LOG_LEVEL\", \"value\": \"0\"\n+            }, {\n+                \"name\": \"REDIS_HOST\", \"value\": \"rhr676nz3urb0uz.zrw8ae.clustercfg.use1.cache.amazonaws.com\"\n+            }, {\n+                \"name\": \"REDIS_PORT\", \"value\": \"6379\"\n+            }, {\n+                \"name\": \"API_SECRET_KEY\", \"value\": \"Y2UwMDhiNzJiOTQ3NzlhZTAyMjZlMDg1Y2NiNWM3ZTM=\"\n+            }],\n+            \"ulimits\": [],\n+            \"dnsServers\": [],\n+            \"mountPoints\": [],\n+            \"secrets\": [],\n+            \"dockerSecurityOptions\": [],\n+            \"memory\": 4096,\n+            \"volumesFrom\": [],\n+            \"image\": \"355521354617.dkr.ecr.us-east-1.amazonaws.com/rheem-ds-portal-ecr-staging:EDE-210-670c57e\",\n+            \"essential\": true,\n+            \"links\": [],\n+            \"extraHosts\": [],\n+            \"dockerLabels\": {},\n+            \"systemControls\": [],\n+            \"name\": \"rheem-ds-portal-service\",\n+            \"logConfiguration\": {\n+                \"logDriver\": \"awslogs\",\n+                \"options\": {\n+                  \"awslogs-group\": \"RheemDsPortal-logs\",\n+                  \"awslogs-region\": \"us-east-1\",\n+                  \"awslogs-stream-prefix\": \"ecs\"\n+                }\n+              }\n+        }\n+    ],\n+    \"memory\": \"4096\",\n+    \"family\": \"rheem-ds-portal-service\",\n+    \"networkMode\": \"awsvpc\",\n+    \"executionRoleArn\": \"arn:aws:iam::355521354617:role/rheem-ds-portal-EDE-210-ECSTaskExecutionRole-PCAEZOTS33CG\",\n+    \"taskRoleArn\": \"arn:aws:iam::355521354617:role/rheem-ds-portal-ecs-service-EDE-210TaskRole\",\n+    \"requiresCompatibilities\": [\n+        \"FARGATE\"\n+    ],\n+    \"cpu\": \"2048\",\n+    \"inferenceAccelerators\": [],\n+    \"volumes\": [],\n+    \"placementConstraints\": []\n+}"
      },
      {
        "sha": "03afa17cdd988fbfc2083e8e51bc1aedfcdfb646",
        "filename": "devops/stack-creation.sh",
        "status": "added",
        "additions": 255,
        "deletions": 0,
        "changes": 255,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/devops/stack-creation.sh",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/devops/stack-creation.sh",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/devops/stack-creation.sh?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,255 @@\n+#!/bin/bash\n+set -e\n+apt-get update\n+curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n+apt -y install unzip\n+unzip awscliv2.zip\n+./aws/install\n+aws --version\n+apt -y install jq\n+apt -y install docker.io\n+apt -y install python3-pip\n+pip3 --version\n+pip3 install versionner\n+\n+# Initialize Common Variables\n+GIT_BRANCH=`git branch 2> /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/\\1/'`\n+if [ \"$GIT_BRANCH\" == \"main\" ];then\n+  ENV=\"production\"\n+  REDIS_CLUSTER=\"rhr676nz3urb0uz.zrw8ae.clustercfg.use1.cache.amazonaws.com\"\n+else\n+  ENV=\"staging\"\n+  GIT_BRANCH=$(jq --raw-output .pull_request.head.ref \"$GITHUB_EVENT_PATH\")\n+  REDIS_CLUSTER=\"rhrk7zjmiows5xi.zrw8ae.clustercfg.use1.cache.amazonaws.com\"\n+fi\n+echo $GIT_BRANCH\n+GIT_SHORT_COMMIT=`git rev-parse --short HEAD`\n+VPC_ID=``\n+SUBNET_1_ID=``\n+SUBNET_2_ID=``\n+ECS_CLUSTERNAME=``\n+ECR_REPO_NAME=``\n+ECS_SERVICE=``\n+PORT=8000\n+MEMORY=4096\n+CPU=2048\n+ACCOUNT_ID=\"355521354617\"\n+JSON_PREFIX=\"rheem-ds\"\n+BUCKET_NAME='rheem-datascience-infa'\n+ECS_SERVICE_STACK_NAME=rheem-ds-portal-${GIT_BRANCH}\n+PullRequestId=$(jq --raw-output .pull_request.number \"$GITHUB_EVENT_PATH\")\n+EventRuleName=\"rheem-ds-portal-${GIT_BRANCH}\"\n+EventRuleStackName=\"EventRule-${GIT_BRANCH}\"\n+event_input_json=``\n+RDS_PORT=5432\n+TEMP_BUCKET='rheem-athena-query-output'\n+LONG_TERM_BUCKET='rheem-download-data-output'\n+REGION='us-east-1'\n+DS_AUTH_URL='https://ds-auth.rheemconnect.com/'\n+DS_APP_URL='https://ds.rheemconnect.com'\n+SECRET_KEY='fL3dCuXw47oOojJSVH46aSA2b+5kZ+/QbuCakkqR'\n+FLASK_PROD='1'\n+RDS_HOST=''\n+RDS_USER=''\n+RDS_PASSWORD=''\n+RDS_SCHEMA=''\n+RDS_DB=''\n+ATHENA_DATABASE=''\n+CloudWatchLogsGroup=\"RheemDsPortal-${GIT_BRANCH}\"\n+TargetGroupName=\"rheem-ds-portal-tg-${GIT_BRANCH}\"\n+\n+\n+echo \"${GITHUB_EVENT_PATH}\"\n+echo \"${GIT_BRANCH}\"\n+echo \"${ENV}\"\n+echo \"${ECS_SERVICE_STACK_NAME}\"\n+echo \"${ECS_CLUSTERNAME}\"\n+echo \"${BUCKET_NAME}\"\n+echo \"${PullRequestId}\"\n+echo \"${CloudWatchLogsGroup}\"\n+echo \"${TargetGroupName}\"\n+\n+cd devops\n+aws s3 cp \"s3://$BUCKET_NAME/$ENV\" ./json/ --recursive\n+\n+RDS_HOST=$(jq '.database_host' ./json/config/database_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+RDS_DB=$(jq '.database_schema' ./json/config/database_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+RDS_USER=$(jq '.database_user' ./json/config/database_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+RDS_SCHEMA=$(jq '.database_user' ./json/config/database_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+RDS_PASSWORD=$(jq '.database_password' ./json/config/database_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+ATHENA_DATABASE=$(jq '.database_name' ./json/config/athena_config.conf |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+\n+if [ ! -z $(jq '.ecr_repo_name' ./json/rheem-ds-portal-ecr-${ENV}.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2) ];then\n+    ECR_REPO_NAME=$(jq '.ecr_repo_name' ./json/rheem-ds-portal-ecr-${ENV}.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+fi\n+if [ ! -z $(jq '.ecs_service_name' ./json/rheem-ds-portal-ecs-${GIT_BRANCH}-service.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2) ];then\n+    ECS_SERVICE=$(jq '.ecs_service_name' ./json/rheem-ds-portal-ecs-${GIT_BRANCH}-service.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+    ELB_DNS_URL=$(jq '.elb_dns_url' ./json/rheem-ds-portal-ecs-${GIT_BRANCH}-service.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+fi\n+\n+VPC_ID=$(jq '.vpcId' ./json/rheem-datascience-stack.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+SUBNET_1_ID=$(jq '.subnetIdOne' ./json/rheem-datascience-stack.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+SUBNET_2_ID=$(jq '.subnetIdTwo' ./json/rheem-datascience-stack.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+ECS_CLUSTERNAME=$(jq '.ecs_cluster_name' ./json/rheem-datascience-stack.json |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+\n+echo $VPC_ID\n+echo $SUBNET_1_ID\n+echo $SUBNET_2_ID\n+echo $ECR_REPO_NAME\n+echo $ECS_CLUSTERNAME\n+echo $ECS_SERVICE\n+echo $ELB_DNS_URL\n+echo \"${RDS_HOST}\"\n+echo \"${RDS_DB}\"\n+echo \"${RDS_USER}\"\n+echo \"${RDS_SCHEMA}\"\n+echo \"${RDS_PASSWORD}\"\n+echo \"${ATHENA_DATABASE}\"\n+echo \"${REDIS_CLUSTER}\"\n+\n+\n+\n+# export VPC_ID=$VPC_ID\n+# export SUBNET_1_ID=$SUBNET_1_ID\n+# export SUBNET_2_ID=$SUBNET_2_ID\n+#jq '.vpcId=env.VPC_ID' ./json/vpc.json > tmp.$$.json && mv tmp.$$.json ./json/rheem-datascience-vpc-${GIT_BRANCH}.json\n+#jq '.subnetIdOne=env.SUBNET_1_ID' ./json/rheem-datascience-vpc-${GIT_BRANCH}.json > tmp.$$.json && mv tmp.$$.json ./json/rheem-datascience-vpc-${GIT_BRANCH}.json\n+#jq '.subnetIdTwo=env.SUBNET_2_ID' ./json/rheem-datascience-vpc-${GIT_BRANCH}.json > tmp.$$.json && mv tmp.$$.json ./json/rheem-datascience-vpc-${GIT_BRANCH}.json\n+#aws s3 cp ./json/rheem-datascience-vpc-${GIT_BRANCH}.json s3://$BUCKET_NAME/${ENV}/rheem-datascience-vpc-${GIT_BRANCH}.json\n+\n+# Check for ECR\n+if [ -z \"${ECR_REPO_NAME}\" ];then\n+    echo \"Creating ECR REPO\"\n+    aws cloudformation create-stack --stack-name rheem-ds-portal-ECR-${ENV} --template-body file://ecr-creation.yaml --parameters ParameterKey=ECRName,ParameterValue=rheem-ds-portal-ecr-${ENV}\n+    ECR_REPO_NAME=rheem-ds-portal-ecr-${ENV}\n+    export ECR_REPO_NAME=$ECR_REPO_NAME\n+    jq '.ecr_repo_name=env.ECR_REPO_NAME' json/ecr.json > tmp.$$.json && mv tmp.$$.json json/rheem-ds-portal-ecr-${ENV}.json\n+    aws s3 cp ./json/rheem-ds-portal-ecr-${ENV}.json s3://$BUCKET_NAME/${ENV}/rheem-ds-portal-ecr-${ENV}.json\n+    echo \"ECR.json file uploaded and ECR is created successfully\"\n+fi\n+\n+echo \"Log into ECR Repository\"\n+aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ${ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com\n+cd ..\n+echo \"Generating Docker Image\"\n+\n+# Generating version\n+sh version.sh\n+\n+docker build . -t \"${ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com/${ECR_REPO_NAME}:${GIT_BRANCH}-${GIT_SHORT_COMMIT}\"\n+docker push \"${ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com/${ECR_REPO_NAME}:${GIT_BRANCH}-${GIT_SHORT_COMMIT}\"\n+cd devops\n+\n+#ECR completed, now creating cluster\n+if [ -z \"${ECS_SERVICE}\" ];then\n+    aws cloudformation create-stack --stack-name \"${ECS_SERVICE_STACK_NAME}\" --template-body file://rheem-ds-portal-ecs.yaml --parameters ParameterKey=ClusterName,ParameterValue=\"${ECS_CLUSTERNAME}\"  ParameterKey=EnvironmentName,ParameterValue=\"${ECS_SERVICE_STACK_NAME}\" ParameterKey=DockerImage,ParameterValue=\"${ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com/${ECR_REPO_NAME}:${GIT_BRANCH}-${GIT_SHORT_COMMIT}\" ParameterKey=ServiceName,ParameterValue=\"rheem-ds-portal-ecs-service-${GIT_BRANCH}\" ParameterKey=VpcId,ParameterValue=\"${VPC_ID}\" ParameterKey=SubnetOne,ParameterValue=\"${SUBNET_1_ID}\" ParameterKey=SubnetTwo,ParameterValue=\"${SUBNET_2_ID}\" ParameterKey=RdsHost,ParameterValue=\"${RDS_HOST}\" ParameterKey=RdsDb,ParameterValue=\"${RDS_DB}\" ParameterKey=RdsUser,ParameterValue=\"${RDS_USER}\" ParameterKey=RdsSchema,ParameterValue=\"${RDS_SCHEMA}\" ParameterKey=RdsPassword,ParameterValue=\"${RDS_PASSWORD}\" ParameterKey=RdsPort,ParameterValue=\"${RDS_PORT}\" ParameterKey=AthenaDatabase,ParameterValue=\"${ATHENA_DATABASE}\" ParameterKey=TempBucket,ParameterValue=\"${TEMP_BUCKET}\" ParameterKey=LongTermBucket,ParameterValue=\"${LONG_TERM_BUCKET}\" ParameterKey=Region,ParameterValue=\"${REGION}\" ParameterKey=FlaskProd,ParameterValue=\"${FLASK_PROD}\" ParameterKey=DsAuthUrl,ParameterValue=\"${DS_AUTH_URL}\" ParameterKey=DsAppUrl,ParameterValue=\"${DS_APP_URL}\" ParameterKey=ContainerPort,ParameterValue=\"${PORT}\" ParameterKey=SecretKey,ParameterValue=\"${SECRET_KEY}\" ParameterKey=CloudWatchGroup,ParameterValue=\"${CloudWatchLogsGroup}\" ParameterKey=TargetGroupName,ParameterValue=\"${TargetGroupName}\" ParameterKey=RedisCluster,ParameterValue=\"${REDIS_CLUSTER}\" --capabilities CAPABILITY_NAMED_IAM\n+    i=0\n+    while [ \"$i\" -lt 10 ]\n+    do\n+        stackStatus=$(aws cloudformation describe-stacks --stack-name \"${ECS_SERVICE_STACK_NAME}\" | grep \"StackStatus\" |sed \"s/[\\\"\\[ ,]//g;s/]//g\" | cut -d':' -f2)\n+        if [ \"${stackStatus}\" == \"CREATE_COMPLETE\" ];then\n+            echo \"ECS Service Stack is Ready\"\n+            break;\n+        else\n+            echo \"Waiting for ECS Service Stack creation\"\n+            sleep 1m\n+            i=$((i+1))\n+        fi\n+    done\n+\n+    ECS_SERVICE=$(aws cloudformation describe-stacks --stack-name \"${ECS_SERVICE_STACK_NAME}\" | grep RheemDSPortalECSService -A 1 | grep OutputValue | cut -d \":\" -f2 | tr -d ',' | tr -d '\"' | sed 's/^ *//')\n+    ELB_DNS_URL=$(aws cloudformation describe-stacks --stack-name \"${ECS_SERVICE_STACK_NAME}\" | grep RheemDSPortalLoadBalancerDNS -A 1 | grep OutputValue | cut -d \":\" -f2 | tr -d ',' | tr -d '\"' | sed 's/^ *//')\n+\n+    export ECS_SERVICE=$ECS_SERVICE\n+    export ELB_DNS_URL=\"${ELB_DNS_URL}\"\n+\n+    jq '.ecs_service_name=env.ECS_SERVICE' json/ecs-service.json > tmp.$$.json && mv tmp.$$.json json/rheem-ds-portal-ecs-${GIT_BRANCH}-service.json\n+    jq '.elb_dns_url=env.ELB_DNS_URL' json/rheem-ds-portal-ecs-${GIT_BRANCH}-service.json > tmp.$$.json && mv tmp.$$.json json/rheem-ds-portal-ecs-${GIT_BRANCH}-service.json\n+    aws s3 cp ./json/rheem-ds-portal-ecs-${GIT_BRANCH}-service.json s3://$BUCKET_NAME/${ENV}/rheem-ds-portal-ecs-${GIT_BRANCH}-service.json\n+fi\n+\n+sleep 1m\n+\n+echo \"Updating service...\"\n+export imageID=\"${ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com/${ECR_REPO_NAME}:$GIT_BRANCH-$GIT_SHORT_COMMIT\"\n+jq '.containerDefinitions[0].image=env.imageID' rheem-ds-portal-service.json > tmp.$$.json && mv tmp.$$.json rheem-ds-portal-service.json\n+export ECS_SERVICE=$ECS_SERVICE\n+# Exporting ELB DNS URL for Git Action Next Step\n+echo \"::set-env name=ELB_DNS_URL::${ELB_DNS_URL}\"\n+export ELB_DNS_URL=\"https://${ELB_DNS_URL}\"\n+if [ \"$GIT_BRANCH\" == \"main\" ];then\n+    export ELB_DNS_URL=\"https://ds.rheemconnect.com\"\n+fi\n+jq '.family=env.ECS_SERVICE' rheem-ds-portal-service.json > tmp.$$.json && mv tmp.$$.json rheem-ds-portal-service.json\n+jq '.containerDefinitions[0].name=env.ECS_SERVICE' rheem-ds-portal-service.json > tmp.$$.json && mv tmp.$$.json rheem-ds-portal-service.json\n+jq '.containerDefinitions[0].environment[1].value=env.ELB_DNS_URL' rheem-ds-portal-service.json > tmp.$$.json && mv tmp.$$.json rheem-ds-portal-service.json\n+export REDIS_CLUSTER=$REDIS_CLUSTER\n+jq '.containerDefinitions[0].environment[15].value=env.REDIS_CLUSTER' rheem-ds-portal-service.json > tmp.$$.json && mv tmp.$$.json rheem-ds-portal-service.json\n+\n+TASK_ARN=$(aws cloudformation describe-stacks --stack-name \"${ECS_SERVICE_STACK_NAME}\" | grep -w RheemDSPortalECSTaskExecutionRole -A 1 | grep OutputValue | cut -d \":\" -f2- | tr -d ',' | tr -d '\"' | sed 's/^ *//')\n+export TASK_ARN=$TASK_ARN\n+jq '.taskRoleArn=env.TASK_ARN' rheem-ds-portal-service.json > tmp.$$.json && mv tmp.$$.json rheem-ds-portal-service.json\n+\n+EXECUTION_ROLE_ARN=$(aws cloudformation describe-stacks --stack-name \"${ECS_SERVICE_STACK_NAME}\" | grep RheemDSPortalECSTaskExecutionRole -A 1 | grep OutputValue | cut -d \":\" -f2- | tr -d ',' | tr -d '\"' | sed 's/^ *//')\n+export EXECUTION_ROLE_ARN=$EXECUTION_ROLE_ARN\n+jq '.executionRoleArn=env.EXECUTION_ROLE_ARN' rheem-ds-portal-service.json > tmp.$$.json && mv tmp.$$.json rheem-ds-portal-service.json\n+\n+echo \"Registering task definitions\"\n+aws ecs register-task-definition --cli-input-json file://rheem-ds-portal-service.json\n+TASK_ID=$(aws ecs list-tasks --cluster ${ECS_CLUSTERNAME} --desired-status RUNNING --family ${ECS_SERVICE} | egrep \"task\" | tr \"/\" \" \" | tr \"[\" \" \" |  awk '{print $3}' | sed 's/\"$//')\n+TASK_REVISION=$(aws ecs describe-task-definition --task-definition rheem-ds-portal-ecs-service-${GIT_BRANCH} | egrep \"revision\" | tr \"/\" \" \" | awk '{print $2}' | sed 's/\"$//' | sed 's/,//g')\n+aws ecs stop-task --cluster ${ECS_CLUSTERNAME} --task ${TASK_ID}\n+aws ecs update-service --cluster ${ECS_CLUSTERNAME} --service rheem-ds-portal-ecs-service-${GIT_BRANCH} --task-definition rheem-ds-portal-ecs-service-${GIT_BRANCH}:${TASK_REVISION} --desired-count 1\n+echo \"Service Updated successfully\"\n+\n+if [ \"$ENV\" == \"staging\" ];then\n+    echo \"Checking Existing Comments in PR\"\n+    API_TOKEN=\"token ${API_TOKEN}\"\n+    echo $API_TOKEN\n+    comments=$(curl -X GET -H \"Accept:application/vnd.github.v3+json\" -H \"Authorization:${API_TOKEN}\"  https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/issues/${PullRequestId}/comments )\n+    echo $comments > pr-comments.json\n+    commentFlag=$(cat pr-comments.json |  jq '.[] | select(.body | tostring | contains(\"Deployed Application URL:\"))' | sed 's/^ *//')\n+    removeFlag=$(cat pr-comments.json |  jq '.[] | select(.body | tostring | contains(\"is No Longer Available\"))' | sed 's/^ *//')\n+    echo ${commentFlag}\n+    echo ${removeFlag}\n+    if [ -z \"${commentFlag}\" ] || ! [ -z \"${removeFlag}\" ];then\n+        echo \"Updating Merge Request\"\n+        COMMENT=\"Deployed Application URL: ${ELB_DNS_URL}\"\n+        curl -X POST -H \"Accept:application/vnd.github.v3+json\" -H \"Authorization:${API_TOKEN}\" --data '{\"body\":\"'\"${COMMENT}\"'\"}' https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/issues/${PullRequestId}/comments\n+\n+        color=\"#548B54\"\n+        IST_TIME=$(date -d \"+1 hours\")\n+        EDT_TIME=$(TZ=\"EDT\" date -d \"+1 hours\")\n+        GMT_TIME=$(TZ=\"GMT\" date -d \"+1 hours\")\n+        text=\":heavy_check_mark: *Deployment for Rheem-DS-Portal completed successfully*\\n *Branch:* ${GIT_BRANCH}\\n *URL:* ${ELB_DNS_URL} \\n Environment will expire at,\\n 1. IST TIME: ${IST_TIME} \\n2. EDT TIME: ${EDT_TIME} \\n3. GMT TIME: ${GMT_TIME}\"\n+        json=\"{\\\"attachments\\\":[{ \\\"color\\\":\\\"${color}\\\", \\\"text\\\": \\\"${text}\\\" }]}\"\n+        curl -d \"payload=$json\" ${WEBHOOK_URL}\n+    else\n+        echo \"Environment Updated\"\n+        color=\"#FFA500\"\n+        IST_TIME=$(date -d \"+1 hours\")\n+        EDT_TIME=$(TZ=\"EDT\" date -d \"+1 hours\")\n+        GMT_TIME=$(TZ=\"GMT\" date -d \"+1 hours\")\n+        text=\":heavy_check_mark: *Deployment for Rheem-DS-Portal completed successfully*\\n *Existing environment is updated* \\n *Branch:* ${GIT_BRANCH}\\n *URL:* ${ELB_DNS_URL} \\n Environment will expire at,\\n 1. IST TIME: ${IST_TIME} \\n2. EDT TIME: ${EDT_TIME} \\n3. GMT TIME: ${GMT_TIME}\"\n+        json=\"{\\\"attachments\\\":[{ \\\"color\\\":\\\"${color}\\\", \\\"text\\\": \\\"${text}\\\" }]}\"\n+        curl -d \"payload=$json\" ${WEBHOOK_URL}\n+    fi\n+    echo \"Updating Event Rule and Targets\"\n+    aws cloudformation delete-stack --stack-name \"${EventRuleStackName}\"\n+    aws cloudformation wait stack-delete-complete --stack-name \"${EventRuleStackName}\"\n+    export ECS_SERVICE_STACK_NAME=${ECS_SERVICE_STACK_NAME}\n+    export GIT_BRANCH=${GIT_BRANCH}\n+    export ELB_DNS_URL=${ELB_DNS_URL}\n+    export PullRequestId=${PullRequestId}\n+    export EventRuleName=${EventRuleName}\n+    export EcsFileName=\"rheem-datascience-ecs-${GIT_BRANCH}-service.json\"\n+    export EventRuleStackName=${EventRuleStackName}\n+    echo \"::set-env name=ELB_DNS_URL::${ELB_DNS_URL}\"\n+    sed -e \"s,stack_value,${ECS_SERVICE_STACK_NAME},g\" -e \"s,ecs_file_value,${EcsFileName},g\" -e \"s,elb_dns_value,${ELB_DNS_URL},g\" -e \"s,pull_request_id,${PullRequestId},g\" -e \"s,git_brach_value,${GIT_BRANCH},g\" -e \"s,rule_name,${EventRuleName},g\" -e \"s,event_rule_stack_name,${EventRuleStackName},g\" < event_rule.yaml > event_rule_updated.yaml\n+\n+    echo \"Creating Event Rule\"\n+    aws cloudformation create-stack --stack-name ${EventRuleStackName} --template-body file://event_rule_updated.yaml --parameters ParameterKey=EventRuleName,ParameterValue=\"${EventRuleName}\" ParameterKey=Duration,ParameterValue=\"60\"\n+\n+fi\n+\n+"
      },
      {
        "sha": "5c3abd6ba2e4a75524e3800da3a5db0e6807bf04",
        "filename": "init.py",
        "status": "added",
        "additions": 413,
        "deletions": 0,
        "changes": 413,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/init.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/init.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/init.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,413 @@\n+\"\"\"Initialize Flask app.\"\"\"\n+import os\n+import dash\n+import logging\n+import json\n+import dash_core_components as dcc\n+import dash_html_components as html\n+import dash_bootstrap_components as dbc\n+import admin_components\n+\n+from dash.dependencies import Input, Output, State, ALL\n+from dash.exceptions import PreventUpdate\n+from app.commons.utill import get_env_variable, check_context_triggered_for_input, get_date_rage\n+from app.commons.dao.sql.product_codes import get_product_types\n+from app.single_day_dashboard import get_single_day_page_dashboard, init_single_day_dashboard_callbacks\n+from app.multi_day_dashboard import get_multi_day_page_dashboard, init_multi_day_dashboard_callbacks\n+from app.device_analysis import get_device_analysis_page, init_devices_analysis_callbacks\n+\n+from datetime import datetime, timedelta\n+from flask import Flask, request, redirect, session, url_for, render_template, jsonify, Response\n+from flask_login import LoginManager, login_required, current_user, login_user, logout_user\n+from app.auth.user import User, get_user\n+import base64\n+\n+NAME = str(__name__)\n+\n+NAME = str(__name__)\n+\n+__version__ = '0.2.0'\n+\n+log_switcher={\n+  0:logging.DEBUG,\n+  1:logging.INFO,\n+  2:logging.ERROR,\n+  3:logging.WARNING\n+}\n+\n+log_level = log_switcher.get(int(get_env_variable('LOG_LEVEL')), logging.DEBUG)\n+logging.basicConfig(level=log_level)\n+\n+AUTH_URL = os.environ.get('DS_AUTH_URL')\n+APP_URL = os.environ.get('DS_APP_URL')\n+API_SECRET_KEY = os.environ.get('API_SECRET_KEY')\n+\n+def get_path_name(hash):\n+  if hash is None or hash == '':\n+    hash = '#/dashboard'\n+\n+  if len(hash.split('/')) <= 2:\n+    mainMenu = hash.split('#')[1]\n+    subMenu = ''\n+    pathname = mainMenu\n+  else:\n+    pathname = hash.split('/', 1)[1]\n+    mainMenu = pathname.split('/')[0]\n+    subMenu = pathname.split('/')[1]\n+    pathname = mainMenu+'/'+subMenu\n+  return pathname, mainMenu, subMenu\n+\n+def protect_views(app):\n+    for view_func in app.server.view_functions:\n+        if view_func.startswith('/'):\n+            app.server.view_functions[view_func] = login_required(app.server.view_functions[view_func])\n+    return app\n+\n+\n+def create_app():\n+  # first initializing logs\n+  \"\"\"Construct core Flask application with embedded Dash app.\"\"\"\n+  flaskApp = Flask('RheemDashApp', instance_relative_config=False)\n+  login_manager = LoginManager()\n+  login_manager.init_app(flaskApp)\n+  login_manager.login_view = \"/login\"\n+  flaskApp.config.from_object('config.Config')\n+\n+  @login_manager.user_loader\n+  def load_user(userid):\n+    user = get_user(userid)\n+    return user\n+\n+  @flaskApp.route('/login')\n+  def login():\n+    return redirect(AUTH_URL + '?redirectUri=' + APP_URL + '/callback', code=303)\n+\n+  @flaskApp.route(\"/logout\")\n+  def logout():\n+    session['authed'] = None\n+    session['token'] = None\n+    logout_user()\n+    return redirect(url_for('login'))\n+\n+  @flaskApp.route('/healthcheck')\n+  def healthcheck():\n+      \"\"\"Landing page.\"\"\"\n+      return jsonify({'version': '1.0.0'})\n+\n+  @flaskApp.route('/load-dashboard')\n+  def load_dashboard():\n+    start_date = request.args.get('startDate')\n+    end_date = request.args.get('endDate')\n+    expiry_time = request.args.get('expiryTime')\n+    auth_header = request.headers.get('Authorization')\n+    error = {'error': ''}\n+\n+    # Check if AuthHeader Present\n+    if not auth_header:\n+      error['error'] = 'Authorization Header is not Present in Request'\n+      return Response(json.dumps(error), status=400)\n+\n+    # Validating AuthHeader\n+    try:\n+      env_secret_key = base64.decodestring(API_SECRET_KEY.encode('utf-8')).decode('utf-8')\n+      auth_header = base64.decodestring(auth_header.encode('utf-8')).decode('utf-8')\n+    except:\n+      error['error'] = 'Error While Decoding Auth Header'\n+      return Response(json.dumps(error), status=500)\n+\n+    if env_secret_key != auth_header:\n+      error['error'] = 'Invalid Authorization Token'\n+      return Response(error, status=401)\n+\n+    if start_date and end_date and expiry_time:\n+      start_date, end_date = get_date_rage(start_date, end_date)\n+      diff = end_date - start_date\n+      diff = diff.days\n+      if diff > 1:\n+        json_data = get_multi_day_dashboard_data(start_date, end_date, expiry_time)\n+      else:\n+        compare_date = start_date - timedelta(days=1)\n+        json_data = get_single_day_dashboard_data(start_date, compare_date, expiry_time)\n+      data = {'data': json_data}\n+      return Response(json.dumps(data), status=200)\n+    else:\n+      error['error'] = 'Required Parameters Missing'\n+      return Response(json.dumps(error), status=400)\n+\n+\n+  @flaskApp.route('/callback')\n+  def callback():\n+    is_authenticated = False\n+\n+    # if not session.get('authed') is None and session.get('authed') is True:\n+    #     is_authenticated = True\n+    # else:\n+    token = request.args.get('token')\n+    user = None\n+    if not token:\n+        return False\n+    else:\n+      user = get_user(token)\n+      if user is not None:\n+        is_authenticated = True\n+\n+    session['authed'] = is_authenticated\n+    session['token'] = token\n+    session['user'] = {'firstName': user.firstName, 'lastName': user.lastName, 'email': user.email}\n+    login_user(user)\n+\n+    if is_authenticated:\n+        return redirect(url_for('/'))\n+    else:\n+        return redirect(url_for('/login'))\n+\n+  with open('app/config.json') as f:\n+    application_config = json.load(f)\n+\n+  with flaskApp.app_context():\n+    app = dash.Dash(server=flaskApp, routes_pathname_prefix='/', suppress_callback_exceptions=True)\n+    app = protect_views(app)\n+    app.renderer = '''\n+    var renderer = new DashRenderer({\n+        request_pre: (payload) => {\n+            // print out payload parameter\n+            document.getElementById('splash-screen').style.display = 'flex';\n+        },\n+        request_post: (payload, response) => {\n+            // print out payload and response parameter\n+            document.getElementById('splash-screen').style.display = 'none';\n+        }\n+    })\n+    '''\n+\n+    app.index_string = '''\n+    <!DOCTYPE html>\n+    <html>\n+        <head>\n+            {%metas%}\n+            <title>{%title%}</title>\n+            {%favicon%}\n+            {%css%}\n+        </head>\n+        <body class=\"quick-panel-right demo-panel-right offcanvas-right \">\n+\n+            {%app_entry%}\n+            {%config%}\n+            {%scripts%}\n+            {%renderer%}\n+            <link\n+                href=\"https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700%7CRoboto:300,400,500,600,700\"\n+                rel=\"stylesheet\"\n+            />\n+            <link\n+                href=\"https://fonts.googleapis.com/icon?family=Material+Icons\"\n+                rel=\"stylesheet\"\n+            />\n+            <link\n+                rel=\"stylesheet\"\n+                href=\"https://fonts.googleapis.com/css?family=Roboto:300,400,500\"\n+            />\n+            <div id=\"splash-screen\" class=\"kt-splash-screen\">\n+                <img\n+                    src=\"/assets/media/logos/logo-dark.png\"\n+                    alt=\"Rheem\"\n+                />\n+                <svg class=\"splash-spinner\" viewBox=\"0 0 50 50\">\n+                    <circle class=\"path\"\n+                    cx=\"25\"\n+                    cy=\"25\"\n+                    r=\"20\"\n+                    fill=\"none\"\n+                    stroke-width=\"5\"\n+                    ></circle>\n+                </svg>\n+            </div>\n+        </body>\n+    </html>\n+    '''\n+\n+    product_types = get_product_types()\n+\n+    app.layout = admin_components.AdminComponents(\n+      id=\"main-layout\",\n+      config=application_config,\n+      version=__version__,\n+      quickActionTitle=\"Select Product Type\",\n+      quickActionData=product_types,\n+      children=[\n+        dcc.Location(id='url', refresh=False),\n+        dbc.Row(className='row', id='datalake-container'),\n+        dcc.Store(id='single-day-session-store', storage_type='session'),\n+        dcc.Store(id='multi-day-session-store', storage_type='session'),\n+        dcc.Store(id='device-analytics-page-session-store', storage_type='session'),\n+        dcc.Store(id='current-search', storage_type='memory')\n+      ]\n+    )\n+\n+    single_dashboard = get_single_day_page_dashboard()\n+    device_analsis_page = get_device_analysis_page()\n+    multi_day_dashboard = get_multi_day_page_dashboard()\n+\n+    init_single_day_dashboard_callbacks(app)\n+    init_devices_analysis_callbacks(app)\n+    init_multi_day_dashboard_callbacks(app)\n+\n+    # Authentication\n+    flaskApp.config['SECRET_KEY'] = os.environ.get('SECRET_KEY')\n+\n+    from app.commons.dao.db_connection import redis_store as redis_db_connection\n+    from app.commons.device_analysis_helper import get_device_analysis_data\n+    from app.commons.dashboard_helper import get_single_day_dashboard_data, get_multi_day_dashboard_data\n+    from app.commons.utill import map_data, check_context_triggered_for_input\n+\n+    # Update the index\n+    @app.callback(\n+    [\n+      Output('url', 'hash')\n+    ],\n+    [\n+      Input('main-layout', 'date_clicks'),\n+      Input({'type': 'search', 'details': ALL, 'link': ALL}, 'data')\n+    ],\n+    [\n+      State('url', 'hash'),\n+      State('main-layout', 'start'),\n+      State('main-layout', 'end')\n+    ], prevent_initial_call=True)\n+    def on_date_change(date_clicks, search, hash, start_date_str, end_date_str):\n+      print(hash, start_date_str, end_date_str)\n+      input_id, triggered = check_context_triggered_for_input(dash.callback_context, [])\n+      print(input_id, triggered, search)\n+\n+      if input_id is None:\n+        raise PreventUpdate\n+\n+      start_date, end_date = get_date_rage(start_date_str, end_date_str)\n+\n+      diff = end_date - start_date\n+      diff = diff.days\n+\n+      if input_id != 'main-layout':\n+        search_details = json.loads(input_id)\n+        link = search_details['link']\n+        hash = link\n+        start_date_str = start_date.strftime('%Y-%m-%d')\n+        end_date_str = end_date.strftime('%Y-%m-%d')\n+\n+      pathname, mainMenu, subMenu = get_path_name(hash.strip())\n+      print('Path: ', hash, pathname, mainMenu, subMenu)\n+\n+      if (mainMenu == '/dashboard' or mainMenu == 'dashboard' or pathname == '') and diff == 0:\n+        return ['#/dashboard/'+start_date_str]\n+      elif (mainMenu == '/dashboard' or mainMenu == 'dashboard' or pathname == '') and diff > 0:\n+        return ['#/dashboard/'+start_date_str+'/'+end_date_str]\n+      elif diff == 0:\n+        return ['#/' + mainMenu +'/' + subMenu+'/'+start_date_str]\n+      else:\n+        return ['#/' + mainMenu +'/' + subMenu+'/'+start_date_str+'/'+end_date_str]\n+\n+    @app.callback(\n+    [\n+      Output('datalake-container', 'children'),\n+      Output('main-layout', 'activePage'),\n+      Output('main-layout', 'subHeaderTitles'),\n+      Output('single-day-session-store', 'data'),\n+      Output('multi-day-session-store', 'data'),\n+      Output('device-analytics-page-session-store', 'data'),\n+      Output('main-layout', 'userDetails'),\n+      Output('main-layout', 'showQuickActions'),\n+      Output('main-layout', 'selectedAction'),\n+      Output('current-search', 'data')\n+    ],\n+    [\n+      Input('url', 'hash'),\n+      Input('main-layout', 'quick_action_clicks')\n+    ],\n+    [\n+      State('main-layout', 'config'),\n+      State('main-layout', 'start'),\n+      State('main-layout', 'end'),\n+      State({'type': 'search', 'details': ALL, 'link': ALL}, 'data'),\n+      State('main-layout', 'quick_action_selected_data'),\n+      State('current-search', 'data')\n+    ])\n+    def display_page(hash, quick_action_clicks, config, start_date_str, end_date_str, search, selected_product_type, stored_search):\n+      input_id, triggered = check_context_triggered_for_input(dash.callback_context, ['main-layout', 'url'])\n+      print('display_page', input_id, hash, start_date_str, end_date_str)\n+\n+      # TODO get start and end date from URL\n+      start_date, end_date = get_date_rage(start_date_str, end_date_str)\n+\n+      diff = end_date - start_date\n+      diff = diff.days\n+\n+      pathname, mainMenu, subMenu = get_path_name(hash)\n+      print('Path: ', hash, pathname, mainMenu, subMenu)\n+\n+      search_params = {}\n+      search_params['start_date'] = start_date.strftime('%Y-%m-%d')\n+      search_params['end_date'] = end_date.strftime('%Y-%m-%d')\n+\n+      # Get User From Flask App Session\n+      user_details = session.get('user')\n+\n+      subtitles = []\n+      for navLink in config['navLinks']:\n+        if navLink[\"link\"].find(mainMenu) >= 0:\n+          subtitles.append(navLink)\n+        else:\n+          continue\n+\n+        if 'children' in navLink.keys():\n+          for subNavLink in navLink[\"children\"]:\n+            if subNavLink[\"link\"].find(subMenu) > 0:\n+              subtitles.append(subNavLink)\n+              break\n+      if start_date_str is not None:\n+        subtitles.append({'name': start_date_str, 'icon': 'flaticon-calendar'})\n+\n+      if end_date_str is not None and diff > 0:\n+        subtitles.append({'name': end_date_str, 'icon': 'flaticon-calendar'})\n+\n+      if (mainMenu == '/dashboard' or mainMenu == 'dashboard') and diff == 0:\n+        compare_date = start_date - timedelta(days=1)\n+        json_data = get_single_day_dashboard_data(start_date, compare_date)\n+        return single_dashboard, pathname, subtitles, json_data, None, None, user_details, False, None, search\n+      elif (mainMenu == '/dashboard' or mainMenu == 'dashboard') and diff > 0:\n+        json_data = get_multi_day_dashboard_data(start_date, end_date)\n+        return multi_day_dashboard, pathname, subtitles, None, json_data, None, user_details, False, None, search\n+      elif ('reports/device-analysis' in pathname):\n+        \n+        product_type = None\n+        search_type = None\n+\n+        if (search is None or len(search) == 0) and stored_search is not None:\n+          search = stored_search # change of in-page search\n+\n+        if search is not None and len(search) > 0:\n+          [ obj ] = search\n+          print(obj)\n+          if 'alarm_codes' in obj:\n+            search_params['alarm_codes'] = obj['alarm_codes']\n+          \n+          if 'product_type' in obj:\n+            product_type = obj['product_type']\n+\n+          if 'connection_range' in obj:\n+            search_params['connection_range'] = obj['connection_range']\n+          \n+          if 'locations' in obj:\n+            search_params['locations'] = obj['locations']\n+\n+          if 'search_type' in obj:\n+            search_type = obj['search_type']\n+        \n+        if ( input_id == 'main-layout' or product_type is None) and selected_product_type is not None:\n+          product_type = selected_product_type\n+\n+        json_data = get_device_analysis_data(start_date, end_date, search_type, product_type, search_params)\n+        return device_analsis_page, pathname, subtitles, None, None, json_data, user_details, True, product_type, search\n+      else:\n+        return html.Div(html.H1(pathname)), pathname, subtitles, None, None, None, user_details, True, None, search\n+    \n+    return flaskApp\n\\ No newline at end of file"
      },
      {
        "sha": "85e44b51d9ff3637a75558bb7f1e0df85113783f",
        "filename": "rheem_ds_admin_components",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": null,
        "raw_url": null,
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/rheem_ds_admin_components?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -1 +1 @@\n-Subproject commit 73935ec7b350c8c3f5e7aac76775580d3b34027e\n+Subproject commit 85e44b51d9ff3637a75558bb7f1e0df85113783f"
      },
      {
        "sha": "7a49f8e09021caeda59a01d3aaa96ddaad6c814d",
        "filename": "start.bat",
        "status": "added",
        "additions": 21,
        "deletions": 0,
        "changes": 21,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/start.bat",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/start.bat",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/start.bat?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,21 @@\n+# start.sh\n+SET DS_AUTH_URL=http://ds-auth.rheemconnect.com\n+SET DS_APP_URL=http://localhost:5000/\n+SET SECRET_KEY=k1LUZ1fZShowB6opoyUIEJkJvS8RBF6MMgmNcDGNmgGYr\n+SET FLASK_DEBUG=1\n+SET FLASK_APP=wsgi.py\n+SET APP_CONFIG_FILE=config.py\n+SET port=8080\n+SET secret=\"mysecrettext\"\n+SET postgres_url=rheem-datascience-production.cxi7zfcpgbcr.us-east-1.rds.amazonaws.com\n+SET postgres_port=5432\n+SET postgres_user=rheemdatascience\n+SET postgres_password=MzTbtmf9S4nP4PGM\n+SET postgres_db=postgres\n+SET AWS_REGION=us-east-1\n+SET AWS_ATHENA_DATABASE=econet\n+SET TEMP_BUCKET=rheem-athena-query-output\n+SET LONG_TERM_BUCKET=rheem-download-data-output\n+SET S3_PROFILE=rheem\n+SET FLASK_PROD=0\n+python -m flask run"
      },
      {
        "sha": "95cc12111e8f6f427e12b030a2294a9886c18505",
        "filename": "start.sh",
        "status": "added",
        "additions": 28,
        "deletions": 0,
        "changes": 28,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/start.sh",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/start.sh",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/start.sh?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,28 @@\n+# start.sh\n+export DS_AUTH_URL=\"https://ds-auth.rheemconnect.com/\"\n+export DS_APP_URL=\"http://localhost:8000\"\n+export SECRET_KEY=\"k1LUZ1fZShowB6opoyUIEJkJvS8RBF6MMgmNcDGNmgGYr\"\n+export FLASK_APP=wsgi.py\n+export FLASK_DEBUG=1\n+export APP_CONFIG_FILE=config.py\n+export port=8080\n+export secret=\"mysecrettext\"\n+export postgres_url=production-rheem-datascience-rds-database.cxi7zfcpgbcr.us-east-1.rds.amazonaws.com\n+export postgres_port=5432\n+export postgres_user=econet_production\n+export postgres_schema=econet_production\n+export postgres_password=MjEyOTQ0YjkxOGMzOTJlZTFlMGY4MWQ0\n+export postgres_db=postgres\n+export AWS_REGION=us-east-1\n+export AWS_ATHENA_DATABASE=production-rheem-datascience-econet-database\n+export TEMP_BUCKET=rheem-athena-query-output\n+export LONG_TERM_BUCKET=rheem-download-data-output\n+export AWS_PROFILE=rheem\n+export FLASK_PROD=0\n+export LOG_LEVEL=1\n+export REDIS_HOST=127.0.0.1\n+export REDIS_PORT=6379\n+export API_SECRET_KEY=Y2UwMDhiNzJiOTQ3NzlhZTAyMjZlMDg1Y2NiNWM3ZTM=\n+cp -r rheem_ds_admin_components/assets .\n+python wsgi.py\n+"
      },
      {
        "sha": "4b1038741720d0f1a19dc2ee0a16f370403cb0fc",
        "filename": "version.sh",
        "status": "added",
        "additions": 17,
        "deletions": 0,
        "changes": 17,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/version.sh",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/version.sh",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/version.sh?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,17 @@\n+#!/bin/sh\n+GIT_BRANCH=`git branch 2> /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/\\1/'`\n+GIT_COMMIT=`git rev-parse --short HEAD`\n+\n+\n+if [ \"$GIT_BRANCH\" == \"main\" ]\n+then\n+  ver set --build \"\"\n+  ver up\n+  ver tag\n+  git add .\n+  git commit -m \"version release\"\n+  git push origin --tags\n+else\n+  GIT_BRANCH='develop'\n+  ver set --build \"$GIT_BRANCH-$GIT_COMMIT\"\n+fi"
      },
      {
        "sha": "abc118190b7c62e02cd9e29d9dee7b65b3bec829",
        "filename": "wsgi.py",
        "status": "added",
        "additions": 19,
        "deletions": 0,
        "changes": 19,
        "blob_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/blob/eb26859dd183748040c139e4c179f86a00bef959/wsgi.py",
        "raw_url": "https://github.com/EcoNet-Rheem/rheem-datascience-portal/raw/eb26859dd183748040c139e4c179f86a00bef959/wsgi.py",
        "contents_url": "https://api.github.com/repos/EcoNet-Rheem/rheem-datascience-portal/contents/wsgi.py?ref=eb26859dd183748040c139e4c179f86a00bef959",
        "patch": "@@ -0,0 +1,19 @@\n+\"\"\"Application entry point.\"\"\"\n+from tornado.wsgi import WSGIContainer\n+from tornado.httpserver import HTTPServer\n+from tornado.ioloop import IOLoop\n+\n+from init import create_app\n+from config import Config\n+\n+APP = create_app()\n+\n+if __name__ == \"__main__\":\n+    CONFIG = Config()\n+    if CONFIG.FLASK_PROD == \"1\":\n+        HTTP_SEVER = HTTPServer(WSGIContainer(APP))\n+        HTTP_SEVER.listen(8000)\n+        IOLoop.instance().start()\n+    else:\n+        # Development Server\n+        APP.run(host='0.0.0.0', port=8000, debug=False)"
      }
    ]
  }